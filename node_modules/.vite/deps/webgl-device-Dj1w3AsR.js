import { C as getBrowser, _ as Resource, c as DeviceLimits, f as getVertexFormatInfo, g as Buffer, h as getTypedArrayConstructor, i as initializeSpectorJS, l as textureFormatDecoder, m as getDataType, n as makeDebugContext, o as Device, s as DeviceFeatures, u as getCompatibleVertexFormat, v as uid$1, w as isBrowser, y as log } from "./webgl-developer-tools-DgucggGC.js";

//#region node_modules/@luma.gl/core/dist/utils/promise-utils.js
function withResolvers() {
	let resolve;
	let reject;
	return {
		promise: new Promise((_resolve, _reject) => {
			resolve = _resolve;
			reject = _reject;
		}),
		resolve,
		reject
	};
}

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/canvas-context.js
/**
* Manages a canvas. Supports both HTML or offscreen canvas
* - Creates a new canvas or looks up a canvas from the DOM
* - Provides check for DOM loaded
* @todo commit() @see https://github.com/w3ctag/design-reviews/issues/288
* @todo transferControlToOffscreen: @see https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement/transferControlToOffscreen
*/
var CanvasContext = class CanvasContext {
	static isHTMLCanvas(canvas) {
		return typeof HTMLCanvasElement !== "undefined" && canvas instanceof HTMLCanvasElement;
	}
	static isOffscreenCanvas(canvas) {
		return typeof OffscreenCanvas !== "undefined" && canvas instanceof OffscreenCanvas;
	}
	static defaultProps = {
		id: void 0,
		canvas: null,
		width: 800,
		height: 600,
		useDevicePixels: true,
		autoResize: true,
		container: null,
		visible: true,
		alphaMode: "opaque",
		colorSpace: "srgb",
		trackPosition: false
	};
	id;
	props;
	canvas;
	/** Handle to HTML canvas */
	htmlCanvas;
	/** Handle to wrapped OffScreenCanvas */
	offscreenCanvas;
	type;
	/** Promise that resolved once the resize observer has updated the pixel size */
	initialized;
	isInitialized = false;
	/** Visibility is automatically updated (via an IntersectionObserver) */
	isVisible = true;
	/** Width of canvas in CSS units (tracked by a ResizeObserver) */
	cssWidth;
	/** Height of canvas in CSS units (tracked by a ResizeObserver) */
	cssHeight;
	/** Device pixel ratio. Automatically updated via media queries */
	devicePixelRatio;
	/** Exact width of canvas in physical pixels (tracked by a ResizeObserver) */
	devicePixelWidth;
	/** Exact height of canvas in physical pixels (tracked by a ResizeObserver) */
	devicePixelHeight;
	/** Width of drawing buffer: automatically tracks this.pixelWidth if props.autoResize is true */
	drawingBufferWidth;
	/** Height of drawing buffer: automatically tracks this.pixelHeight if props.autoResize is true */
	drawingBufferHeight;
	_initializedResolvers = withResolvers();
	_resizeObserver;
	_intersectionObserver;
	_position;
	destroyed = false;
	toString() {
		return `${this[Symbol.toStringTag]}(${this.id})`;
	}
	constructor(props) {
		this.props = {
			...CanvasContext.defaultProps,
			...props
		};
		props = this.props;
		this.initialized = this._initializedResolvers.promise;
		if (!isBrowser()) this.canvas = {
			width: props.width || 1,
			height: props.height || 1
		};
		else if (!props.canvas) this.canvas = createCanvasElement(props);
		else if (typeof props.canvas === "string") this.canvas = getCanvasFromDOM(props.canvas);
		else this.canvas = props.canvas;
		if (CanvasContext.isHTMLCanvas(this.canvas)) {
			this.id = props.id || this.canvas.id;
			this.type = "html-canvas";
			this.htmlCanvas = this.canvas;
		} else if (CanvasContext.isOffscreenCanvas(this.canvas)) {
			this.id = props.id || "offscreen-canvas";
			this.type = "offscreen-canvas";
			this.offscreenCanvas = this.canvas;
		} else {
			this.id = props.id || "node-canvas-context";
			this.type = "node";
		}
		this.cssWidth = this.htmlCanvas?.clientWidth || this.canvas.width;
		this.cssHeight = this.htmlCanvas?.clientHeight || this.canvas.height;
		this.devicePixelWidth = this.canvas.width;
		this.devicePixelHeight = this.canvas.height;
		this.drawingBufferWidth = this.canvas.width;
		this.drawingBufferHeight = this.canvas.height;
		this.devicePixelRatio = globalThis.devicePixelRatio || 1;
		this._position = [0, 0];
		if (CanvasContext.isHTMLCanvas(this.canvas)) {
			this._intersectionObserver = new IntersectionObserver((entries) => this._handleIntersection(entries));
			this._intersectionObserver.observe(this.canvas);
			this._resizeObserver = new ResizeObserver((entries) => this._handleResize(entries));
			try {
				this._resizeObserver.observe(this.canvas, { box: "device-pixel-content-box" });
			} catch {
				this._resizeObserver.observe(this.canvas, { box: "content-box" });
			}
			setTimeout(() => this._observeDevicePixelRatio(), 0);
			if (this.props.trackPosition) this._trackPosition();
		}
	}
	destroy() {
		this.destroyed = true;
	}
	setProps(props) {
		if ("useDevicePixels" in props) {
			this.props.useDevicePixels = props.useDevicePixels || false;
			this._updateDrawingBufferSize();
		}
		return this;
	}
	/**
	* Returns the size covered by the canvas in CSS pixels
	* @note This can be different from the actual device pixel size of a canvas due to DPR scaling, and rounding to integer pixels
	* @note This is independent of the canvas' internal drawing buffer size (.width, .height).
	*/
	getCSSSize() {
		return [this.cssWidth, this.cssHeight];
	}
	getPosition() {
		return this._position;
	}
	/**
	* Returns the size covered by the canvas in actual device pixels.
	* @note This can be different from the 'CSS' size of a canvas due to DPR scaling, and rounding to integer pixels
	* @note This is independent of the canvas' internal drawing buffer size (.width, .height).
	*/
	getDevicePixelSize() {
		return [this.devicePixelWidth, this.devicePixelHeight];
	}
	/** Get the drawing buffer size (number of pixels GPU is rendering into, can be different from CSS size) */
	getDrawingBufferSize() {
		return [this.drawingBufferWidth, this.drawingBufferHeight];
	}
	/** Returns the biggest allowed framebuffer size. @todo Allow the application to limit this? */
	getMaxDrawingBufferSize() {
		const maxTextureDimension = this.device.limits.maxTextureDimension2D;
		return [maxTextureDimension, maxTextureDimension];
	}
	/** Update the canvas drawing buffer size. Called automatically if props.autoResize is true. */
	setDrawingBufferSize(width, height) {
		this.canvas.width = width;
		this.canvas.height = height;
		this.drawingBufferWidth = width;
		this.drawingBufferHeight = height;
	}
	/**
	* Returns the current DPR (number of physical pixels per CSS pixel), if props.useDevicePixels is true
	* @note This can be a fractional (non-integer) number, e.g. when the user zooms in the browser.
	* @note This function handles the non-HTML canvas cases
	*/
	getDevicePixelRatio() {
		return typeof window !== "undefined" && window.devicePixelRatio || 1;
	}
	/**
	* Maps CSS pixel position to device pixel position
	*/
	cssToDevicePixels(cssPixel, yInvert = true) {
		const ratio = this.cssToDeviceRatio();
		const [width, height] = this.getDrawingBufferSize();
		return scalePixels(cssPixel, ratio, width, height, yInvert);
	}
	/** @deprecated - use .getDevicePixelSize() */
	getPixelSize() {
		return this.getDevicePixelSize();
	}
	/** @deprecated - TODO which values should we use for aspect */
	getAspect() {
		const [width, height] = this.getDevicePixelSize();
		return width / height;
	}
	/** @deprecated Returns multiplier need to convert CSS size to Device size */
	cssToDeviceRatio() {
		try {
			const [drawingBufferWidth] = this.getDrawingBufferSize();
			const [cssWidth] = this.getCSSSize();
			return cssWidth ? drawingBufferWidth / cssWidth : 1;
		} catch {
			return 1;
		}
	}
	/** @deprecated Use canvasContext.setDrawingBufferSize() */
	resize(size) {
		this.setDrawingBufferSize(size.width, size.height);
	}
	/**
	* Allows subclass constructor to override the canvas id for auto created canvases.
	* This can really help when debugging DOM in apps that create multiple devices
	*/
	_setAutoCreatedCanvasId(id) {
		if (this.htmlCanvas?.id === "lumagl-auto-created-canvas") this.htmlCanvas.id = id;
	}
	/** reacts to an observed intersection */
	_handleIntersection(entries) {
		const entry = entries.find((entry_) => entry_.target === this.canvas);
		if (!entry) return;
		const isVisible = entry.isIntersecting;
		if (this.isVisible !== isVisible) {
			this.isVisible = isVisible;
			this.device.props.onVisibilityChange(this);
		}
	}
	/**
	* Reacts to an observed resize by using the most accurate pixel size information the browser can provide
	* @see https://web.dev/articles/device-pixel-content-box
	* @see https://webgpufundamentals.org/webgpu/lessons/webgpu-resizing-the-canvas.html
	*/
	_handleResize(entries) {
		const entry = entries.find((entry_) => entry_.target === this.canvas);
		if (!entry) return;
		this.cssWidth = entry.contentBoxSize[0].inlineSize;
		this.cssHeight = entry.contentBoxSize[0].blockSize;
		const oldPixelSize = this.getDevicePixelSize();
		const devicePixelWidth = entry.devicePixelContentBoxSize?.[0].inlineSize || entry.contentBoxSize[0].inlineSize * devicePixelRatio;
		const devicePixelHeight = entry.devicePixelContentBoxSize?.[0].blockSize || entry.contentBoxSize[0].blockSize * devicePixelRatio;
		const [maxDevicePixelWidth, maxDevicePixelHeight] = this.getMaxDrawingBufferSize();
		this.devicePixelWidth = Math.max(1, Math.min(devicePixelWidth, maxDevicePixelWidth));
		this.devicePixelHeight = Math.max(1, Math.min(devicePixelHeight, maxDevicePixelHeight));
		this._updateDrawingBufferSize();
		this.device.props.onResize(this, { oldPixelSize });
	}
	_updateDrawingBufferSize() {
		if (this.props.autoResize) {
			if (typeof this.props.useDevicePixels === "number") {
				const dpr = this.props.useDevicePixels;
				this.setDrawingBufferSize(this.cssWidth * dpr, this.cssHeight * dpr);
			} else if (this.props.useDevicePixels) this.setDrawingBufferSize(this.devicePixelWidth, this.devicePixelHeight);
			else this.setDrawingBufferSize(this.cssWidth, this.cssHeight);
			this._updateDevice();
		}
		this._initializedResolvers.resolve();
		this.isInitialized = true;
		this.updatePosition();
	}
	/** Monitor DPR changes */
	_observeDevicePixelRatio() {
		const oldRatio = this.devicePixelRatio;
		this.devicePixelRatio = window.devicePixelRatio;
		this.updatePosition();
		this.device.props.onDevicePixelRatioChange(this, { oldRatio });
		matchMedia(`(resolution: ${this.devicePixelRatio}dppx)`).addEventListener("change", () => this._observeDevicePixelRatio(), { once: true });
	}
	/** Start tracking positions with a timer */
	_trackPosition(intervalMs = 100) {
		const intervalId = setInterval(() => {
			if (this.destroyed) clearInterval(intervalId);
			else this.updatePosition();
		}, intervalMs);
	}
	/**
	* Calculated the absolute position of the canvas
	* @note - getBoundingClientRect() is normally cheap but can be expensive
	* if called before browser has finished a reflow. Should not be the case here.
	*/
	updatePosition() {
		const newRect = this.htmlCanvas?.getBoundingClientRect();
		if (newRect) {
			const position = [newRect.left, newRect.top];
			this._position ??= position;
			if (position[0] !== this._position[0] || position[1] !== this._position[1]) {
				const oldPosition = this._position;
				this._position = position;
				this.device.props.onPositionChange?.(this, { oldPosition });
			}
		}
	}
};
/** Get a container element from a string or DOM element */
function getContainer(container) {
	if (typeof container === "string") {
		const element = document.getElementById(container);
		if (!element) throw new Error(`${container} is not an HTML element`);
		return element;
	}
	if (container) return container;
	return document.body;
}
/** Get a Canvas element from DOM id */
function getCanvasFromDOM(canvasId) {
	const canvas = document.getElementById(canvasId);
	if (!CanvasContext.isHTMLCanvas(canvas)) throw new Error("Object is not a canvas element");
	return canvas;
}
/** Create a new canvas */
function createCanvasElement(props) {
	const { width, height } = props;
	const newCanvas = document.createElement("canvas");
	newCanvas.id = uid$1("lumagl-auto-created-canvas");
	newCanvas.width = width || 1;
	newCanvas.height = height || 1;
	newCanvas.style.width = Number.isFinite(width) ? `${width}px` : "100%";
	newCanvas.style.height = Number.isFinite(height) ? `${height}px` : "100%";
	if (!props?.visible) newCanvas.style.visibility = "hidden";
	const container = getContainer(props?.container || null);
	container.insertBefore(newCanvas, container.firstChild);
	return newCanvas;
}
/**
* Scales pixels linearly, handles edge cases
* @param pixel
* @param ratio
* @param width
* @param height
* @param yInvert
* @returns
*/
function scalePixels(pixel, ratio, width, height, yInvert) {
	const point = pixel;
	const x = scaleX(point[0], ratio, width);
	let y = scaleY(point[1], ratio, height, yInvert);
	let t = scaleX(point[0] + 1, ratio, width);
	const xHigh = t === width - 1 ? t : t - 1;
	t = scaleY(point[1] + 1, ratio, height, yInvert);
	let yHigh;
	if (yInvert) {
		t = t === 0 ? t : t + 1;
		yHigh = y;
		y = t;
	} else yHigh = t === height - 1 ? t : t - 1;
	return {
		x,
		y,
		width: Math.max(xHigh - x + 1, 1),
		height: Math.max(yHigh - y + 1, 1)
	};
}
function scaleX(x, ratio, width) {
	return Math.min(Math.round(x * ratio), width - 1);
}
function scaleY(y, ratio, height, yInvert) {
	return yInvert ? Math.max(0, height - 1 - Math.round(y * ratio)) : Math.min(Math.round(y * ratio), height - 1);
}

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/resources/sampler.js
/** Immutable Sampler object */
var Sampler = class Sampler extends Resource {
	static defaultProps = {
		...Resource.defaultProps,
		type: "color-sampler",
		addressModeU: "clamp-to-edge",
		addressModeV: "clamp-to-edge",
		addressModeW: "clamp-to-edge",
		magFilter: "nearest",
		minFilter: "nearest",
		mipmapFilter: "none",
		lodMinClamp: 0,
		lodMaxClamp: 32,
		compare: "less-equal",
		maxAnisotropy: 1
	};
	get [Symbol.toStringTag]() {
		return "Sampler";
	}
	constructor(device, props) {
		props = Sampler.normalizeProps(device, props);
		super(device, props, Sampler.defaultProps);
	}
	static normalizeProps(device, props) {
		return props;
	}
};

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/resources/texture.js
var BASE_DIMENSIONS = {
	"1d": "1d",
	"2d": "2d",
	"2d-array": "2d",
	cube: "2d",
	"cube-array": "2d",
	"3d": "3d"
};
/**
* Abstract Texture interface
* Texture Object
* https://gpuweb.github.io/gpuweb/#gputexture
*/
var Texture = class Texture extends Resource {
	/** The texture can be bound for use as a sampled texture in a shader */
	static SAMPLE = 4;
	/** The texture can be bound for use as a storage texture in a shader */
	static STORAGE = 8;
	/** The texture can be used as a color or depth/stencil attachment in a render pass */
	static RENDER = 16;
	/** The texture can be used as the source of a copy operation */
	static COPY_SRC = 1;
	/** he texture can be used as the destination of a copy or write operation */
	static COPY_DST = 2;
	/** @deprecated Use Texture.SAMPLE */
	static TEXTURE = 4;
	/** @deprecated Use Texture.RENDER */
	static RENDER_ATTACHMENT = 16;
	/** dimension of this texture */
	dimension;
	/** base dimension of this texture */
	baseDimension;
	/** format of this texture */
	format;
	/** width in pixels of this texture */
	width;
	/** height in pixels of this texture */
	height;
	/** depth of this texture */
	depth;
	/** mip levels in this texture */
	mipLevels;
	/** "Time" of last update. Monotonically increasing timestamp. TODO move to AsyncTexture? */
	updateTimestamp;
	get [Symbol.toStringTag]() {
		return "Texture";
	}
	toString() {
		return `Texture(${this.id},${this.format},${this.width}x${this.height})`;
	}
	/** Do not use directly. Create with device.createTexture() */
	constructor(device, props) {
		props = Texture.normalizeProps(device, props);
		super(device, props, Texture.defaultProps);
		this.dimension = this.props.dimension;
		this.baseDimension = BASE_DIMENSIONS[this.dimension];
		this.format = this.props.format;
		this.width = this.props.width;
		this.height = this.props.height;
		this.depth = this.props.depth;
		this.mipLevels = this.props.mipLevels;
		if (this.props.width === void 0 || this.props.height === void 0) if (device.isExternalImage(props.data)) {
			const size = device.getExternalImageSize(props.data);
			this.width = size?.width || 1;
			this.height = size?.height || 1;
		} else {
			this.width = 1;
			this.height = 1;
			if (this.props.width === void 0 || this.props.height === void 0) log.warn(`${this} created with undefined width or height. This is deprecated. Use AsyncTexture instead.`)();
		}
		this.updateTimestamp = device.incrementTimestamp();
	}
	/** Set sampler props associated with this texture */
	setSampler(sampler) {
		this.sampler = sampler instanceof Sampler ? sampler : this.device.createSampler(sampler);
	}
	/**
	* Create a new texture with the same parameters and optionally a different size
	* @note Textures are immutable and cannot be resized after creation, but we can create a similar texture with the same parameters but a new size.
	* @note Does not copy contents of the texture
	*/
	clone(size) {
		return this.device.createTexture({
			...this.props,
			...size
		});
	}
	/** Ensure we have integer coordinates */
	static normalizeProps(device, props) {
		const newProps = { ...props };
		const { width, height } = newProps;
		if (typeof width === "number") newProps.width = Math.max(1, Math.ceil(width));
		if (typeof height === "number") newProps.height = Math.max(1, Math.ceil(height));
		return newProps;
	}
	/** Initialize texture with supplied props */
	_initializeData(data) {
		if (this.device.isExternalImage(data)) this.copyExternalImage({
			image: data,
			width: this.width,
			height: this.height,
			depth: this.depth,
			mipLevel: 0,
			x: 0,
			y: 0,
			z: 0,
			aspect: "all",
			colorSpace: "srgb",
			premultipliedAlpha: false,
			flipY: false
		});
		else if (data) this.copyImageData({
			data,
			mipLevel: 0,
			x: 0,
			y: 0,
			z: 0,
			aspect: "all"
		});
	}
	_normalizeCopyImageDataOptions(options_) {
		const { width, height, depth } = this;
		const options = {
			...Texture.defaultCopyDataOptions,
			width,
			height,
			depth,
			...options_
		};
		const info = this.device.getTextureFormatInfo(this.format);
		if (!options_.bytesPerRow && !info.bytesPerPixel) throw new Error(`bytesPerRow must be provided for texture format ${this.format}`);
		options.bytesPerRow = options_.bytesPerRow || width * (info.bytesPerPixel || 4);
		options.rowsPerImage = options_.rowsPerImage || height;
		return options;
	}
	_normalizeCopyExternalImageOptions(options_) {
		const size = this.device.getExternalImageSize(options_.image);
		const options = {
			...Texture.defaultCopyExternalImageOptions,
			...size,
			...options_
		};
		options.width = Math.min(options.width, this.width - options.x);
		options.height = Math.min(options.height, this.height - options.y);
		return options;
	}
	/** Default options */
	static defaultProps = {
		...Resource.defaultProps,
		data: null,
		dimension: "2d",
		format: "rgba8unorm",
		usage: Texture.TEXTURE | Texture.RENDER_ATTACHMENT | Texture.COPY_DST,
		width: void 0,
		height: void 0,
		depth: 1,
		mipLevels: 1,
		samples: void 0,
		sampler: {},
		view: void 0
	};
	static defaultCopyDataOptions = {
		data: void 0,
		byteOffset: 0,
		bytesPerRow: void 0,
		rowsPerImage: void 0,
		mipLevel: 0,
		x: 0,
		y: 0,
		z: 0,
		aspect: "all"
	};
	/** Default options */
	static defaultCopyExternalImageOptions = {
		image: void 0,
		sourceX: 0,
		sourceY: 0,
		width: void 0,
		height: void 0,
		depth: 1,
		mipLevel: 0,
		x: 0,
		y: 0,
		z: 0,
		aspect: "all",
		colorSpace: "srgb",
		premultipliedAlpha: false,
		flipY: false
	};
};

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/resources/texture-view.js
/** Immutable TextureView object */
var TextureView = class TextureView extends Resource {
	get [Symbol.toStringTag]() {
		return "TextureView";
	}
	/** Should not be constructed directly. Use `texture.createView(props)` */
	constructor(device, props) {
		super(device, props, TextureView.defaultProps);
	}
	static defaultProps = {
		...Resource.defaultProps,
		format: void 0,
		dimension: void 0,
		aspect: "all",
		baseMipLevel: 0,
		mipLevelCount: void 0,
		baseArrayLayer: 0,
		arrayLayerCount: void 0
	};
};

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter-utils/format-compiler-log.js
/** @returns annotated errors or warnings */
function formatCompilerLog(shaderLog, source, options) {
	let formattedLog = "";
	const lines = source.split(/\r?\n/);
	const log$1 = shaderLog.slice().sort((a, b) => a.lineNum - b.lineNum);
	switch (options?.showSourceCode || "no") {
		case "all":
			let currentMessage = 0;
			for (let lineNum = 1; lineNum <= lines.length; lineNum++) {
				formattedLog += getNumberedLine(lines[lineNum - 1], lineNum, options);
				while (log$1.length > currentMessage && log$1[currentMessage].lineNum === lineNum) {
					const message$1 = log$1[currentMessage++];
					formattedLog += formatCompilerMessage(message$1, lines, message$1.lineNum, {
						...options,
						inlineSource: false
					});
				}
			}
			while (log$1.length > currentMessage) {
				const message$1 = log$1[currentMessage++];
				formattedLog += formatCompilerMessage(message$1, [], 0, {
					...options,
					inlineSource: false
				});
			}
			return formattedLog;
		case "issues":
		case "no":
			for (const message$1 of shaderLog) formattedLog += formatCompilerMessage(message$1, lines, message$1.lineNum, { inlineSource: options?.showSourceCode !== "no" });
			return formattedLog;
	}
}
/** Format one message */
function formatCompilerMessage(message$1, lines, lineNum, options) {
	if (options?.inlineSource) return `
${getNumberedLines(lines, lineNum)}${message$1.linePos > 0 ? `${" ".repeat(message$1.linePos + 5)}^^^\n` : ""}${message$1.type.toUpperCase()}: ${message$1.message}

`;
	const color = message$1.type === "error" ? "red" : "#8B4000";
	return options?.html ? `<div class='luma-compiler-log-error' style="color:${color};"><b> ${message$1.type.toUpperCase()}: ${message$1.message}</b></div>` : `${message$1.type.toUpperCase()}: ${message$1.message}`;
}
function getNumberedLines(lines, lineNum, options) {
	let numberedLines = "";
	for (let lineIndex = lineNum - 2; lineIndex <= lineNum; lineIndex++) {
		const sourceLine = lines[lineIndex - 1];
		if (sourceLine !== void 0) numberedLines += getNumberedLine(sourceLine, lineNum, options);
	}
	return numberedLines;
}
function getNumberedLine(line, lineNum, options) {
	const escapedLine = options?.html ? escapeHTML(line) : line;
	return `${padLeft(String(lineNum), 4)}: ${escapedLine}${options?.html ? "<br/>" : "\n"}`;
}
/**
* Pads a string with a number of spaces (space characters) to the left
* @param {String} string - string to pad
* @param {Number} digits - number of spaces to add
* @return {String} string - The padded string
*/
function padLeft(string, paddedLength) {
	let result = "";
	for (let i = string.length; i < paddedLength; ++i) result += " ";
	return result + string;
}
function escapeHTML(unsafe) {
	return unsafe.replaceAll("&", "&amp;").replaceAll("<", "&lt;").replaceAll(">", "&gt;").replaceAll("\"", "&quot;").replaceAll("'", "&#039;");
}

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/resources/shader.js
/**
* Immutable Shader object
* In WebGPU the handle can be copied between threads
*/
var Shader = class Shader extends Resource {
	get [Symbol.toStringTag]() {
		return "Shader";
	}
	/** The stage of this shader */
	stage;
	/** The source code of this shader */
	source;
	/** The compilation status of the shader. 'pending' if compilation is asynchronous, and on production */
	compilationStatus = "pending";
	/** Create a new Shader instance */
	constructor(device, props) {
		props = {
			...props,
			debugShaders: props.debugShaders || device.props.debugShaders || "errors"
		};
		super(device, {
			id: getShaderIdFromProps(props),
			...props
		}, Shader.defaultProps);
		this.stage = this.props.stage;
		this.source = this.props.source;
	}
	/** Get compiler log synchronously (WebGL only) */
	getCompilationInfoSync() {
		return null;
	}
	/** Get translated shader source in host platform's native language (HLSL, GLSL, and even GLSL ES), if available */
	getTranslatedSource() {
		return null;
	}
	/** In browser logging of errors */
	async debugShader() {
		const trigger = this.props.debugShaders;
		switch (trigger) {
			case "never": return;
			case "errors":
				if (this.compilationStatus === "success") return;
				break;
			case "warnings":
			case "always": break;
		}
		const messages = await this.getCompilationInfo();
		if (trigger === "warnings" && messages?.length === 0) return;
		this._displayShaderLog(messages, this.id);
	}
	/**
	* In-browser UI logging of errors
	* TODO - this HTML formatting code should not be in Device, should be pluggable
	*/
	_displayShaderLog(messages, shaderId) {
		if (typeof document === "undefined" || !document?.createElement) return;
		const shaderName = shaderId;
		const shaderTitle = `${this.stage} shader "${shaderName}"`;
		let htmlLog = formatCompilerLog(messages, this.source, {
			showSourceCode: "all",
			html: true
		});
		const translatedSource = this.getTranslatedSource();
		if (translatedSource) htmlLog += `<br /><br /><h1>Translated Source</h1><br /><br /><code style="user-select:text;"><pre>${translatedSource}</pre></code>`;
		const button = document.createElement("Button");
		button.innerHTML = `
<h1>Compilation error in ${shaderTitle}</h1><br /><br />
<code style="user-select:text;"><pre>
${htmlLog}
</pre></code>`;
		button.style.top = "10px";
		button.style.left = "10px";
		button.style.position = "absolute";
		button.style.zIndex = "9999";
		button.style.width = "100%";
		button.style.textAlign = "left";
		document.body.appendChild(button);
		document.getElementsByClassName("luma-compiler-log-error")[0]?.scrollIntoView();
		button.onclick = () => {
			const dataURI = `data:text/plain,${encodeURIComponent(this.source)}`;
			navigator.clipboard.writeText(dataURI);
		};
	}
	static defaultProps = {
		...Resource.defaultProps,
		language: "auto",
		stage: void 0,
		source: "",
		sourceMap: null,
		entryPoint: "main",
		debugShaders: void 0
	};
};
/** Deduce an id, from shader source, or supplied id, or shader type */
function getShaderIdFromProps(props) {
	return getShaderName(props.source) || props.id || uid$1(`unnamed ${props.stage}-shader`);
}
/** Extracts GLSLIFY style naming of shaders: `#define SHADER_NAME ...` */
function getShaderName(shader, defaultName = "unnamed") {
	const match = /#define[\s*]SHADER_NAME[\s*]([A-Za-z0-9_-]+)[\s*]/.exec(shader);
	return match ? match[1] : defaultName;
}

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/resources/framebuffer.js
/**
* Create new textures with correct size for all attachments.
* @note resize() destroys existing textures (if size has changed).
*/
var Framebuffer = class Framebuffer extends Resource {
	get [Symbol.toStringTag]() {
		return "Framebuffer";
	}
	/** Width of all attachments in this framebuffer */
	width;
	/** Height of all attachments in this framebuffer */
	height;
	constructor(device, props = {}) {
		super(device, props, Framebuffer.defaultProps);
		this.width = this.props.width;
		this.height = this.props.height;
	}
	/**
	* Create a copy of this framebuffer with new attached textures, with same props but of the specified size.
	* @note Does not copy contents of the attached textures.
	*/
	clone(size) {
		const colorAttachments = this.colorAttachments.map((colorAttachment) => colorAttachment.texture.clone(size));
		const depthStencilAttachment = this.depthStencilAttachment && this.depthStencilAttachment.texture.clone(size);
		return this.device.createFramebuffer({
			...this.props,
			colorAttachments,
			depthStencilAttachment
		});
	}
	resize(size) {
		let updateSize = !size;
		if (size) {
			const [width, height] = Array.isArray(size) ? size : [size.width, size.height];
			updateSize = updateSize || height !== this.height || width !== this.width;
			this.width = width;
			this.height = height;
		}
		if (updateSize) {
			log.log(2, `Resizing framebuffer ${this.id} to ${this.width}x${this.height}`)();
			this.resizeAttachments(this.width, this.height);
		}
	}
	/** Auto creates any textures */
	autoCreateAttachmentTextures() {
		if (this.props.colorAttachments.length === 0 && !this.props.depthStencilAttachment) throw new Error("Framebuffer has noattachments");
		this.colorAttachments = this.props.colorAttachments.map((attachment$1, index) => {
			if (typeof attachment$1 === "string") {
				const texture = this.createColorTexture(attachment$1, index);
				this.attachResource(texture);
				return texture.view;
			}
			if (attachment$1 instanceof Texture) return attachment$1.view;
			return attachment$1;
		});
		const attachment = this.props.depthStencilAttachment;
		if (attachment) if (typeof attachment === "string") {
			const texture = this.createDepthStencilTexture(attachment);
			this.attachResource(texture);
			this.depthStencilAttachment = texture.view;
		} else if (attachment instanceof Texture) this.depthStencilAttachment = attachment.view;
		else this.depthStencilAttachment = attachment;
	}
	/** Create a color texture */
	createColorTexture(format, index) {
		return this.device.createTexture({
			id: `${this.id}-color-attachment-${index}`,
			usage: Texture.RENDER_ATTACHMENT,
			format,
			width: this.width,
			height: this.height,
			sampler: {
				magFilter: "linear",
				minFilter: "linear"
			}
		});
	}
	/** Create depth stencil texture */
	createDepthStencilTexture(format) {
		return this.device.createTexture({
			id: `${this.id}-depth-stencil-attachment`,
			usage: Texture.RENDER_ATTACHMENT,
			format,
			width: this.width,
			height: this.height
		});
	}
	/**
	* Default implementation of resize
	* Creates new textures with correct size for all attachments.
	* and destroys existing textures if owned
	*/
	resizeAttachments(width, height) {
		for (let i = 0; i < this.colorAttachments.length; ++i) if (this.colorAttachments[i]) {
			const resizedTexture = this.colorAttachments[i].texture.clone({
				width,
				height
			});
			this.destroyAttachedResource(this.colorAttachments[i]);
			this.colorAttachments[i] = resizedTexture.view;
			this.attachResource(resizedTexture.view);
		}
		if (this.depthStencilAttachment) {
			const resizedTexture = this.depthStencilAttachment.texture.clone({
				width,
				height
			});
			this.destroyAttachedResource(this.depthStencilAttachment);
			this.depthStencilAttachment = resizedTexture.view;
			this.attachResource(resizedTexture);
		}
		this.updateAttachments();
	}
	static defaultProps = {
		...Resource.defaultProps,
		width: 1,
		height: 1,
		colorAttachments: [],
		depthStencilAttachment: null
	};
};

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/resources/render-pipeline.js
/**
* A compiled and linked shader program
*/
var RenderPipeline = class RenderPipeline extends Resource {
	get [Symbol.toStringTag]() {
		return "RenderPipeline";
	}
	/** The merged layout */
	shaderLayout;
	/** Buffer map describing buffer interleaving etc */
	bufferLayout;
	/** The linking status of the pipeline. 'pending' if linking is asynchronous, and on production */
	linkStatus = "pending";
	/** The hash of the pipeline */
	hash = "";
	constructor(device, props) {
		super(device, props, RenderPipeline.defaultProps);
		this.shaderLayout = this.props.shaderLayout;
		this.bufferLayout = this.props.bufferLayout || [];
	}
	static defaultProps = {
		...Resource.defaultProps,
		vs: null,
		vertexEntryPoint: "vertexMain",
		vsConstants: {},
		fs: null,
		fragmentEntryPoint: "fragmentMain",
		fsConstants: {},
		shaderLayout: null,
		bufferLayout: [],
		topology: "triangle-list",
		colorAttachmentFormats: void 0,
		depthStencilAttachmentFormat: void 0,
		parameters: {},
		bindings: {},
		uniforms: {}
	};
};

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/resources/render-pass.js
/**
* A RenderPass instance is a required parameter to all draw calls.
*
* It holds a combination of
* - render targets (specified via a framebuffer)
* - clear colors, read/write, discard information for the framebuffer attachments
* - a couple of mutable parameters ()
*/
var RenderPass = class RenderPass extends Resource {
	/** TODO - should be [0, 0, 0, 0], update once deck.gl tests run clean */
	static defaultClearColor = [
		0,
		0,
		0,
		1
	];
	/** Depth 1.0 represents the far plance */
	static defaultClearDepth = 1;
	/** Clears all stencil bits */
	static defaultClearStencil = 0;
	get [Symbol.toStringTag]() {
		return "RenderPass";
	}
	constructor(device, props) {
		props = RenderPass.normalizeProps(device, props);
		super(device, props, RenderPass.defaultProps);
	}
	static normalizeProps(device, props) {
		return props;
	}
	/** Default properties for RenderPass */
	static defaultProps = {
		...Resource.defaultProps,
		framebuffer: null,
		parameters: void 0,
		clearColor: RenderPass.defaultClearColor,
		clearColors: void 0,
		clearDepth: RenderPass.defaultClearDepth,
		clearStencil: RenderPass.defaultClearStencil,
		depthReadOnly: false,
		stencilReadOnly: false,
		discard: false,
		occlusionQuerySet: void 0,
		timestampQuerySet: void 0,
		beginTimestampIndex: void 0,
		endTimestampIndex: void 0
	};
};

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/resources/command-encoder.js
/**
* Encodes commands to queue that can be executed later
*/
var CommandEncoder = class CommandEncoder extends Resource {
	get [Symbol.toStringTag]() {
		return "CommandEncoder";
	}
	constructor(device, props) {
		super(device, props, CommandEncoder.defaultProps);
	}
	static defaultProps = {
		...Resource.defaultProps,
		measureExecutionTime: void 0
	};
};

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/resources/command-buffer.js
/**
* Encodes commands to queue that can be executed later
*/
var CommandBuffer = class CommandBuffer extends Resource {
	get [Symbol.toStringTag]() {
		return "CommandBuffer";
	}
	constructor(device, props) {
		super(device, props, CommandBuffer.defaultProps);
	}
	static defaultProps = { ...Resource.defaultProps };
};

//#endregion
//#region node_modules/@luma.gl/core/dist/shadertypes/data-types/decode-shader-types.js
/** Split a uniform type string into type and components */
function getVariableShaderTypeInfo(format) {
	return UNIFORM_FORMATS[format];
}
/** Decodes a vertex type, returning byte length and flags (integer, signed, normalized) */
function getAttributeShaderTypeInfo(attributeType) {
	const [primitiveType, components] = TYPE_INFO[attributeType];
	const integer = primitiveType === "i32" || primitiveType === "u32";
	const signed = primitiveType !== "u32";
	return {
		primitiveType,
		components,
		byteLength: PRIMITIVE_TYPE_SIZES[primitiveType] * components,
		integer,
		signed
	};
}
var PRIMITIVE_TYPE_SIZES = {
	f32: 4,
	f16: 2,
	i32: 4,
	u32: 4
};
/** All valid shader attribute types. A table guarantees exhaustive list and fast execution */
var TYPE_INFO = {
	f32: ["f32", 1],
	"vec2<f32>": ["f32", 2],
	"vec3<f32>": ["f32", 3],
	"vec4<f32>": ["f32", 4],
	f16: ["f16", 1],
	"vec2<f16>": ["f16", 2],
	"vec3<f16>": ["f16", 3],
	"vec4<f16>": ["f16", 4],
	i32: ["i32", 1],
	"vec2<i32>": ["i32", 2],
	"vec3<i32>": ["i32", 3],
	"vec4<i32>": ["i32", 4],
	u32: ["u32", 1],
	"vec2<u32>": ["u32", 2],
	"vec3<u32>": ["u32", 3],
	"vec4<u32>": ["u32", 4]
};
/** @todo These tables are quite big, consider parsing type strings instead */
var UNIFORM_FORMATS = {
	f32: {
		type: "f32",
		components: 1
	},
	f16: {
		type: "f16",
		components: 1
	},
	i32: {
		type: "i32",
		components: 1
	},
	u32: {
		type: "u32",
		components: 1
	},
	"vec2<f32>": {
		type: "f32",
		components: 2
	},
	"vec3<f32>": {
		type: "f32",
		components: 3
	},
	"vec4<f32>": {
		type: "f32",
		components: 4
	},
	"vec2<f16>": {
		type: "f16",
		components: 2
	},
	"vec3<f16>": {
		type: "f16",
		components: 3
	},
	"vec4<f16>": {
		type: "f16",
		components: 4
	},
	"vec2<i32>": {
		type: "i32",
		components: 2
	},
	"vec3<i32>": {
		type: "i32",
		components: 3
	},
	"vec4<i32>": {
		type: "i32",
		components: 4
	},
	"vec2<u32>": {
		type: "u32",
		components: 2
	},
	"vec3<u32>": {
		type: "u32",
		components: 3
	},
	"vec4<u32>": {
		type: "u32",
		components: 4
	},
	"mat2x2<f32>": {
		type: "f32",
		components: 4
	},
	"mat2x3<f32>": {
		type: "f32",
		components: 6
	},
	"mat2x4<f32>": {
		type: "f32",
		components: 8
	},
	"mat3x2<f32>": {
		type: "f32",
		components: 6
	},
	"mat3x3<f32>": {
		type: "f32",
		components: 9
	},
	"mat3x4<f32>": {
		type: "f32",
		components: 12
	},
	"mat4x2<f32>": {
		type: "f32",
		components: 8
	},
	"mat4x3<f32>": {
		type: "f32",
		components: 12
	},
	"mat4x4<f32>": {
		type: "f32",
		components: 16
	},
	"mat2x2<f16>": {
		type: "f16",
		components: 4
	},
	"mat2x3<f16>": {
		type: "f16",
		components: 6
	},
	"mat2x4<f16>": {
		type: "f16",
		components: 8
	},
	"mat3x2<f16>": {
		type: "f16",
		components: 6
	},
	"mat3x3<f16>": {
		type: "f16",
		components: 9
	},
	"mat3x4<f16>": {
		type: "f16",
		components: 12
	},
	"mat4x2<f16>": {
		type: "f16",
		components: 8
	},
	"mat4x3<f16>": {
		type: "f16",
		components: 12
	},
	"mat4x4<f16>": {
		type: "f16",
		components: 16
	},
	"mat2x2<i32>": {
		type: "i32",
		components: 4
	},
	"mat2x3<i32>": {
		type: "i32",
		components: 6
	},
	"mat2x4<i32>": {
		type: "i32",
		components: 8
	},
	"mat3x2<i32>": {
		type: "i32",
		components: 6
	},
	"mat3x3<i32>": {
		type: "i32",
		components: 9
	},
	"mat3x4<i32>": {
		type: "i32",
		components: 12
	},
	"mat4x2<i32>": {
		type: "i32",
		components: 8
	},
	"mat4x3<i32>": {
		type: "i32",
		components: 12
	},
	"mat4x4<i32>": {
		type: "i32",
		components: 16
	},
	"mat2x2<u32>": {
		type: "u32",
		components: 4
	},
	"mat2x3<u32>": {
		type: "u32",
		components: 6
	},
	"mat2x4<u32>": {
		type: "u32",
		components: 8
	},
	"mat3x2<u32>": {
		type: "u32",
		components: 6
	},
	"mat3x3<u32>": {
		type: "u32",
		components: 9
	},
	"mat3x4<u32>": {
		type: "u32",
		components: 12
	},
	"mat4x2<u32>": {
		type: "u32",
		components: 8
	},
	"mat4x3<u32>": {
		type: "u32",
		components: 12
	},
	"mat4x4<u32>": {
		type: "u32",
		components: 16
	}
};
/**  Predeclared aliases @see https://www.w3.org/TR/WGSL/#vector-types */
const WGSL_ATTRIBUTE_TYPE_ALIAS_MAP = {
	vec2i: "vec2<i32>",
	vec3i: "vec3<i32>",
	vec4i: "vec4<i32>",
	vec2u: "vec2<u32>",
	vec3u: "vec3<u32>",
	vec4u: "vec4<u32>",
	vec2f: "vec2<f32>",
	vec3f: "vec3<f32>",
	vec4f: "vec4<f32>",
	vec2h: "vec2<f16>",
	vec3h: "vec3<f16>",
	vec4h: "vec4<f16>"
};
/** @todo These tables are quite big, consider parsing alias strings instead */
const WGSL_VARIABLE_TYPE_ALIAS_MAP = {
	...WGSL_ATTRIBUTE_TYPE_ALIAS_MAP,
	mat2x2f: "mat2x2<f32>",
	mat2x3f: "mat2x3<f32>",
	mat2x4f: "mat2x4<f32>",
	mat3x2f: "mat3x2<f32>",
	mat3x3f: "mat3x3<f32>",
	mat3x4f: "mat3x4<f32>",
	mat4x2f: "mat4x2<f32>",
	mat4x3f: "mat4x3<f32>",
	mat4x4f: "mat4x4<f32>",
	mat2x2i: "mat2x2<i32>",
	mat2x3i: "mat2x3<i32>",
	mat2x4i: "mat2x4<i32>",
	mat3x2i: "mat3x2<i32>",
	mat3x3i: "mat3x3<i32>",
	mat3x4i: "mat3x4<i32>",
	mat4x2i: "mat4x2<i32>",
	mat4x3i: "mat4x3<i32>",
	mat4x4i: "mat4x4<i32>",
	mat2x2u: "mat2x2<u32>",
	mat2x3u: "mat2x3<u32>",
	mat2x4u: "mat2x4<u32>",
	mat3x2u: "mat3x2<u32>",
	mat3x3u: "mat3x3<u32>",
	mat3x4u: "mat3x4<u32>",
	mat4x2u: "mat4x2<u32>",
	mat4x3u: "mat4x3<u32>",
	mat4x4u: "mat4x4<u32>",
	mat2x2h: "mat2x2<f16>",
	mat2x3h: "mat2x3<f16>",
	mat2x4h: "mat2x4<f16>",
	mat3x2h: "mat3x2<f16>",
	mat3x3h: "mat3x3<f16>",
	mat3x4h: "mat3x4<f16>",
	mat4x2h: "mat4x2<f16>",
	mat4x3h: "mat4x3<f16>",
	mat4x4h: "mat4x4<f16>"
};

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter-utils/get-attribute-from-layouts.js
/**
* Map from "attribute names" to "resolved attribute infos"
* containing information about both buffer layouts and shader attribute declarations
*/
function getAttributeInfosFromLayouts(shaderLayout, bufferLayout) {
	const attributeInfos = {};
	for (const attribute of shaderLayout.attributes) {
		const attributeInfo = getAttributeInfoFromLayouts(shaderLayout, bufferLayout, attribute.name);
		if (attributeInfo) attributeInfos[attribute.name] = attributeInfo;
	}
	return attributeInfos;
}
/**
* Array indexed by "location" holding "resolved attribute infos"
*/
function getAttributeInfosByLocation(shaderLayout, bufferLayout, maxVertexAttributes = 16) {
	const attributeInfos = getAttributeInfosFromLayouts(shaderLayout, bufferLayout);
	const locationInfos = new Array(maxVertexAttributes).fill(null);
	for (const attributeInfo of Object.values(attributeInfos)) locationInfos[attributeInfo.location] = attributeInfo;
	return locationInfos;
}
/**
* Get the combined information from a shader layout and a buffer layout for a specific attribute
*/
function getAttributeInfoFromLayouts(shaderLayout, bufferLayout, name$1) {
	const shaderDeclaration = getAttributeFromShaderLayout(shaderLayout, name$1);
	const bufferMapping = getAttributeFromBufferLayout(bufferLayout, name$1);
	if (!shaderDeclaration) return null;
	const attributeTypeInfo = getAttributeShaderTypeInfo(shaderDeclaration.type);
	const defaultVertexFormat = getCompatibleVertexFormat(attributeTypeInfo);
	const vertexFormat = bufferMapping?.vertexFormat || defaultVertexFormat;
	const vertexFormatInfo = getVertexFormatInfo(vertexFormat);
	return {
		attributeName: bufferMapping?.attributeName || shaderDeclaration.name,
		bufferName: bufferMapping?.bufferName || shaderDeclaration.name,
		location: shaderDeclaration.location,
		shaderType: shaderDeclaration.type,
		primitiveType: attributeTypeInfo.primitiveType,
		shaderComponents: attributeTypeInfo.components,
		vertexFormat,
		bufferDataType: vertexFormatInfo.type,
		bufferComponents: vertexFormatInfo.components,
		normalized: vertexFormatInfo.normalized,
		integer: attributeTypeInfo.integer,
		stepMode: bufferMapping?.stepMode || shaderDeclaration.stepMode || "vertex",
		byteOffset: bufferMapping?.byteOffset || 0,
		byteStride: bufferMapping?.byteStride || 0
	};
}
function getAttributeFromShaderLayout(shaderLayout, name$1) {
	const attribute = shaderLayout.attributes.find((attr) => attr.name === name$1);
	if (!attribute) log.warn(`shader layout attribute "${name$1}" not present in shader`);
	return attribute || null;
}
function getAttributeFromBufferLayout(bufferLayouts, name$1) {
	checkBufferLayouts(bufferLayouts);
	let bufferLayoutInfo = getAttributeFromShortHand(bufferLayouts, name$1);
	if (bufferLayoutInfo) return bufferLayoutInfo;
	bufferLayoutInfo = getAttributeFromAttributesList(bufferLayouts, name$1);
	if (bufferLayoutInfo) return bufferLayoutInfo;
	log.warn(`layout for attribute "${name$1}" not present in buffer layout`);
	return null;
}
/** Check that bufferLayouts are valid (each either has format or attribute) */
function checkBufferLayouts(bufferLayouts) {
	for (const bufferLayout of bufferLayouts) if (bufferLayout.attributes && bufferLayout.format || !bufferLayout.attributes && !bufferLayout.format) log.warn(`BufferLayout ${name} must have either 'attributes' or 'format' field`);
}
/** Get attribute from format shorthand if specified */
function getAttributeFromShortHand(bufferLayouts, name$1) {
	for (const bufferLayout of bufferLayouts) if (bufferLayout.format && bufferLayout.name === name$1) return {
		attributeName: bufferLayout.name,
		bufferName: name$1,
		stepMode: bufferLayout.stepMode,
		vertexFormat: bufferLayout.format,
		byteOffset: 0,
		byteStride: bufferLayout.byteStride || 0
	};
	return null;
}
/**
* Search attribute mappings (e.g. interleaved attributes) for buffer mapping.
* Not the name of the buffer might be the same as one of the interleaved attributes.
*/
function getAttributeFromAttributesList(bufferLayouts, name$1) {
	for (const bufferLayout of bufferLayouts) {
		let byteStride = bufferLayout.byteStride;
		if (typeof bufferLayout.byteStride !== "number") for (const attributeMapping$1 of bufferLayout.attributes || []) {
			const info = getVertexFormatInfo(attributeMapping$1.format);
			byteStride += info.byteLength;
		}
		const attributeMapping = bufferLayout.attributes?.find((mapping) => mapping.attribute === name$1);
		if (attributeMapping) return {
			attributeName: attributeMapping.attribute,
			bufferName: bufferLayout.name,
			stepMode: bufferLayout.stepMode,
			vertexFormat: attributeMapping.format,
			byteOffset: attributeMapping.byteOffset,
			byteStride
		};
	}
	return null;
}

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/resources/vertex-array.js
/**
* Stores attribute bindings.
* Makes it easy to share a render pipeline and use separate vertex arrays.
* @note On WebGL, VertexArray allows non-constant bindings to be performed in advance
* reducing the number of WebGL calls per draw call.
* @note On WebGPU this is just a convenience class that collects the bindings.
*/
var VertexArray = class VertexArray extends Resource {
	static defaultProps = {
		...Resource.defaultProps,
		shaderLayout: void 0,
		bufferLayout: []
	};
	get [Symbol.toStringTag]() {
		return "VertexArray";
	}
	/** Max number of vertex attributes */
	maxVertexAttributes;
	/** Attribute infos indexed by location - TODO only needed by webgl module? */
	attributeInfos;
	/** Index buffer */
	indexBuffer = null;
	/** Attributes indexed by buffer slot */
	attributes;
	constructor(device, props) {
		super(device, props, VertexArray.defaultProps);
		this.maxVertexAttributes = device.limits.maxVertexAttributes;
		this.attributes = new Array(this.maxVertexAttributes).fill(null);
		this.attributeInfos = getAttributeInfosByLocation(props.shaderLayout, props.bufferLayout, this.maxVertexAttributes);
	}
	/** @deprecated Set constant attributes (WebGL only) */
	setConstantWebGL(location, value) {
		this.device.reportError(/* @__PURE__ */ new Error("constant attributes not supported"), this)();
	}
};

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/resources/transform-feedback.js
/** Holds a set of output buffers for pipeline (WebGL only) */
var TransformFeedback = class TransformFeedback extends Resource {
	static defaultProps = {
		...Resource.defaultProps,
		layout: void 0,
		buffers: {}
	};
	get [Symbol.toStringTag]() {
		return "TransformFeedback";
	}
	constructor(device, props) {
		super(device, props, TransformFeedback.defaultProps);
	}
};

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/resources/query-set.js
/** Immutable QuerySet object */
var QuerySet = class QuerySet extends Resource {
	get [Symbol.toStringTag]() {
		return "QuerySet";
	}
	constructor(device, props) {
		super(device, props, QuerySet.defaultProps);
	}
	static defaultProps = {
		...Resource.defaultProps,
		type: void 0,
		count: void 0
	};
};

//#endregion
//#region node_modules/@luma.gl/core/dist/utils/array-utils-flat.js
var arrayBuffer;
function getScratchArrayBuffer(byteLength) {
	if (!arrayBuffer || arrayBuffer.byteLength < byteLength) arrayBuffer = new ArrayBuffer(byteLength);
	return arrayBuffer;
}
function getScratchArray(Type, length) {
	return new Type(getScratchArrayBuffer(Type.BYTES_PER_ELEMENT * length), 0, length);
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/context/parameters/webgl-parameter-tables.js
const GL_PARAMETER_DEFAULTS = {
	[3042]: false,
	[32773]: new Float32Array([
		0,
		0,
		0,
		0
	]),
	[32777]: 32774,
	[34877]: 32774,
	[32969]: 1,
	[32968]: 0,
	[32971]: 1,
	[32970]: 0,
	[3106]: new Float32Array([
		0,
		0,
		0,
		0
	]),
	[3107]: [
		true,
		true,
		true,
		true
	],
	[2884]: false,
	[2885]: 1029,
	[2929]: false,
	[2931]: 1,
	[2932]: 513,
	[2928]: new Float32Array([0, 1]),
	[2930]: true,
	[3024]: true,
	[35725]: null,
	[36006]: null,
	[36007]: null,
	[34229]: null,
	[34964]: null,
	[2886]: 2305,
	[33170]: 4352,
	[2849]: 1,
	[32823]: false,
	[32824]: 0,
	[10752]: 0,
	[32926]: false,
	[32928]: false,
	[32938]: 1,
	[32939]: false,
	[3089]: false,
	[3088]: new Int32Array([
		0,
		0,
		1024,
		1024
	]),
	[2960]: false,
	[2961]: 0,
	[2968]: 4294967295,
	[36005]: 4294967295,
	[2962]: 519,
	[2967]: 0,
	[2963]: 4294967295,
	[34816]: 519,
	[36003]: 0,
	[36004]: 4294967295,
	[2964]: 7680,
	[2965]: 7680,
	[2966]: 7680,
	[34817]: 7680,
	[34818]: 7680,
	[34819]: 7680,
	[2978]: [
		0,
		0,
		1024,
		1024
	],
	[36389]: null,
	[36662]: null,
	[36663]: null,
	[35053]: null,
	[35055]: null,
	[35723]: 4352,
	[36010]: null,
	[35977]: false,
	[3333]: 4,
	[3317]: 4,
	[37440]: false,
	[37441]: false,
	[37443]: 37444,
	[3330]: 0,
	[3332]: 0,
	[3331]: 0,
	[3314]: 0,
	[32878]: 0,
	[3316]: 0,
	[3315]: 0,
	[32877]: 0
};
var enable = (gl, value, key) => value ? gl.enable(key) : gl.disable(key);
var hint = (gl, value, key) => gl.hint(key, value);
var pixelStorei = (gl, value, key) => gl.pixelStorei(key, value);
var bindFramebuffer = (gl, value, key) => {
	const target$1 = key === 36006 ? 36009 : 36008;
	return gl.bindFramebuffer(target$1, value);
};
var bindBuffer = (gl, value, key) => {
	const glTarget = {
		[34964]: 34962,
		[36662]: 36662,
		[36663]: 36663,
		[35053]: 35051,
		[35055]: 35052
	}[key];
	gl.bindBuffer(glTarget, value);
};
function isArray$1(array) {
	return Array.isArray(array) || ArrayBuffer.isView(array) && !(array instanceof DataView);
}
const GL_PARAMETER_SETTERS = {
	[3042]: enable,
	[32773]: (gl, value) => gl.blendColor(...value),
	[32777]: "blendEquation",
	[34877]: "blendEquation",
	[32969]: "blendFunc",
	[32968]: "blendFunc",
	[32971]: "blendFunc",
	[32970]: "blendFunc",
	[3106]: (gl, value) => gl.clearColor(...value),
	[3107]: (gl, value) => gl.colorMask(...value),
	[2884]: enable,
	[2885]: (gl, value) => gl.cullFace(value),
	[2929]: enable,
	[2931]: (gl, value) => gl.clearDepth(value),
	[2932]: (gl, value) => gl.depthFunc(value),
	[2928]: (gl, value) => gl.depthRange(...value),
	[2930]: (gl, value) => gl.depthMask(value),
	[3024]: enable,
	[35723]: hint,
	[35725]: (gl, value) => gl.useProgram(value),
	[36007]: (gl, value) => gl.bindRenderbuffer(36161, value),
	[36389]: (gl, value) => gl.bindTransformFeedback?.(36386, value),
	[34229]: (gl, value) => gl.bindVertexArray(value),
	[36006]: bindFramebuffer,
	[36010]: bindFramebuffer,
	[34964]: bindBuffer,
	[36662]: bindBuffer,
	[36663]: bindBuffer,
	[35053]: bindBuffer,
	[35055]: bindBuffer,
	[2886]: (gl, value) => gl.frontFace(value),
	[33170]: hint,
	[2849]: (gl, value) => gl.lineWidth(value),
	[32823]: enable,
	[32824]: "polygonOffset",
	[10752]: "polygonOffset",
	[35977]: enable,
	[32926]: enable,
	[32928]: enable,
	[32938]: "sampleCoverage",
	[32939]: "sampleCoverage",
	[3089]: enable,
	[3088]: (gl, value) => gl.scissor(...value),
	[2960]: enable,
	[2961]: (gl, value) => gl.clearStencil(value),
	[2968]: (gl, value) => gl.stencilMaskSeparate(1028, value),
	[36005]: (gl, value) => gl.stencilMaskSeparate(1029, value),
	[2962]: "stencilFuncFront",
	[2967]: "stencilFuncFront",
	[2963]: "stencilFuncFront",
	[34816]: "stencilFuncBack",
	[36003]: "stencilFuncBack",
	[36004]: "stencilFuncBack",
	[2964]: "stencilOpFront",
	[2965]: "stencilOpFront",
	[2966]: "stencilOpFront",
	[34817]: "stencilOpBack",
	[34818]: "stencilOpBack",
	[34819]: "stencilOpBack",
	[2978]: (gl, value) => gl.viewport(...value),
	[34383]: enable,
	[10754]: enable,
	[12288]: enable,
	[12289]: enable,
	[12290]: enable,
	[12291]: enable,
	[12292]: enable,
	[12293]: enable,
	[12294]: enable,
	[12295]: enable,
	[3333]: pixelStorei,
	[3317]: pixelStorei,
	[37440]: pixelStorei,
	[37441]: pixelStorei,
	[37443]: pixelStorei,
	[3330]: pixelStorei,
	[3332]: pixelStorei,
	[3331]: pixelStorei,
	[3314]: pixelStorei,
	[32878]: pixelStorei,
	[3316]: pixelStorei,
	[3315]: pixelStorei,
	[32877]: pixelStorei,
	framebuffer: (gl, framebuffer) => {
		const handle = framebuffer && "handle" in framebuffer ? framebuffer.handle : framebuffer;
		return gl.bindFramebuffer(36160, handle);
	},
	blend: (gl, value) => value ? gl.enable(3042) : gl.disable(3042),
	blendColor: (gl, value) => gl.blendColor(...value),
	blendEquation: (gl, args) => {
		const separateModes = typeof args === "number" ? [args, args] : args;
		gl.blendEquationSeparate(...separateModes);
	},
	blendFunc: (gl, args) => {
		const separateFuncs = args?.length === 2 ? [...args, ...args] : args;
		gl.blendFuncSeparate(...separateFuncs);
	},
	clearColor: (gl, value) => gl.clearColor(...value),
	clearDepth: (gl, value) => gl.clearDepth(value),
	clearStencil: (gl, value) => gl.clearStencil(value),
	colorMask: (gl, value) => gl.colorMask(...value),
	cull: (gl, value) => value ? gl.enable(2884) : gl.disable(2884),
	cullFace: (gl, value) => gl.cullFace(value),
	depthTest: (gl, value) => value ? gl.enable(2929) : gl.disable(2929),
	depthFunc: (gl, value) => gl.depthFunc(value),
	depthMask: (gl, value) => gl.depthMask(value),
	depthRange: (gl, value) => gl.depthRange(...value),
	dither: (gl, value) => value ? gl.enable(3024) : gl.disable(3024),
	derivativeHint: (gl, value) => {
		gl.hint(35723, value);
	},
	frontFace: (gl, value) => gl.frontFace(value),
	mipmapHint: (gl, value) => gl.hint(33170, value),
	lineWidth: (gl, value) => gl.lineWidth(value),
	polygonOffsetFill: (gl, value) => value ? gl.enable(32823) : gl.disable(32823),
	polygonOffset: (gl, value) => gl.polygonOffset(...value),
	sampleCoverage: (gl, value) => gl.sampleCoverage(value[0], value[1] || false),
	scissorTest: (gl, value) => value ? gl.enable(3089) : gl.disable(3089),
	scissor: (gl, value) => gl.scissor(...value),
	stencilTest: (gl, value) => value ? gl.enable(2960) : gl.disable(2960),
	stencilMask: (gl, value) => {
		value = isArray$1(value) ? value : [value, value];
		const [mask, backMask] = value;
		gl.stencilMaskSeparate(1028, mask);
		gl.stencilMaskSeparate(1029, backMask);
	},
	stencilFunc: (gl, args) => {
		args = isArray$1(args) && args.length === 3 ? [...args, ...args] : args;
		const [func, ref, mask, backFunc, backRef, backMask] = args;
		gl.stencilFuncSeparate(1028, func, ref, mask);
		gl.stencilFuncSeparate(1029, backFunc, backRef, backMask);
	},
	stencilOp: (gl, args) => {
		args = isArray$1(args) && args.length === 3 ? [...args, ...args] : args;
		const [sfail, dpfail, dppass, backSfail, backDpfail, backDppass] = args;
		gl.stencilOpSeparate(1028, sfail, dpfail, dppass);
		gl.stencilOpSeparate(1029, backSfail, backDpfail, backDppass);
	},
	viewport: (gl, value) => gl.viewport(...value)
};
function getValue(glEnum, values, cache) {
	return values[glEnum] !== void 0 ? values[glEnum] : cache[glEnum];
}
const GL_COMPOSITE_PARAMETER_SETTERS = {
	blendEquation: (gl, values, cache) => gl.blendEquationSeparate(getValue(32777, values, cache), getValue(34877, values, cache)),
	blendFunc: (gl, values, cache) => gl.blendFuncSeparate(getValue(32969, values, cache), getValue(32968, values, cache), getValue(32971, values, cache), getValue(32970, values, cache)),
	polygonOffset: (gl, values, cache) => gl.polygonOffset(getValue(32824, values, cache), getValue(10752, values, cache)),
	sampleCoverage: (gl, values, cache) => gl.sampleCoverage(getValue(32938, values, cache), getValue(32939, values, cache)),
	stencilFuncFront: (gl, values, cache) => gl.stencilFuncSeparate(1028, getValue(2962, values, cache), getValue(2967, values, cache), getValue(2963, values, cache)),
	stencilFuncBack: (gl, values, cache) => gl.stencilFuncSeparate(1029, getValue(34816, values, cache), getValue(36003, values, cache), getValue(36004, values, cache)),
	stencilOpFront: (gl, values, cache) => gl.stencilOpSeparate(1028, getValue(2964, values, cache), getValue(2965, values, cache), getValue(2966, values, cache)),
	stencilOpBack: (gl, values, cache) => gl.stencilOpSeparate(1029, getValue(34817, values, cache), getValue(34818, values, cache), getValue(34819, values, cache))
};
const GL_HOOKED_SETTERS = {
	enable: (update, capability) => update({ [capability]: true }),
	disable: (update, capability) => update({ [capability]: false }),
	pixelStorei: (update, pname, value) => update({ [pname]: value }),
	hint: (update, pname, value) => update({ [pname]: value }),
	useProgram: (update, value) => update({ [35725]: value }),
	bindRenderbuffer: (update, target$1, value) => update({ [36007]: value }),
	bindTransformFeedback: (update, target$1, value) => update({ [36389]: value }),
	bindVertexArray: (update, value) => update({ [34229]: value }),
	bindFramebuffer: (update, target$1, framebuffer) => {
		switch (target$1) {
			case 36160: return update({
				[36006]: framebuffer,
				[36010]: framebuffer
			});
			case 36009: return update({ [36006]: framebuffer });
			case 36008: return update({ [36010]: framebuffer });
			default: return null;
		}
	},
	bindBuffer: (update, target$1, buffer) => {
		const pname = {
			[34962]: [34964],
			[36662]: [36662],
			[36663]: [36663],
			[35051]: [35053],
			[35052]: [35055]
		}[target$1];
		if (pname) return update({ [pname]: buffer });
		return { valueChanged: true };
	},
	blendColor: (update, r, g, b, a) => update({ [32773]: new Float32Array([
		r,
		g,
		b,
		a
	]) }),
	blendEquation: (update, mode) => update({
		[32777]: mode,
		[34877]: mode
	}),
	blendEquationSeparate: (update, modeRGB, modeAlpha) => update({
		[32777]: modeRGB,
		[34877]: modeAlpha
	}),
	blendFunc: (update, src, dst) => update({
		[32969]: src,
		[32968]: dst,
		[32971]: src,
		[32970]: dst
	}),
	blendFuncSeparate: (update, srcRGB, dstRGB, srcAlpha, dstAlpha) => update({
		[32969]: srcRGB,
		[32968]: dstRGB,
		[32971]: srcAlpha,
		[32970]: dstAlpha
	}),
	clearColor: (update, r, g, b, a) => update({ [3106]: new Float32Array([
		r,
		g,
		b,
		a
	]) }),
	clearDepth: (update, depth) => update({ [2931]: depth }),
	clearStencil: (update, s) => update({ [2961]: s }),
	colorMask: (update, r, g, b, a) => update({ [3107]: [
		r,
		g,
		b,
		a
	] }),
	cullFace: (update, mode) => update({ [2885]: mode }),
	depthFunc: (update, func) => update({ [2932]: func }),
	depthRange: (update, zNear, zFar) => update({ [2928]: new Float32Array([zNear, zFar]) }),
	depthMask: (update, mask) => update({ [2930]: mask }),
	frontFace: (update, face) => update({ [2886]: face }),
	lineWidth: (update, width) => update({ [2849]: width }),
	polygonOffset: (update, factor, units) => update({
		[32824]: factor,
		[10752]: units
	}),
	sampleCoverage: (update, value, invert) => update({
		[32938]: value,
		[32939]: invert
	}),
	scissor: (update, x, y, width, height) => update({ [3088]: new Int32Array([
		x,
		y,
		width,
		height
	]) }),
	stencilMask: (update, mask) => update({
		[2968]: mask,
		[36005]: mask
	}),
	stencilMaskSeparate: (update, face, mask) => update({ [face === 1028 ? 2968 : 36005]: mask }),
	stencilFunc: (update, func, ref, mask) => update({
		[2962]: func,
		[2967]: ref,
		[2963]: mask,
		[34816]: func,
		[36003]: ref,
		[36004]: mask
	}),
	stencilFuncSeparate: (update, face, func, ref, mask) => update({
		[face === 1028 ? 2962 : 34816]: func,
		[face === 1028 ? 2967 : 36003]: ref,
		[face === 1028 ? 2963 : 36004]: mask
	}),
	stencilOp: (update, fail, zfail, zpass) => update({
		[2964]: fail,
		[2965]: zfail,
		[2966]: zpass,
		[34817]: fail,
		[34818]: zfail,
		[34819]: zpass
	}),
	stencilOpSeparate: (update, face, fail, zfail, zpass) => update({
		[face === 1028 ? 2964 : 34817]: fail,
		[face === 1028 ? 2965 : 34818]: zfail,
		[face === 1028 ? 2966 : 34819]: zpass
	}),
	viewport: (update, x, y, width, height) => update({ [2978]: [
		x,
		y,
		width,
		height
	] })
};
var isEnabled = (gl, key) => gl.isEnabled(key);
const GL_PARAMETER_GETTERS = {
	[3042]: isEnabled,
	[2884]: isEnabled,
	[2929]: isEnabled,
	[3024]: isEnabled,
	[32823]: isEnabled,
	[32926]: isEnabled,
	[32928]: isEnabled,
	[3089]: isEnabled,
	[2960]: isEnabled,
	[35977]: isEnabled
};
const NON_CACHE_PARAMETERS = new Set([
	34016,
	36388,
	36387,
	35983,
	35368,
	34965,
	35739,
	35738,
	3074,
	34853,
	34854,
	34855,
	34856,
	34857,
	34858,
	34859,
	34860,
	34861,
	34862,
	34863,
	34864,
	34865,
	34866,
	34867,
	34868,
	35097,
	32873,
	35869,
	32874,
	34068
]);

//#endregion
//#region node_modules/@luma.gl/webgl/dist/context/parameters/unified-parameter-api.js
/**
* Sets any GL parameter regardless of function (gl.blendMode, ...)
*
* @note requires a `cache` object to be set on the context (gl.state.cache)
* This object is used to fill in any missing values for composite setter functions
*/
function setGLParameters(gl, parameters) {
	if (isObjectEmpty$2(parameters)) return;
	const compositeSetters = {};
	for (const key in parameters) {
		const glConstant = Number(key);
		const setter = GL_PARAMETER_SETTERS[key];
		if (setter) if (typeof setter === "string") compositeSetters[setter] = true;
		else setter(gl, parameters[key], glConstant);
	}
	const cache = gl.state && gl.state.cache;
	if (cache) for (const key in compositeSetters) {
		const compositeSetter = GL_COMPOSITE_PARAMETER_SETTERS[key];
		compositeSetter(gl, parameters, cache);
	}
}
/**
* Reads the entire WebGL state from a context

// default to querying all parameters

* @returns - a newly created map, with values keyed by GL parameters
*
* @note Copies the state from a context (gl.getParameter should not be overriden)
* Reads the entire WebGL state from a context
*
* @note This can generates a huge amount of synchronous driver roundtrips and should be
* considered a very slow operation, to be used only if/when a context already manipulated
* by external code needs to be synchronized for the first time
*/
function getGLParameters(gl, parameters = GL_PARAMETER_DEFAULTS) {
	if (typeof parameters === "number") {
		const key = parameters;
		const getter = GL_PARAMETER_GETTERS[key];
		return getter ? getter(gl, key) : gl.getParameter(key);
	}
	const parameterKeys = Array.isArray(parameters) ? parameters : Object.keys(parameters);
	const state = {};
	for (const key of parameterKeys) {
		const getter = GL_PARAMETER_GETTERS[key];
		state[key] = getter ? getter(gl, Number(key)) : gl.getParameter(Number(key));
	}
	return state;
}
/**
* Reset all parameters to a (almost) pure context state
* @note viewport and scissor will be set to the values in GL_PARAMETER_DEFAULTS,
* NOT the canvas size dimensions, so they will have to be properly set after
* calling this function.
*/
function resetGLParameters(gl) {
	setGLParameters(gl, GL_PARAMETER_DEFAULTS);
}
function isObjectEmpty$2(object) {
	for (const key in object) return false;
	return true;
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/context/state-tracker/deep-array-equal.js
/** deeply compare two arrays */
function deepArrayEqual(x, y) {
	if (x === y) return true;
	if (isArray(x) && isArray(y) && x.length === y.length) {
		for (let i = 0; i < x.length; ++i) if (x[i] !== y[i]) return false;
		return true;
	}
	return false;
}
function isArray(x) {
	return Array.isArray(x) || ArrayBuffer.isView(x);
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/context/state-tracker/webgl-state-tracker.js
/**
* Support for listening to context state changes and intercepting state queries
* NOTE: this system does not handle buffer bindings
*/
var WebGLStateTracker = class {
	static get(gl) {
		return gl.state;
	}
	gl;
	program = null;
	stateStack = [];
	enable = true;
	cache = null;
	log;
	initialized = false;
	constructor(gl, props) {
		this.gl = gl;
		this.log = props?.log || (() => {});
		this._updateCache = this._updateCache.bind(this);
		Object.seal(this);
	}
	push(values = {}) {
		this.stateStack.push({});
	}
	pop() {
		const oldValues = this.stateStack[this.stateStack.length - 1];
		setGLParameters(this.gl, oldValues);
		this.stateStack.pop();
	}
	/**
	* Initialize WebGL state caching on a context
	* can be called multiple times to enable/disable
	*
	* @note After calling this function, context state will be cached
	* .push() and .pop() will be available for saving,
	* temporarily modifying, and then restoring state.
	*/
	trackState(gl, options) {
		this.cache = options?.copyState ? getGLParameters(gl) : Object.assign({}, GL_PARAMETER_DEFAULTS);
		if (this.initialized) throw new Error("WebGLStateTracker");
		this.initialized = true;
		this.gl.state = this;
		installProgramSpy(gl);
		for (const key in GL_HOOKED_SETTERS) {
			const setter = GL_HOOKED_SETTERS[key];
			installSetterSpy(gl, key, setter);
		}
		installGetterOverride(gl, "getParameter");
		installGetterOverride(gl, "isEnabled");
	}
	/**
	// interceptor for context set functions - update our cache and our stack
	// values (Object) - the key values for this setter
	* @param values
	* @returns
	*/
	_updateCache(values) {
		let valueChanged = false;
		let oldValue;
		const oldValues = this.stateStack.length > 0 ? this.stateStack[this.stateStack.length - 1] : null;
		for (const key in values) {
			const value = values[key];
			const cached = this.cache[key];
			if (!deepArrayEqual(value, cached)) {
				valueChanged = true;
				oldValue = cached;
				if (oldValues && !(key in oldValues)) oldValues[key] = cached;
				this.cache[key] = value;
			}
		}
		return {
			valueChanged,
			oldValue
		};
	}
};
/**
// Overrides a WebGL2RenderingContext state "getter" function
// to return values directly from cache
* @param gl
* @param functionName
*/
function installGetterOverride(gl, functionName) {
	const originalGetterFunc = gl[functionName].bind(gl);
	gl[functionName] = function get(pname) {
		if (pname === void 0 || NON_CACHE_PARAMETERS.has(pname)) return originalGetterFunc(pname);
		const glState = WebGLStateTracker.get(gl);
		if (!(pname in glState.cache)) glState.cache[pname] = originalGetterFunc(pname);
		return glState.enable ? glState.cache[pname] : originalGetterFunc(pname);
	};
	Object.defineProperty(gl[functionName], "name", {
		value: `${functionName}-from-cache`,
		configurable: false
	});
}
/**
// Overrides a WebGL2RenderingContext state "setter" function
// to call a setter spy before the actual setter. Allows us to keep a cache
// updated with a copy of the WebGL context state.
* @param gl
* @param functionName
* @param setter
* @returns
*/
function installSetterSpy(gl, functionName, setter) {
	if (!gl[functionName]) return;
	const originalSetterFunc = gl[functionName].bind(gl);
	gl[functionName] = function set(...params) {
		const { valueChanged, oldValue } = setter(WebGLStateTracker.get(gl)._updateCache, ...params);
		if (valueChanged) originalSetterFunc(...params);
		return oldValue;
	};
	Object.defineProperty(gl[functionName], "name", {
		value: `${functionName}-to-cache`,
		configurable: false
	});
}
function installProgramSpy(gl) {
	const originalUseProgram = gl.useProgram.bind(gl);
	gl.useProgram = function useProgramLuma(handle) {
		const glState = WebGLStateTracker.get(gl);
		if (glState.program !== handle) {
			originalUseProgram(handle);
			glState.program = handle;
		}
	};
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/context/helpers/create-browser-context.js
/**
* Create a WebGL context for a canvas
* Note calling this multiple time on the same canvas does return the same context
* @param canvas A canvas element or offscreen canvas
*/
function createBrowserContext(canvas, props, webglContextAttributes) {
	let errorMessage = "";
	const webglProps = {
		preserveDrawingBuffer: true,
		...webglContextAttributes
	};
	let gl = null;
	gl ||= canvas.getContext("webgl2", webglProps);
	if (webglProps.failIfMajorPerformanceCaveat) errorMessage ||= "Only software GPU is available. Set `failIfMajorPerformanceCaveat: false` to allow.";
	if (!gl && !webglContextAttributes.failIfMajorPerformanceCaveat) {
		webglProps.failIfMajorPerformanceCaveat = false;
		gl = canvas.getContext("webgl2", webglProps);
		gl.luma ||= {};
		gl.luma.softwareRenderer = true;
	}
	if (!gl) {
		gl = canvas.getContext("webgl", {});
		if (gl) {
			gl = null;
			errorMessage ||= "Your browser only supports WebGL1";
		}
	}
	if (!gl) {
		errorMessage ||= "Your browser does not support WebGL";
		throw new Error(`Failed to create WebGL context: ${errorMessage}`);
	}
	const { onContextLost, onContextRestored } = props;
	canvas.addEventListener("webglcontextlost", (event) => onContextLost(event), false);
	canvas.addEventListener("webglcontextrestored", (event) => onContextRestored(event), false);
	gl.luma ||= {};
	return gl;
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/context/helpers/webgl-extensions.js
/** Ensure extensions are only requested once */
function getWebGLExtension(gl, name$1, extensions) {
	if (extensions[name$1] === void 0) extensions[name$1] = gl.getExtension(name$1) || null;
	return extensions[name$1];
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/device-helpers/webgl-device-info.js
/** @returns strings identifying the GPU vendor and driver. */
function getDeviceInfo(gl, extensions) {
	const vendorMasked = gl.getParameter(7936);
	const rendererMasked = gl.getParameter(7937);
	getWebGLExtension(gl, "WEBGL_debug_renderer_info", extensions);
	const ext = extensions.WEBGL_debug_renderer_info;
	const vendorUnmasked = gl.getParameter(ext ? ext.UNMASKED_VENDOR_WEBGL : 7936);
	const rendererUnmasked = gl.getParameter(ext ? ext.UNMASKED_RENDERER_WEBGL : 7937);
	const vendor = vendorUnmasked || vendorMasked;
	const renderer = rendererUnmasked || rendererMasked;
	const version = gl.getParameter(7938);
	const gpu = identifyGPUVendor(vendor, renderer);
	const gpuBackend = identifyGPUBackend(vendor, renderer);
	return {
		type: "webgl",
		gpu,
		gpuType: identifyGPUType(vendor, renderer),
		gpuBackend,
		vendor,
		renderer,
		version,
		shadingLanguage: "glsl",
		shadingLanguageVersion: 300
	};
}
/** "Sniff" the GPU type from the info. This works best if unmasked info is available. */
function identifyGPUVendor(vendor, renderer) {
	if (/NVIDIA/i.exec(vendor) || /NVIDIA/i.exec(renderer)) return "nvidia";
	if (/INTEL/i.exec(vendor) || /INTEL/i.exec(renderer)) return "intel";
	if (/Apple/i.exec(vendor) || /Apple/i.exec(renderer)) return "apple";
	if (/AMD/i.exec(vendor) || /AMD/i.exec(renderer) || /ATI/i.exec(vendor) || /ATI/i.exec(renderer)) return "amd";
	if (/SwiftShader/i.exec(vendor) || /SwiftShader/i.exec(renderer)) return "software";
	return "unknown";
}
/** "Sniff" the GPU backend from the info. This works best if unmasked info is available. */
function identifyGPUBackend(vendor, renderer) {
	if (/Metal/i.exec(vendor) || /Metal/i.exec(renderer)) return "metal";
	if (/ANGLE/i.exec(vendor) || /ANGLE/i.exec(renderer)) return "opengl";
	return "unknown";
}
function identifyGPUType(vendor, renderer) {
	if (/SwiftShader/i.exec(vendor) || /SwiftShader/i.exec(renderer)) return "cpu";
	switch (identifyGPUVendor(vendor, renderer)) {
		case "intel": return "integrated";
		case "software": return "cpu";
		case "unknown": return "unknown";
		default: return "discrete";
	}
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/converters/webgl-vertex-formats.js
function getGLFromVertexType(dataType) {
	switch (dataType) {
		case "uint8": return 5121;
		case "sint8": return 5120;
		case "unorm8": return 5121;
		case "snorm8": return 5120;
		case "uint16": return 5123;
		case "sint16": return 5122;
		case "unorm16": return 5123;
		case "snorm16": return 5122;
		case "uint32": return 5125;
		case "sint32": return 5124;
		case "float16": return 5131;
		case "float32": return 5126;
	}
	throw new Error(String(dataType));
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/converters/webgl-texture-table.js
var X_S3TC = "WEBGL_compressed_texture_s3tc";
var X_S3TC_SRGB = "WEBGL_compressed_texture_s3tc_srgb";
var X_RGTC = "EXT_texture_compression_rgtc";
var X_BPTC = "EXT_texture_compression_bptc";
var X_ETC2 = "WEBGL_compressed_texture_etc";
var X_ASTC = "WEBGL_compressed_texture_astc";
var X_ETC1 = "WEBGL_compressed_texture_etc1";
var X_PVRTC = "WEBGL_compressed_texture_pvrtc";
var X_ATC = "WEBGL_compressed_texture_atc";
var EXT_texture_norm16 = "EXT_texture_norm16";
var EXT_render_snorm = "EXT_render_snorm";
var EXT_color_buffer_float = "EXT_color_buffer_float";
const TEXTURE_FEATURES = {
	"float32-renderable-webgl": ["EXT_color_buffer_float"],
	"float16-renderable-webgl": ["EXT_color_buffer_half_float"],
	"rgb9e5ufloat-renderable-webgl": ["WEBGL_render_shared_exponent"],
	"snorm8-renderable-webgl": [EXT_render_snorm],
	"norm16-renderable-webgl": [EXT_texture_norm16],
	"snorm16-renderable-webgl": [EXT_texture_norm16, EXT_render_snorm],
	"float32-filterable": ["OES_texture_float_linear"],
	"float16-filterable-webgl": ["OES_texture_half_float_linear"],
	"texture-filterable-anisotropic-webgl": ["EXT_texture_filter_anisotropic"],
	"texture-blend-float-webgl": ["EXT_float_blend"],
	"texture-compression-bc": [
		X_S3TC,
		X_S3TC_SRGB,
		X_RGTC,
		X_BPTC
	],
	"texture-compression-bc5-webgl": [X_RGTC],
	"texture-compression-bc7-webgl": [X_BPTC],
	"texture-compression-etc2": [X_ETC2],
	"texture-compression-astc": [X_ASTC],
	"texture-compression-etc1-webgl": [X_ETC1],
	"texture-compression-pvrtc-webgl": [X_PVRTC],
	"texture-compression-atc-webgl": [X_ATC]
};
function isTextureFeature(feature) {
	return feature in TEXTURE_FEATURES;
}
/** Checks a texture feature (for Device.features). Mainly compressed texture support */
function checkTextureFeature(gl, feature, extensions) {
	return (TEXTURE_FEATURES[feature] || []).every((extension) => getWebGLExtension(gl, extension, extensions));
}
/**
* Texture format data -
* Exported but can change without notice
*/
const WEBGL_TEXTURE_FORMATS = {
	"r8unorm": {
		gl: 33321,
		rb: true
	},
	"r8snorm": { gl: 36756 },
	"r8uint": {
		gl: 33330,
		rb: true
	},
	"r8sint": {
		gl: 33329,
		rb: true
	},
	"rg8unorm": {
		gl: 33323,
		rb: true
	},
	"rg8snorm": { gl: 36757 },
	"rg8uint": {
		gl: 33336,
		rb: true
	},
	"rg8sint": {
		gl: 33335,
		rb: true
	},
	"r16uint": {
		gl: 33332,
		rb: true
	},
	"r16sint": {
		gl: 33331,
		rb: true
	},
	"r16float": {
		gl: 33325,
		rb: true
	},
	"r16unorm": {
		gl: 33322,
		rb: true
	},
	"r16snorm": { gl: 36760 },
	"rgba4unorm-webgl": {
		gl: 32854,
		rb: true
	},
	"rgb565unorm-webgl": {
		gl: 36194,
		rb: true
	},
	"rgb5a1unorm-webgl": {
		gl: 32855,
		rb: true
	},
	"rgb8unorm-webgl": { gl: 32849 },
	"rgb8snorm-webgl": { gl: 36758 },
	"rgba8unorm": { gl: 32856 },
	"rgba8unorm-srgb": { gl: 35907 },
	"rgba8snorm": { gl: 36759 },
	"rgba8uint": { gl: 36220 },
	"rgba8sint": { gl: 36238 },
	"bgra8unorm": {},
	"bgra8unorm-srgb": {},
	"rg16uint": { gl: 33338 },
	"rg16sint": { gl: 33337 },
	"rg16float": {
		gl: 33327,
		rb: true
	},
	"rg16unorm": { gl: 33324 },
	"rg16snorm": { gl: 36761 },
	"r32uint": {
		gl: 33334,
		rb: true
	},
	"r32sint": {
		gl: 33333,
		rb: true
	},
	"r32float": { gl: 33326 },
	"rgb9e5ufloat": { gl: 35901 },
	"rg11b10ufloat": {
		gl: 35898,
		rb: true
	},
	"rgb10a2unorm": {
		gl: 32857,
		rb: true
	},
	"rgb10a2uint": {
		gl: 36975,
		rb: true
	},
	"rgb16unorm-webgl": { gl: 32852 },
	"rgb16snorm-webgl": { gl: 36762 },
	"rg32uint": {
		gl: 33340,
		rb: true
	},
	"rg32sint": {
		gl: 33339,
		rb: true
	},
	"rg32float": {
		gl: 33328,
		rb: true
	},
	"rgba16uint": {
		gl: 36214,
		rb: true
	},
	"rgba16sint": {
		gl: 36232,
		rb: true
	},
	"rgba16float": { gl: 34842 },
	"rgba16unorm": {
		gl: 32859,
		rb: true
	},
	"rgba16snorm": { gl: 36763 },
	"rgb32float-webgl": {
		gl: 34837,
		x: EXT_color_buffer_float,
		dataFormat: 6407,
		types: [5126]
	},
	"rgba32uint": {
		gl: 36208,
		rb: true
	},
	"rgba32sint": {
		gl: 36226,
		rb: true
	},
	"rgba32float": {
		gl: 34836,
		rb: true
	},
	"stencil8": {
		gl: 36168,
		rb: true
	},
	"depth16unorm": {
		gl: 33189,
		dataFormat: 6402,
		types: [5123],
		rb: true
	},
	"depth24plus": {
		gl: 33190,
		dataFormat: 6402,
		types: [5125]
	},
	"depth32float": {
		gl: 36012,
		dataFormat: 6402,
		types: [5126],
		rb: true
	},
	"depth24plus-stencil8": {
		gl: 35056,
		rb: true,
		depthTexture: true,
		dataFormat: 34041,
		types: [34042]
	},
	"depth32float-stencil8": {
		gl: 36013,
		dataFormat: 34041,
		types: [36269],
		rb: true
	},
	"bc1-rgb-unorm-webgl": {
		gl: 33776,
		x: X_S3TC
	},
	"bc1-rgb-unorm-srgb-webgl": {
		gl: 35916,
		x: X_S3TC_SRGB
	},
	"bc1-rgba-unorm": {
		gl: 33777,
		x: X_S3TC
	},
	"bc1-rgba-unorm-srgb": {
		gl: 35916,
		x: X_S3TC_SRGB
	},
	"bc2-rgba-unorm": {
		gl: 33778,
		x: X_S3TC
	},
	"bc2-rgba-unorm-srgb": {
		gl: 35918,
		x: X_S3TC_SRGB
	},
	"bc3-rgba-unorm": {
		gl: 33779,
		x: X_S3TC
	},
	"bc3-rgba-unorm-srgb": {
		gl: 35919,
		x: X_S3TC_SRGB
	},
	"bc4-r-unorm": {
		gl: 36283,
		x: X_RGTC
	},
	"bc4-r-snorm": {
		gl: 36284,
		x: X_RGTC
	},
	"bc5-rg-unorm": {
		gl: 36285,
		x: X_RGTC
	},
	"bc5-rg-snorm": {
		gl: 36286,
		x: X_RGTC
	},
	"bc6h-rgb-ufloat": {
		gl: 36495,
		x: X_BPTC
	},
	"bc6h-rgb-float": {
		gl: 36494,
		x: X_BPTC
	},
	"bc7-rgba-unorm": {
		gl: 36492,
		x: X_BPTC
	},
	"bc7-rgba-unorm-srgb": {
		gl: 36493,
		x: X_BPTC
	},
	"etc2-rgb8unorm": { gl: 37492 },
	"etc2-rgb8unorm-srgb": { gl: 37494 },
	"etc2-rgb8a1unorm": { gl: 37496 },
	"etc2-rgb8a1unorm-srgb": { gl: 37497 },
	"etc2-rgba8unorm": { gl: 37493 },
	"etc2-rgba8unorm-srgb": { gl: 37495 },
	"eac-r11unorm": { gl: 37488 },
	"eac-r11snorm": { gl: 37489 },
	"eac-rg11unorm": { gl: 37490 },
	"eac-rg11snorm": { gl: 37491 },
	"astc-4x4-unorm": { gl: 37808 },
	"astc-4x4-unorm-srgb": { gl: 37840 },
	"astc-5x4-unorm": { gl: 37809 },
	"astc-5x4-unorm-srgb": { gl: 37841 },
	"astc-5x5-unorm": { gl: 37810 },
	"astc-5x5-unorm-srgb": { gl: 37842 },
	"astc-6x5-unorm": { gl: 37811 },
	"astc-6x5-unorm-srgb": { gl: 37843 },
	"astc-6x6-unorm": { gl: 37812 },
	"astc-6x6-unorm-srgb": { gl: 37844 },
	"astc-8x5-unorm": { gl: 37813 },
	"astc-8x5-unorm-srgb": { gl: 37845 },
	"astc-8x6-unorm": { gl: 37814 },
	"astc-8x6-unorm-srgb": { gl: 37846 },
	"astc-8x8-unorm": { gl: 37815 },
	"astc-8x8-unorm-srgb": { gl: 37847 },
	"astc-10x5-unorm": { gl: 37819 },
	"astc-10x5-unorm-srgb": { gl: 37851 },
	"astc-10x6-unorm": { gl: 37817 },
	"astc-10x6-unorm-srgb": { gl: 37849 },
	"astc-10x8-unorm": { gl: 37818 },
	"astc-10x8-unorm-srgb": { gl: 37850 },
	"astc-10x10-unorm": { gl: 37819 },
	"astc-10x10-unorm-srgb": { gl: 37851 },
	"astc-12x10-unorm": { gl: 37820 },
	"astc-12x10-unorm-srgb": { gl: 37852 },
	"astc-12x12-unorm": { gl: 37821 },
	"astc-12x12-unorm-srgb": { gl: 37853 },
	"pvrtc-rgb4unorm-webgl": { gl: 35840 },
	"pvrtc-rgba4unorm-webgl": { gl: 35842 },
	"pvrtc-rbg2unorm-webgl": { gl: 35841 },
	"pvrtc-rgba2unorm-webgl": { gl: 35843 },
	"etc1-rbg-unorm-webgl": { gl: 36196 },
	"atc-rgb-unorm-webgl": { gl: 35986 },
	"atc-rgba-unorm-webgl": { gl: 35986 },
	"atc-rgbai-unorm-webgl": { gl: 34798 }
};
/** Checks if a texture format is supported, renderable, filterable etc */
function getTextureFormatCapabilitiesWebGL(gl, formatSupport, extensions) {
	let supported = formatSupport.create;
	const webglFormatInfo = WEBGL_TEXTURE_FORMATS[formatSupport.format];
	if (webglFormatInfo?.gl === void 0) supported = false;
	if (webglFormatInfo?.x) supported = supported && Boolean(getWebGLExtension(gl, webglFormatInfo.x, extensions));
	return {
		format: formatSupport.format,
		create: supported && formatSupport.create,
		render: supported && formatSupport.render,
		filter: supported && formatSupport.filter,
		blend: supported && formatSupport.blend,
		store: supported && formatSupport.store
	};
}
/** Get parameters necessary to work with format in WebGL: internalFormat, dataFormat, type, compressed, */
function getTextureFormatWebGL(format) {
	const formatData = WEBGL_TEXTURE_FORMATS[format];
	const webglFormat = convertTextureFormatToGL(format);
	const decoded = textureFormatDecoder.getInfo(format);
	if (decoded.compressed) formatData.dataFormat = webglFormat;
	return {
		internalFormat: webglFormat,
		format: formatData?.dataFormat || getWebGLPixelDataFormat(decoded.channels, decoded.integer, decoded.normalized, webglFormat),
		type: decoded.dataType ? getGLFromVertexType(decoded.dataType) : formatData?.types?.[0] || 5121,
		compressed: decoded.compressed || false
	};
}
function getDepthStencilAttachmentWebGL(format) {
	switch (textureFormatDecoder.getInfo(format).attachment) {
		case "depth": return 36096;
		case "stencil": return 36128;
		case "depth-stencil": return 33306;
		default: throw new Error(`Not a depth stencil format: ${format}`);
	}
}
function getWebGLPixelDataFormat(channels, integer, normalized, format) {
	if (format === 6408 || format === 6407) return format;
	switch (channels) {
		case "r": return integer && !normalized ? 36244 : 6403;
		case "rg": return integer && !normalized ? 33320 : 33319;
		case "rgb": return integer && !normalized ? 36248 : 6407;
		case "rgba": return integer && !normalized ? 36249 : 6408;
		case "bgra": throw new Error("bgra pixels not supported by WebGL");
		default: return 6408;
	}
}
/**
* Map WebGPU style texture format strings to GL constants
*/
function convertTextureFormatToGL(format) {
	const webglFormat = WEBGL_TEXTURE_FORMATS[format]?.gl;
	if (webglFormat === void 0) throw new Error(`Unsupported texture format ${format}`);
	return webglFormat;
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/device-helpers/webgl-device-features.js
/**
* Defines luma.gl "feature" names and semantics
* when value is 'string' it is the name of the extension that enables this feature
*/
var WEBGL_FEATURES = {
	"depth-clip-control": "EXT_depth_clamp",
	"timer-query-webgl": "EXT_disjoint_timer_query_webgl2",
	"compilation-status-async-webgl": "KHR_parallel_shader_compile",
	"polygon-mode-webgl": "WEBGL_polygon_mode",
	"provoking-vertex-webgl": "WEBGL_provoking_vertex",
	"shader-clip-cull-distance-webgl": "WEBGL_clip_cull_distance",
	"shader-noperspective-interpolation-webgl": "NV_shader_noperspective_interpolation",
	"shader-conservative-depth-webgl": "EXT_conservative_depth"
};
/**
* WebGL extensions exposed as luma.gl features
* To minimize GL log noise and improve performance, this class ensures that
* - WebGL extensions are not queried until the corresponding feature is checked.
* - WebGL extensions are only queried once.
*/
var WebGLDeviceFeatures = class extends DeviceFeatures {
	gl;
	extensions;
	testedFeatures = /* @__PURE__ */ new Set();
	constructor(gl, extensions, disabledFeatures) {
		super([], disabledFeatures);
		this.gl = gl;
		this.extensions = extensions;
		getWebGLExtension(gl, "EXT_color_buffer_float", extensions);
	}
	*[Symbol.iterator]() {
		const features = this.getFeatures();
		for (const feature of features) if (this.has(feature)) yield feature;
		return [];
	}
	has(feature) {
		if (this.disabledFeatures?.[feature]) return false;
		if (!this.testedFeatures.has(feature)) {
			this.testedFeatures.add(feature);
			if (isTextureFeature(feature) && checkTextureFeature(this.gl, feature, this.extensions)) this.features.add(feature);
			if (this.getWebGLFeature(feature)) this.features.add(feature);
		}
		return this.features.has(feature);
	}
	initializeFeatures() {
		const features = this.getFeatures().filter((feature) => feature !== "polygon-mode-webgl");
		for (const feature of features) this.has(feature);
	}
	getFeatures() {
		return [...Object.keys(WEBGL_FEATURES), ...Object.keys(TEXTURE_FEATURES)];
	}
	/** Extract all WebGL features */
	getWebGLFeature(feature) {
		const featureInfo = WEBGL_FEATURES[feature];
		return typeof featureInfo === "string" ? Boolean(getWebGLExtension(this.gl, featureInfo, this.extensions)) : Boolean(featureInfo);
	}
};

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/device-helpers/webgl-device-limits.js
var WebGLDeviceLimits = class extends DeviceLimits {
	get maxTextureDimension1D() {
		return 0;
	}
	get maxTextureDimension2D() {
		return this.getParameter(3379);
	}
	get maxTextureDimension3D() {
		return this.getParameter(32883);
	}
	get maxTextureArrayLayers() {
		return this.getParameter(35071);
	}
	get maxBindGroups() {
		return 0;
	}
	get maxDynamicUniformBuffersPerPipelineLayout() {
		return 0;
	}
	get maxDynamicStorageBuffersPerPipelineLayout() {
		return 0;
	}
	get maxSampledTexturesPerShaderStage() {
		return this.getParameter(35660);
	}
	get maxSamplersPerShaderStage() {
		return this.getParameter(35661);
	}
	get maxStorageBuffersPerShaderStage() {
		return 0;
	}
	get maxStorageTexturesPerShaderStage() {
		return 0;
	}
	get maxUniformBuffersPerShaderStage() {
		return this.getParameter(35375);
	}
	get maxUniformBufferBindingSize() {
		return this.getParameter(35376);
	}
	get maxStorageBufferBindingSize() {
		return 0;
	}
	get minUniformBufferOffsetAlignment() {
		return this.getParameter(35380);
	}
	get minStorageBufferOffsetAlignment() {
		return 0;
	}
	get maxVertexBuffers() {
		return 16;
	}
	get maxVertexAttributes() {
		return this.getParameter(34921);
	}
	get maxVertexBufferArrayStride() {
		return 2048;
	}
	get maxInterStageShaderVariables() {
		return this.getParameter(35659);
	}
	get maxComputeWorkgroupStorageSize() {
		return 0;
	}
	get maxComputeInvocationsPerWorkgroup() {
		return 0;
	}
	get maxComputeWorkgroupSizeX() {
		return 0;
	}
	get maxComputeWorkgroupSizeY() {
		return 0;
	}
	get maxComputeWorkgroupSizeZ() {
		return 0;
	}
	get maxComputeWorkgroupsPerDimension() {
		return 0;
	}
	gl;
	limits = {};
	constructor(gl) {
		super();
		this.gl = gl;
	}
	getParameter(parameter) {
		if (this.limits[parameter] === void 0) this.limits[parameter] = this.gl.getParameter(parameter);
		return this.limits[parameter] || 0;
	}
};

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/resources/webgl-framebuffer.js
/** luma.gl Framebuffer, WebGL implementation  */
var WEBGLFramebuffer = class extends Framebuffer {
	device;
	gl;
	handle;
	colorAttachments = [];
	depthStencilAttachment = null;
	constructor(device, props) {
		super(device, props);
		const isDefaultFramebuffer = props.handle === null;
		this.device = device;
		this.gl = device.gl;
		this.handle = this.props.handle || isDefaultFramebuffer ? this.props.handle : this.gl.createFramebuffer();
		if (!isDefaultFramebuffer) {
			device._setWebGLDebugMetadata(this.handle, this, { spector: this.props });
			this.autoCreateAttachmentTextures();
			this.updateAttachments();
		}
	}
	/** destroys any auto created resources etc. */
	destroy() {
		super.destroy();
		if (!this.destroyed && this.handle !== null) this.gl.deleteFramebuffer(this.handle);
	}
	updateAttachments() {
		/** Attach from a map of attachments */
		const prevHandle = this.gl.bindFramebuffer(36160, this.handle);
		for (let i = 0; i < this.colorAttachments.length; ++i) {
			const attachment = this.colorAttachments[i];
			if (attachment) {
				const attachmentPoint = 36064 + i;
				this._attachTextureView(attachmentPoint, attachment);
			}
		}
		if (this.depthStencilAttachment) {
			const attachmentPoint = getDepthStencilAttachmentWebGL(this.depthStencilAttachment.props.format);
			this._attachTextureView(attachmentPoint, this.depthStencilAttachment);
		}
		/** Check the status */
		if (this.device.props.debug) {
			const status = this.gl.checkFramebufferStatus(36160);
			if (status !== 36053) throw new Error(`Framebuffer ${_getFrameBufferStatus(status)}`);
		}
		this.gl.bindFramebuffer(36160, prevHandle);
	}
	/** In WebGL we must use renderbuffers for depth/stencil attachments (unless we have extensions) */
	/**
	* @param attachment
	* @param texture
	* @param layer = 0 - index into WEBGLTextureArray and Texture3D or face for `TextureCubeMap`
	* @param level = 0 - mipmapLevel
	*/
	_attachTextureView(attachment, textureView) {
		const { gl } = this.device;
		const { texture } = textureView;
		const level = textureView.props.baseMipLevel;
		const layer = textureView.props.baseArrayLayer;
		gl.bindTexture(texture.glTarget, texture.handle);
		switch (texture.glTarget) {
			case 35866:
			case 32879:
				gl.framebufferTextureLayer(36160, attachment, texture.handle, level, layer);
				break;
			case 34067:
				const face = mapIndexToCubeMapFace(layer);
				gl.framebufferTexture2D(36160, attachment, face, texture.handle, level);
				break;
			case 3553:
				gl.framebufferTexture2D(36160, attachment, 3553, texture.handle, level);
				break;
			default: throw new Error("Illegal texture type");
		}
		gl.bindTexture(texture.glTarget, null);
	}
};
function mapIndexToCubeMapFace(layer) {
	return layer < 34069 ? layer + 34069 : layer;
}
function _getFrameBufferStatus(status) {
	switch (status) {
		case 36053: return "success";
		case 36054: return "Mismatched attachments";
		case 36055: return "No attachments";
		case 36057: return "Height/width mismatch";
		case 36061: return "Unsupported or split attachments";
		case 36182: return "Samples mismatch";
		default: return `${status}`;
	}
}
/**
* Attachment resize is expected to be a noop if size is same
*
protected override resizeAttachments(width: number, height: number): this {
// for default framebuffer, just update the stored size
if (this.handle === null) {
// assert(width === undefined && height === undefined);
this.width = this.gl.drawingBufferWidth;
this.height = this.gl.drawingBufferHeight;
return this;
}

if (width === undefined) {
width = this.gl.drawingBufferWidth;
}
if (height === undefined) {
height = this.gl.drawingBufferHeight;
}

// TODO Not clear that this is better than default destroy/create implementation

for (const colorAttachment of this.colorAttachments) {
colorAttachment.texture.clone({width, height});
}
if (this.depthStencilAttachment) {
this.depthStencilAttachment.texture.resize({width, height});
}
return this;
}
*/

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/webgl-canvas-context.js
/**
* A WebGL Canvas Context which manages the canvas and handles drawing buffer resizing etc
*/
var WebGLCanvasContext = class extends CanvasContext {
	device;
	handle = null;
	_framebuffer = null;
	get [Symbol.toStringTag]() {
		return "WebGLCanvasContext";
	}
	constructor(device, props) {
		super(props);
		this.device = device;
		this._setAutoCreatedCanvasId(`${this.device.id}-canvas`);
		this._updateDevice();
	}
	getCurrentFramebuffer() {
		this._framebuffer = this._framebuffer || new WEBGLFramebuffer(this.device, { handle: null });
		return this._framebuffer;
	}
	_updateDevice() {}
};

//#endregion
//#region node_modules/@luma.gl/webgl/dist/utils/uid.js
var uidCounters = {};
/**
* Returns a UID.
* @param id= - Identifier base name
* @return uid
**/
function uid(id = "id") {
	uidCounters[id] = uidCounters[id] || 1;
	return `${id}-${uidCounters[id]++}`;
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/resources/webgl-buffer.js
/** WebGL Buffer interface */
var WEBGLBuffer = class extends Buffer {
	device;
	gl;
	handle;
	/** Target in OpenGL defines the type of buffer */
	glTarget;
	/** Usage is a hint on how frequently the buffer will be updates */
	glUsage;
	/** Index type is needed when issuing draw calls, so we pre-compute it */
	glIndexType = 5123;
	/** Number of bytes allocated on the GPU for this buffer */
	byteLength = 0;
	/** Number of bytes used */
	bytesUsed = 0;
	constructor(device, props = {}) {
		super(device, props);
		this.device = device;
		this.gl = this.device.gl;
		this.handle = (typeof props === "object" ? props.handle : void 0) || this.gl.createBuffer();
		device._setWebGLDebugMetadata(this.handle, this, { spector: {
			...this.props,
			data: typeof this.props.data
		} });
		this.glTarget = getWebGLTarget(this.props.usage);
		this.glUsage = getWebGLUsage(this.props.usage);
		this.glIndexType = this.props.indexType === "uint32" ? 5125 : 5123;
		if (props.data) this._initWithData(props.data, props.byteOffset, props.byteLength);
		else this._initWithByteLength(props.byteLength || 0);
	}
	destroy() {
		if (!this.destroyed && this.handle) {
			this.removeStats();
			this.trackDeallocatedMemory();
			this.gl.deleteBuffer(this.handle);
			this.destroyed = true;
			this.handle = null;
		}
	}
	/** Allocate a new buffer and initialize to contents of typed array */
	_initWithData(data, byteOffset = 0, byteLength = data.byteLength + byteOffset) {
		const glTarget = this.glTarget;
		this.gl.bindBuffer(glTarget, this.handle);
		this.gl.bufferData(glTarget, byteLength, this.glUsage);
		this.gl.bufferSubData(glTarget, byteOffset, data);
		this.gl.bindBuffer(glTarget, null);
		this.bytesUsed = byteLength;
		this.byteLength = byteLength;
		this._setDebugData(data, byteOffset, byteLength);
		this.trackAllocatedMemory(byteLength);
	}
	_initWithByteLength(byteLength) {
		let data = byteLength;
		if (byteLength === 0) data = new Float32Array(0);
		const glTarget = this.glTarget;
		this.gl.bindBuffer(glTarget, this.handle);
		this.gl.bufferData(glTarget, data, this.glUsage);
		this.gl.bindBuffer(glTarget, null);
		this.bytesUsed = byteLength;
		this.byteLength = byteLength;
		this._setDebugData(null, 0, byteLength);
		this.trackAllocatedMemory(byteLength);
		return this;
	}
	write(data, byteOffset = 0) {
		const dataView = ArrayBuffer.isView(data) ? data : new Uint8Array(data);
		const srcOffset = 0;
		const byteLength = void 0;
		const glTarget = 36663;
		this.gl.bindBuffer(glTarget, this.handle);
		if (srcOffset !== 0 || byteLength !== void 0) this.gl.bufferSubData(glTarget, byteOffset, dataView, srcOffset, byteLength);
		else this.gl.bufferSubData(glTarget, byteOffset, dataView);
		this.gl.bindBuffer(glTarget, null);
		this._setDebugData(data, byteOffset, data.byteLength);
	}
	async mapAndWriteAsync(callback, byteOffset = 0, byteLength = this.byteLength - byteOffset) {
		const arrayBuffer$1 = new ArrayBuffer(byteLength);
		await callback(arrayBuffer$1, "copied");
		this.write(arrayBuffer$1, byteOffset);
	}
	async readAsync(byteOffset = 0, byteLength) {
		return this.readSyncWebGL(byteOffset, byteLength);
	}
	async mapAndReadAsync(callback, byteOffset = 0, byteLength) {
		return await callback((await this.readAsync(byteOffset, byteLength)).buffer, "copied");
	}
	readSyncWebGL(byteOffset = 0, byteLength) {
		byteLength = byteLength ?? this.byteLength - byteOffset;
		const data = new Uint8Array(byteLength);
		const dstOffset = 0;
		this.gl.bindBuffer(36662, this.handle);
		this.gl.getBufferSubData(36662, byteOffset, data, dstOffset, byteLength);
		this.gl.bindBuffer(36662, null);
		this._setDebugData(data, byteOffset, byteLength);
		return data;
	}
};
/**
* Returns a WebGL buffer target
*
* @param usage
* static MAP_READ = 0x01;
* static MAP_WRITE = 0x02;
* static COPY_SRC = 0x0004;
* static COPY_DST = 0x0008;
* static INDEX = 0x0010;
* static VERTEX = 0x0020;
* static UNIFORM = 0x0040;
* static STORAGE = 0x0080;
* static INDIRECT = 0x0100;
* static QUERY_RESOLVE = 0x0200;
*
* @returns WebGL buffer targe
*
* Buffer bind points in WebGL2
* gl.COPY_READ_BUFFER: Buffer for copying from one buffer object to another.
* gl.COPY_WRITE_BUFFER: Buffer for copying from one buffer object to another.
* gl.TRANSFORM_FEEDBACK_BUFFER: Buffer for transform feedback operations.
* gl.PIXEL_PACK_BUFFER: Buffer used for pixel transfer operations.
* gl.PIXEL_UNPACK_BUFFER: Buffer used for pixel transfer operations.
*/
function getWebGLTarget(usage) {
	if (usage & Buffer.INDEX) return 34963;
	if (usage & Buffer.VERTEX) return 34962;
	if (usage & Buffer.UNIFORM) return 35345;
	return 34962;
}
/** @todo usage is not passed correctly */
function getWebGLUsage(usage) {
	if (usage & Buffer.INDEX) return 35044;
	if (usage & Buffer.VERTEX) return 35044;
	if (usage & Buffer.UNIFORM) return 35048;
	return 35044;
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/helpers/parse-shader-compiler-log.js
/**
* Parse a WebGL-format GLSL compilation log into an array of WebGPU style message records.
* This follows documented WebGL conventions for compilation logs.
* Based on https://github.com/wwwtyro/gl-format-compiler-error (public domain)
*/
function parseShaderCompilerLog(errLog) {
	const lines = errLog.split(/\r?\n/);
	const messages = [];
	for (const line of lines) {
		if (line.length <= 1) continue;
		const segments = line.split(":");
		if (segments.length === 2) {
			const [messageType$1, message$1] = segments;
			messages.push({
				message: message$1.trim(),
				type: getMessageType(messageType$1),
				lineNum: 0,
				linePos: 0
			});
			continue;
		}
		const [messageType, linePosition, lineNumber, ...rest] = segments;
		let lineNum = parseInt(lineNumber, 10);
		if (isNaN(lineNum)) lineNum = 0;
		let linePos = parseInt(linePosition, 10);
		if (isNaN(linePos)) linePos = 0;
		messages.push({
			message: rest.join(":").trim(),
			type: getMessageType(messageType),
			lineNum,
			linePos
		});
	}
	return messages;
}
/** Ensure supported type */
function getMessageType(messageType) {
	const MESSAGE_TYPES = [
		"warning",
		"error",
		"info"
	];
	const lowerCaseType = messageType.toLowerCase();
	return MESSAGE_TYPES.includes(lowerCaseType) ? lowerCaseType : "info";
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/resources/webgl-shader.js
/**
* An immutable compiled shader program that execute portions of the GPU Pipeline
*/
var WEBGLShader = class extends Shader {
	device;
	handle;
	constructor(device, props) {
		super(device, props);
		this.device = device;
		switch (this.props.stage) {
			case "vertex":
				this.handle = this.props.handle || this.device.gl.createShader(35633);
				break;
			case "fragment":
				this.handle = this.props.handle || this.device.gl.createShader(35632);
				break;
			default: throw new Error(this.props.stage);
		}
		device._setWebGLDebugMetadata(this.handle, this, { spector: this.props });
		this._compile(this.source);
	}
	destroy() {
		if (this.handle) {
			this.removeStats();
			this.device.gl.deleteShader(this.handle);
			this.destroyed = true;
			this.handle.destroyed = true;
		}
	}
	get asyncCompilationStatus() {
		return this._waitForCompilationComplete().then(() => {
			this._getCompilationStatus();
			return this.compilationStatus;
		});
	}
	async getCompilationInfo() {
		await this._waitForCompilationComplete();
		return this.getCompilationInfoSync();
	}
	getCompilationInfoSync() {
		const shaderLog = this.device.gl.getShaderInfoLog(this.handle);
		return shaderLog ? parseShaderCompilerLog(shaderLog) : [];
	}
	getTranslatedSource() {
		return this.device.getExtension("WEBGL_debug_shaders").WEBGL_debug_shaders?.getTranslatedShaderSource(this.handle) || null;
	}
	/** Compile a shader and get compilation status */
	async _compile(source) {
		source = source.startsWith("#version ") ? source : `#version 300 es\n${source}`;
		const { gl } = this.device;
		gl.shaderSource(this.handle, source);
		gl.compileShader(this.handle);
		if (!this.device.props.debug) {
			this.compilationStatus = "pending";
			return;
		}
		if (!this.device.features.has("compilation-status-async-webgl")) {
			this._getCompilationStatus();
			this.debugShader();
			if (this.compilationStatus === "error") throw new Error(`GLSL compilation errors in ${this.props.stage} shader ${this.props.id}`);
			return;
		}
		log.once(1, "Shader compilation is asynchronous")();
		await this._waitForCompilationComplete();
		log.info(2, `Shader ${this.id} - async compilation complete: ${this.compilationStatus}`)();
		this._getCompilationStatus();
		this.debugShader();
	}
	/** Use KHR_parallel_shader_compile extension if available */
	async _waitForCompilationComplete() {
		const waitMs = async (ms) => await new Promise((resolve) => setTimeout(resolve, ms));
		const DELAY_MS = 10;
		if (!this.device.features.has("compilation-status-async-webgl")) {
			await waitMs(DELAY_MS);
			return;
		}
		const { gl } = this.device;
		for (;;) {
			if (gl.getShaderParameter(this.handle, 37297)) return;
			await waitMs(DELAY_MS);
		}
	}
	/**
	* Get the shader compilation status
	* TODO - Load log even when no error reported, to catch warnings?
	* https://gamedev.stackexchange.com/questions/30429/how-to-detect-glsl-warnings
	*/
	_getCompilationStatus() {
		this.compilationStatus = this.device.gl.getShaderParameter(this.handle, 35713) ? "success" : "error";
	}
};

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/converters/device-parameters.js
/**
* Execute a function with a set of temporary WebGL parameter overrides
* - Saves current "global" WebGL context settings
* - Sets the supplies WebGL context parameters,
* - Executes supplied function
* - Restores parameters
* - Returns the return value of the supplied function
*/
function withDeviceAndGLParameters(device, parameters, glParameters, func) {
	if (isObjectEmpty$1(parameters)) return func(device);
	const webglDevice = device;
	webglDevice.pushState();
	try {
		setDeviceParameters(device, parameters);
		setGLParameters(webglDevice.gl, glParameters);
		return func(device);
	} finally {
		webglDevice.popState();
	}
}
/** Set WebGPU Style Parameters */
function setDeviceParameters(device, parameters) {
	const webglDevice = device;
	const { gl } = webglDevice;
	if (parameters.cullMode) switch (parameters.cullMode) {
		case "none":
			gl.disable(2884);
			break;
		case "front":
			gl.enable(2884);
			gl.cullFace(1028);
			break;
		case "back":
			gl.enable(2884);
			gl.cullFace(1029);
			break;
	}
	if (parameters.frontFace) gl.frontFace(map("frontFace", parameters.frontFace, {
		ccw: 2305,
		cw: 2304
	}));
	if (parameters.unclippedDepth) {
		if (device.features.has("depth-clip-control")) gl.enable(34383);
	}
	if (parameters.depthBias !== void 0) {
		gl.enable(32823);
		gl.polygonOffset(parameters.depthBias, parameters.depthBiasSlopeScale || 0);
	}
	if (parameters.provokingVertex) {
		if (device.features.has("provoking-vertex-webgl")) {
			const ext = webglDevice.getExtension("WEBGL_provoking_vertex").WEBGL_provoking_vertex;
			const vertex = map("provokingVertex", parameters.provokingVertex, {
				first: 36429,
				last: 36430
			});
			ext?.provokingVertexWEBGL(vertex);
		}
	}
	if (parameters.polygonMode || parameters.polygonOffsetLine) {
		if (device.features.has("polygon-mode-webgl")) {
			if (parameters.polygonMode) {
				const ext = webglDevice.getExtension("WEBGL_polygon_mode").WEBGL_polygon_mode;
				const mode = map("polygonMode", parameters.polygonMode, {
					fill: 6914,
					line: 6913
				});
				ext?.polygonModeWEBGL(1028, mode);
				ext?.polygonModeWEBGL(1029, mode);
			}
			if (parameters.polygonOffsetLine) gl.enable(10754);
		}
	}
	if (device.features.has("shader-clip-cull-distance-webgl")) {
		if (parameters.clipDistance0) gl.enable(12288);
		if (parameters.clipDistance1) gl.enable(12289);
		if (parameters.clipDistance2) gl.enable(12290);
		if (parameters.clipDistance3) gl.enable(12291);
		if (parameters.clipDistance4) gl.enable(12292);
		if (parameters.clipDistance5) gl.enable(12293);
		if (parameters.clipDistance6) gl.enable(12294);
		if (parameters.clipDistance7) gl.enable(12295);
	}
	if (parameters.depthWriteEnabled !== void 0) gl.depthMask(mapBoolean("depthWriteEnabled", parameters.depthWriteEnabled));
	if (parameters.depthCompare) {
		parameters.depthCompare !== "always" ? gl.enable(2929) : gl.disable(2929);
		gl.depthFunc(convertCompareFunction("depthCompare", parameters.depthCompare));
	}
	if (parameters.stencilWriteMask) {
		const mask = parameters.stencilWriteMask;
		gl.stencilMaskSeparate(1028, mask);
		gl.stencilMaskSeparate(1029, mask);
	}
	if (parameters.stencilReadMask) log.warn("stencilReadMask not supported under WebGL");
	if (parameters.stencilCompare) {
		const mask = parameters.stencilReadMask || 4294967295;
		const glValue = convertCompareFunction("depthCompare", parameters.stencilCompare);
		parameters.stencilCompare !== "always" ? gl.enable(2960) : gl.disable(2960);
		gl.stencilFuncSeparate(1028, glValue, 0, mask);
		gl.stencilFuncSeparate(1029, glValue, 0, mask);
	}
	if (parameters.stencilPassOperation && parameters.stencilFailOperation && parameters.stencilDepthFailOperation) {
		const dppass = convertStencilOperation("stencilPassOperation", parameters.stencilPassOperation);
		const sfail = convertStencilOperation("stencilFailOperation", parameters.stencilFailOperation);
		const dpfail = convertStencilOperation("stencilDepthFailOperation", parameters.stencilDepthFailOperation);
		gl.stencilOpSeparate(1028, sfail, dpfail, dppass);
		gl.stencilOpSeparate(1029, sfail, dpfail, dppass);
	}
	switch (parameters.blend) {
		case true:
			gl.enable(3042);
			break;
		case false:
			gl.disable(3042);
			break;
		default:
	}
	if (parameters.blendColorOperation || parameters.blendAlphaOperation) {
		const colorEquation = convertBlendOperationToEquation("blendColorOperation", parameters.blendColorOperation || "add");
		const alphaEquation = convertBlendOperationToEquation("blendAlphaOperation", parameters.blendAlphaOperation || "add");
		gl.blendEquationSeparate(colorEquation, alphaEquation);
		const colorSrcFactor = convertBlendFactorToFunction("blendColorSrcFactor", parameters.blendColorSrcFactor || "one");
		const colorDstFactor = convertBlendFactorToFunction("blendColorDstFactor", parameters.blendColorDstFactor || "zero");
		const alphaSrcFactor = convertBlendFactorToFunction("blendAlphaSrcFactor", parameters.blendAlphaSrcFactor || "one");
		const alphaDstFactor = convertBlendFactorToFunction("blendAlphaDstFactor", parameters.blendAlphaDstFactor || "zero");
		gl.blendFuncSeparate(colorSrcFactor, colorDstFactor, alphaSrcFactor, alphaDstFactor);
	}
}
function convertCompareFunction(parameter, value) {
	return map(parameter, value, {
		never: 512,
		less: 513,
		equal: 514,
		"less-equal": 515,
		greater: 516,
		"not-equal": 517,
		"greater-equal": 518,
		always: 519
	});
}
function convertStencilOperation(parameter, value) {
	return map(parameter, value, {
		keep: 7680,
		zero: 0,
		replace: 7681,
		invert: 5386,
		"increment-clamp": 7682,
		"decrement-clamp": 7683,
		"increment-wrap": 34055,
		"decrement-wrap": 34056
	});
}
function convertBlendOperationToEquation(parameter, value) {
	return map(parameter, value, {
		add: 32774,
		subtract: 32778,
		"reverse-subtract": 32779,
		min: 32775,
		max: 32776
	});
}
function convertBlendFactorToFunction(parameter, value, type = "color") {
	return map(parameter, value, {
		one: 1,
		zero: 0,
		src: 768,
		"one-minus-src": 769,
		dst: 774,
		"one-minus-dst": 775,
		"src-alpha": 770,
		"one-minus-src-alpha": 771,
		"dst-alpha": 772,
		"one-minus-dst-alpha": 773,
		"src-alpha-saturated": 776,
		constant: type === "color" ? 32769 : 32771,
		"one-minus-constant": type === "color" ? 32770 : 32772,
		src1: 768,
		"one-minus-src1": 769,
		"src1-alpha": 770,
		"one-minus-src1-alpha": 771
	});
}
function message(parameter, value) {
	return `Illegal parameter ${value} for ${parameter}`;
}
function map(parameter, value, valueMap) {
	if (!(value in valueMap)) throw new Error(message(parameter, value));
	return valueMap[value];
}
function mapBoolean(parameter, value) {
	return value;
}
/** Returns true if given object is empty, false otherwise. */
function isObjectEmpty$1(obj) {
	let isEmpty = true;
	for (const key in obj) {
		isEmpty = false;
		break;
	}
	return isEmpty;
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/converters/sampler-parameters.js
/**
* Convert WebGPU-style sampler props to WebGL
* @param props
* @returns
*/
function convertSamplerParametersToWebGL(props) {
	const params = {};
	if (props.addressModeU) params[10242] = convertAddressMode(props.addressModeU);
	if (props.addressModeV) params[10243] = convertAddressMode(props.addressModeV);
	if (props.addressModeW) params[32882] = convertAddressMode(props.addressModeW);
	if (props.magFilter) params[10240] = convertMaxFilterMode(props.magFilter);
	if (props.minFilter || props.mipmapFilter) params[10241] = convertMinFilterMode(props.minFilter || "linear", props.mipmapFilter);
	if (props.lodMinClamp !== void 0) params[33082] = props.lodMinClamp;
	if (props.lodMaxClamp !== void 0) params[33083] = props.lodMaxClamp;
	if (props.type === "comparison-sampler") params[34892] = 34894;
	if (props.compare) params[34893] = convertCompareFunction("compare", props.compare);
	if (props.maxAnisotropy) params[34046] = props.maxAnisotropy;
	return params;
}
/** Convert address more */
function convertAddressMode(addressMode) {
	switch (addressMode) {
		case "clamp-to-edge": return 33071;
		case "repeat": return 10497;
		case "mirror-repeat": return 33648;
	}
}
function convertMaxFilterMode(maxFilter) {
	switch (maxFilter) {
		case "nearest": return 9728;
		case "linear": return 9729;
	}
}
/**
* WebGPU has separate min filter and mipmap filter,
* WebGL is combined and effectively offers 6 options
*/
function convertMinFilterMode(minFilter, mipmapFilter = "none") {
	if (!mipmapFilter) return convertMaxFilterMode(minFilter);
	switch (mipmapFilter) {
		case "none": return convertMaxFilterMode(minFilter);
		case "nearest":
			switch (minFilter) {
				case "nearest": return 9984;
				case "linear": return 9985;
			}
			break;
		case "linear": switch (minFilter) {
			case "nearest": return 9986;
			case "linear": return 9987;
		}
	}
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/resources/webgl-sampler.js
/**
* Sampler object -
* so that they can be set directly on the texture
* https://github.com/WebGLSamples/WebGL2Samples/blob/master/samples/sampler_object.html
*/
var WEBGLSampler = class extends Sampler {
	device;
	handle;
	parameters;
	constructor(device, props) {
		super(device, props);
		this.device = device;
		this.parameters = convertSamplerParametersToWebGL(props);
		this.handle = props.handle || this.device.gl.createSampler();
		this._setSamplerParameters(this.parameters);
	}
	destroy() {
		if (this.handle) {
			this.device.gl.deleteSampler(this.handle);
			this.handle = void 0;
		}
	}
	toString() {
		return `Sampler(${this.id},${JSON.stringify(this.props)})`;
	}
	/** Set sampler parameters on the sampler */
	_setSamplerParameters(parameters) {
		for (const [pname, value] of Object.entries(parameters)) {
			const param = Number(pname);
			switch (param) {
				case 33082:
				case 33083:
					this.device.gl.samplerParameterf(this.handle, param, value);
					break;
				default:
					this.device.gl.samplerParameteri(this.handle, param, value);
					break;
			}
		}
	}
};

//#endregion
//#region node_modules/@luma.gl/webgl/dist/context/state-tracker/with-parameters.js
/**
* Execute a function with a set of temporary WebGL parameter overrides
* - Saves current "global" WebGL context settings
* - Sets the supplies WebGL context parameters,
* - Executes supplied function
* - Restores parameters
* - Returns the return value of the supplied function
*/
function withGLParameters(gl, parameters, func) {
	if (isObjectEmpty(parameters)) return func(gl);
	const { nocatch = true } = parameters;
	const webglState = WebGLStateTracker.get(gl);
	webglState.push();
	setGLParameters(gl, parameters);
	let value;
	if (nocatch) {
		value = func(gl);
		webglState.pop();
	} else try {
		value = func(gl);
	} finally {
		webglState.pop();
	}
	return value;
}
function isObjectEmpty(object) {
	for (const key in object) return false;
	return true;
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/resources/webgl-texture-view.js
var WEBGLTextureView = class extends TextureView {
	device;
	gl;
	handle;
	texture;
	constructor(device, props) {
		super(device, {
			...Texture.defaultProps,
			...props
		});
		this.device = device;
		this.gl = this.device.gl;
		this.handle = null;
		this.texture = props.texture;
	}
};

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/resources/webgl-texture.js
/**
* WebGL... the texture API from hell... hopefully made simpler
*/
var WEBGLTexture = class extends Texture {
	device;
	gl;
	handle;
	sampler = void 0;
	view;
	/**
	* The WebGL target corresponding to the texture type
	* @note `target` cannot be modified by bind:
	* textures are special because when you first bind them to a target,
	* When you first bind a texture as a GL_TEXTURE_2D, you are saying that this texture is a 2D texture.
	* And it will always be a 2D texture; this state cannot be changed ever.
	* A texture that was first bound as a GL_TEXTURE_2D, must always be bound as a GL_TEXTURE_2D;
	* attempting to bind it as GL_TEXTURE_3D will give rise to a run-time error
	*/
	glTarget;
	/** The WebGL format - essentially channel structure */
	glFormat;
	/** The WebGL data format - the type of each channel */
	glType;
	/** The WebGL constant corresponding to the WebGPU style constant in format */
	glInternalFormat;
	/** Whether the internal format is compressed */
	compressed;
	/** Texture binding slot - TODO - move to texture view? */
	_textureUnit = 0;
	constructor(device, props) {
		super(device, props);
		this.device = device;
		this.gl = this.device.gl;
		const formatInfo = getTextureFormatWebGL(this.props.format);
		this.glTarget = getWebGLTextureTarget(this.props.dimension);
		this.glInternalFormat = formatInfo.internalFormat;
		this.glFormat = formatInfo.format;
		this.glType = formatInfo.type;
		this.compressed = formatInfo.compressed;
		this.handle = this.props.handle || this.gl.createTexture();
		this.device._setWebGLDebugMetadata(this.handle, this, { spector: this.props });
		/**
		* Use WebGL immutable texture storage to allocate and clear texture memory.
		* - texStorage2D should be considered a preferred alternative to texImage2D. It may have lower memory costs than texImage2D in some implementations.
		* - Once texStorage*D has been called, the texture is immutable and can only be updated with texSubImage*(), not texImage()
		* @see https://registry.khronos.org/webgl/specs/latest/2.0/ WebGL 2 spec section 3.7.6
		*/
		this.gl.bindTexture(this.glTarget, this.handle);
		const { dimension, width, height, depth, mipLevels, glTarget, glInternalFormat } = this;
		switch (dimension) {
			case "2d":
			case "cube":
				this.gl.texStorage2D(glTarget, mipLevels, glInternalFormat, width, height);
				break;
			case "2d-array":
			case "3d":
				this.gl.texStorage3D(glTarget, mipLevels, glInternalFormat, width, height, depth);
				break;
			default: throw new Error(dimension);
		}
		this.gl.bindTexture(this.glTarget, null);
		this._initializeData(props.data);
		this.setSampler(this.props.sampler);
		this.view = new WEBGLTextureView(this.device, {
			...this.props,
			texture: this
		});
		Object.seal(this);
	}
	destroy() {
		if (this.handle) {
			this.gl.deleteTexture(this.handle);
			this.removeStats();
			this.trackDeallocatedMemory("Texture");
			this.destroyed = true;
		}
	}
	createView(props) {
		return new WEBGLTextureView(this.device, {
			...props,
			texture: this
		});
	}
	setSampler(sampler = {}) {
		super.setSampler(sampler);
		const parameters = convertSamplerParametersToWebGL(this.sampler.props);
		this._setSamplerParameters(parameters);
	}
	copyImageData(options_) {
		const options = this._normalizeCopyImageDataOptions(options_);
		const typedArray = options.data;
		const { width, height, depth } = this;
		const { mipLevel = 0, byteOffset = 0, x = 0, y = 0, z = 0 } = options;
		const { glFormat, glType, compressed } = this;
		const glTarget = getWebGLCubeFaceTarget(this.glTarget, this.dimension, z);
		let unpackRowLength;
		if (!this.compressed) {
			const { bytesPerPixel } = this.device.getTextureFormatInfo(this.format);
			if (bytesPerPixel) {
				if (options.bytesPerRow % bytesPerPixel !== 0) throw new Error(`bytesPerRow (${options.bytesPerRow}) must be a multiple of bytesPerPixel (${bytesPerPixel}) for ${this.format}`);
				unpackRowLength = options.bytesPerRow / bytesPerPixel;
			}
		}
		const glParameters = !this.compressed ? {
			...unpackRowLength !== void 0 ? { [3314]: unpackRowLength } : {},
			[32878]: options.rowsPerImage
		} : {};
		this.gl.bindTexture(glTarget, this.handle);
		withGLParameters(this.gl, glParameters, () => {
			switch (this.dimension) {
				case "2d":
				case "cube":
					if (compressed) this.gl.compressedTexSubImage2D(glTarget, mipLevel, x, y, width, height, glFormat, typedArray, byteOffset);
					else this.gl.texSubImage2D(glTarget, mipLevel, x, y, width, height, glFormat, glType, typedArray, byteOffset);
					break;
				case "2d-array":
				case "3d":
					if (compressed) this.gl.compressedTexSubImage3D(glTarget, mipLevel, x, y, z, width, height, depth, glFormat, typedArray, byteOffset);
					else this.gl.texSubImage3D(glTarget, mipLevel, x, y, z, width, height, depth, glFormat, glType, typedArray, byteOffset);
					break;
				default:
			}
		});
		this.gl.bindTexture(glTarget, null);
	}
	copyExternalImage(options_) {
		const options = this._normalizeCopyExternalImageOptions(options_);
		if (options.sourceX || options.sourceY) throw new Error("WebGL does not support sourceX/sourceY)");
		const { glFormat, glType } = this;
		const { image, depth, mipLevel, x, y, z, width, height } = options;
		const glTarget = getWebGLCubeFaceTarget(this.glTarget, this.dimension, depth);
		const glParameters = options.flipY ? { [37440]: true } : {};
		this.gl.bindTexture(this.glTarget, this.handle);
		withGLParameters(this.gl, glParameters, () => {
			switch (this.dimension) {
				case "2d":
				case "cube":
					this.gl.texSubImage2D(glTarget, mipLevel, x, y, width, height, glFormat, glType, image);
					break;
				case "2d-array":
				case "3d":
					this.gl.texSubImage3D(glTarget, mipLevel, x, y, z, width, height, depth, glFormat, glType, image);
					break;
				default:
			}
		});
		this.gl.bindTexture(this.glTarget, null);
		return {
			width: options.width,
			height: options.height
		};
	}
	generateMipmapsWebGL(options) {
		if (!(this.device.isTextureFormatRenderable(this.props.format) && this.device.isTextureFormatFilterable(this.props.format))) {
			log.warn(`${this} is not renderable or filterable, may not be able to generate mipmaps`)();
			if (!options?.force) return;
		}
		try {
			this.gl.bindTexture(this.glTarget, this.handle);
			this.gl.generateMipmap(this.glTarget);
		} catch (error) {
			log.warn(`Error generating mipmap for ${this}: ${error.message}`)();
		} finally {
			this.gl.bindTexture(this.glTarget, null);
		}
	}
	/**
	* Sets sampler parameters on texture
	*/
	_setSamplerParameters(parameters) {
		log.log(2, `${this.id} sampler parameters`, this.device.getGLKeys(parameters))();
		this.gl.bindTexture(this.glTarget, this.handle);
		for (const [pname, pvalue] of Object.entries(parameters)) {
			const param = Number(pname);
			const value = pvalue;
			switch (param) {
				case 33082:
				case 33083:
					this.gl.texParameterf(this.glTarget, param, value);
					break;
				case 10240:
				case 10241:
					this.gl.texParameteri(this.glTarget, param, value);
					break;
				case 10242:
				case 10243:
				case 32882:
					this.gl.texParameteri(this.glTarget, param, value);
					break;
				case 34046:
					if (this.device.features.has("texture-filterable-anisotropic-webgl")) this.gl.texParameteri(this.glTarget, param, value);
					break;
				case 34892:
				case 34893:
					this.gl.texParameteri(this.glTarget, param, value);
					break;
			}
		}
		this.gl.bindTexture(this.glTarget, null);
	}
	_getActiveUnit() {
		return this.gl.getParameter(34016) - 33984;
	}
	_bind(_textureUnit) {
		const { gl } = this;
		if (_textureUnit !== void 0) {
			this._textureUnit = _textureUnit;
			gl.activeTexture(33984 + _textureUnit);
		}
		gl.bindTexture(this.glTarget, this.handle);
		return _textureUnit;
	}
	_unbind(_textureUnit) {
		const { gl } = this;
		if (_textureUnit !== void 0) {
			this._textureUnit = _textureUnit;
			gl.activeTexture(33984 + _textureUnit);
		}
		gl.bindTexture(this.glTarget, null);
		return _textureUnit;
	}
};
/** Convert a WebGPU style texture constant to a WebGL style texture constant */
function getWebGLTextureTarget(dimension) {
	switch (dimension) {
		case "1d": break;
		case "2d": return 3553;
		case "3d": return 32879;
		case "cube": return 34067;
		case "2d-array": return 35866;
		case "cube-array": break;
	}
	throw new Error(dimension);
}
/**
* In WebGL, cube maps specify faces by overriding target instead of using the depth parameter.
* @note We still bind the texture using GL.TEXTURE_CUBE_MAP, but we need to use the face-specific target when setting mip levels.
* @returns glTarget unchanged, if dimension !== 'cube'.
*/
function getWebGLCubeFaceTarget(glTarget, dimension, level) {
	return dimension === "cube" ? 34069 + level : glTarget;
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/converters/webgl-shadertypes.js
/** Converts to a luma shadertype to a GL data type (GL.BYTE, GL.FLOAT32 etc)  */
function convertDataTypeToGLDataType(normalizedType) {
	return NORMALIZED_SHADER_TYPE_TO_WEBGL[normalizedType];
}
/** Convert a WebGL "compisite type (e.g. GL.VEC3) into the corresponding luma shader uniform type */
function convertGLUniformTypeToShaderVariableType(glUniformType) {
	return WEBGL_SHADER_TYPES[glUniformType];
}
/** Check if a WebGL "uniform:" is a texture binding */
function isGLSamplerType(type) {
	return Boolean(WEBGL_SAMPLER_TO_TEXTURE_BINDINGS[type]);
}
function getTextureBindingFromGLSamplerType(glSamplerType) {
	return WEBGL_SAMPLER_TO_TEXTURE_BINDINGS[glSamplerType];
}
var WEBGL_SHADER_TYPES = {
	[5126]: "f32",
	[35664]: "vec2<f32>",
	[35665]: "vec3<f32>",
	[35666]: "vec4<f32>",
	[5124]: "i32",
	[35667]: "vec2<i32>",
	[35668]: "vec3<i32>",
	[35669]: "vec4<i32>",
	[5125]: "u32",
	[36294]: "vec2<u32>",
	[36295]: "vec3<u32>",
	[36296]: "vec4<u32>",
	[35670]: "f32",
	[35671]: "vec2<f32>",
	[35672]: "vec3<f32>",
	[35673]: "vec4<f32>",
	[35674]: "mat2x2<f32>",
	[35685]: "mat2x3<f32>",
	[35686]: "mat2x4<f32>",
	[35687]: "mat3x2<f32>",
	[35675]: "mat3x3<f32>",
	[35688]: "mat3x4<f32>",
	[35689]: "mat4x2<f32>",
	[35690]: "mat4x3<f32>",
	[35676]: "mat4x4<f32>"
};
var WEBGL_SAMPLER_TO_TEXTURE_BINDINGS = {
	[35678]: {
		viewDimension: "2d",
		sampleType: "float"
	},
	[35680]: {
		viewDimension: "cube",
		sampleType: "float"
	},
	[35679]: {
		viewDimension: "3d",
		sampleType: "float"
	},
	[35682]: {
		viewDimension: "3d",
		sampleType: "depth"
	},
	[36289]: {
		viewDimension: "2d-array",
		sampleType: "float"
	},
	[36292]: {
		viewDimension: "2d-array",
		sampleType: "depth"
	},
	[36293]: {
		viewDimension: "cube",
		sampleType: "float"
	},
	[36298]: {
		viewDimension: "2d",
		sampleType: "sint"
	},
	[36299]: {
		viewDimension: "3d",
		sampleType: "sint"
	},
	[36300]: {
		viewDimension: "cube",
		sampleType: "sint"
	},
	[36303]: {
		viewDimension: "2d-array",
		sampleType: "uint"
	},
	[36306]: {
		viewDimension: "2d",
		sampleType: "uint"
	},
	[36307]: {
		viewDimension: "3d",
		sampleType: "uint"
	},
	[36308]: {
		viewDimension: "cube",
		sampleType: "uint"
	},
	[36311]: {
		viewDimension: "2d-array",
		sampleType: "uint"
	}
};
/** Map from WebGL normalized types to WebGL */
var NORMALIZED_SHADER_TYPE_TO_WEBGL = {
	uint8: 5121,
	sint8: 5120,
	unorm8: 5121,
	snorm8: 5120,
	uint16: 5123,
	sint16: 5122,
	unorm16: 5123,
	snorm16: 5122,
	uint32: 5125,
	sint32: 5124,
	float16: 5131,
	float32: 5126
};

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/helpers/get-shader-layout-from-glsl.js
/**
* Extract metadata describing binding information for a program's shaders
* Note: `linkProgram()` needs to have been called
* (although linking does not need to have been successful).
*/
function getShaderLayoutFromGLSL(gl, program) {
	const shaderLayout = {
		attributes: [],
		bindings: []
	};
	shaderLayout.attributes = readAttributeDeclarations(gl, program);
	const uniformBlocks = readUniformBlocks(gl, program);
	for (const uniformBlock of uniformBlocks) {
		const uniforms$1 = uniformBlock.uniforms.map((uniform) => ({
			name: uniform.name,
			format: uniform.format,
			byteOffset: uniform.byteOffset,
			byteStride: uniform.byteStride,
			arrayLength: uniform.arrayLength
		}));
		shaderLayout.bindings.push({
			type: "uniform",
			name: uniformBlock.name,
			group: 0,
			location: uniformBlock.location,
			visibility: (uniformBlock.vertex ? 1 : 0) & (uniformBlock.fragment ? 2 : 0),
			minBindingSize: uniformBlock.byteLength,
			uniforms: uniforms$1
		});
	}
	const uniforms = readUniformBindings(gl, program);
	let textureUnit = 0;
	for (const uniform of uniforms) if (isGLSamplerType(uniform.type)) {
		const { viewDimension, sampleType } = getTextureBindingFromGLSamplerType(uniform.type);
		shaderLayout.bindings.push({
			type: "texture",
			name: uniform.name,
			group: 0,
			location: textureUnit,
			viewDimension,
			sampleType
		});
		uniform.textureUnit = textureUnit;
		textureUnit += 1;
	}
	if (uniforms.length) shaderLayout.uniforms = uniforms;
	const varyings = readVaryings(gl, program);
	if (varyings?.length) shaderLayout.varyings = varyings;
	return shaderLayout;
}
/**
* Extract info about all transform feedback varyings
*
* linkProgram needs to have been called, although linking does not need to have been successful
*/
function readAttributeDeclarations(gl, program) {
	const attributes = [];
	const count = gl.getProgramParameter(program, 35721);
	for (let index = 0; index < count; index++) {
		const activeInfo = gl.getActiveAttrib(program, index);
		if (!activeInfo) throw new Error("activeInfo");
		const { name: name$1, type: compositeType } = activeInfo;
		const location = gl.getAttribLocation(program, name$1);
		if (location >= 0) {
			const attributeType = convertGLUniformTypeToShaderVariableType(compositeType);
			const stepMode = /instance/i.test(name$1) ? "instance" : "vertex";
			attributes.push({
				name: name$1,
				location,
				stepMode,
				type: attributeType
			});
		}
	}
	attributes.sort((a, b) => a.location - b.location);
	return attributes;
}
/**
* Extract info about all transform feedback varyings
*
* linkProgram needs to have been called, although linking does not need to have been successful
*/
function readVaryings(gl, program) {
	const varyings = [];
	const count = gl.getProgramParameter(program, 35971);
	for (let location = 0; location < count; location++) {
		const activeInfo = gl.getTransformFeedbackVarying(program, location);
		if (!activeInfo) throw new Error("activeInfo");
		const { name: name$1, type: glUniformType, size } = activeInfo;
		const { type, components } = getVariableShaderTypeInfo(convertGLUniformTypeToShaderVariableType(glUniformType));
		varyings.push({
			location,
			name: name$1,
			type,
			size: size * components
		});
	}
	varyings.sort((a, b) => a.location - b.location);
	return varyings;
}
/**
* Extract info about all uniforms
*
* Query uniform locations and build name to setter map.
*/
function readUniformBindings(gl, program) {
	const uniforms = [];
	const uniformCount = gl.getProgramParameter(program, 35718);
	for (let i = 0; i < uniformCount; i++) {
		const activeInfo = gl.getActiveUniform(program, i);
		if (!activeInfo) throw new Error("activeInfo");
		const { name: rawName, size, type } = activeInfo;
		const { name: name$1, isArray: isArray$2 } = parseUniformName(rawName);
		let webglLocation = gl.getUniformLocation(program, name$1);
		const uniformInfo = {
			location: webglLocation,
			name: name$1,
			size,
			type,
			isArray: isArray$2
		};
		uniforms.push(uniformInfo);
		if (uniformInfo.size > 1) for (let j = 0; j < uniformInfo.size; j++) {
			const elementName = `${name$1}[${j}]`;
			webglLocation = gl.getUniformLocation(program, elementName);
			const arrayElementUniformInfo = {
				...uniformInfo,
				name: elementName,
				location: webglLocation
			};
			uniforms.push(arrayElementUniformInfo);
		}
	}
	return uniforms;
}
/**
* Extract info about all "active" uniform blocks
* @note In WebGL, "active" just means that unused (inactive) blocks may have been optimized away during linking)
*/
function readUniformBlocks(gl, program) {
	const getBlockParameter = (blockIndex, pname) => gl.getActiveUniformBlockParameter(program, blockIndex, pname);
	const uniformBlocks = [];
	const blockCount = gl.getProgramParameter(program, 35382);
	for (let blockIndex = 0; blockIndex < blockCount; blockIndex++) {
		const blockInfo = {
			name: gl.getActiveUniformBlockName(program, blockIndex) || "",
			location: getBlockParameter(blockIndex, 35391),
			byteLength: getBlockParameter(blockIndex, 35392),
			vertex: getBlockParameter(blockIndex, 35396),
			fragment: getBlockParameter(blockIndex, 35398),
			uniformCount: getBlockParameter(blockIndex, 35394),
			uniforms: []
		};
		const uniformIndices = getBlockParameter(blockIndex, 35395) || [];
		const uniformType = gl.getActiveUniforms(program, uniformIndices, 35383);
		const uniformArrayLength = gl.getActiveUniforms(program, uniformIndices, 35384);
		const uniformOffset = gl.getActiveUniforms(program, uniformIndices, 35387);
		const uniformStride = gl.getActiveUniforms(program, uniformIndices, 35388);
		for (let i = 0; i < blockInfo.uniformCount; ++i) {
			const activeInfo = gl.getActiveUniform(program, uniformIndices[i]);
			if (!activeInfo) throw new Error("activeInfo");
			const format = convertGLUniformTypeToShaderVariableType(uniformType[i]);
			blockInfo.uniforms.push({
				name: activeInfo.name,
				format,
				type: uniformType[i],
				arrayLength: uniformArrayLength[i],
				byteOffset: uniformOffset[i],
				byteStride: uniformStride[i]
			});
		}
		uniformBlocks.push(blockInfo);
	}
	uniformBlocks.sort((a, b) => a.location - b.location);
	return uniformBlocks;
}
/**
* TOOD - compare with a above, confirm copy, then delete
const bindings: Binding[] = [];
const count = gl.getProgramParameter(program, gl.ACTIVE_UNIFORM_BLOCKS);
for (let blockIndex = 0; blockIndex < count; blockIndex++) {
const vertex = gl.getActiveUniformBlockParameter(program, blockIndex, gl.UNIFORM_BLOCK_REFERENCED_BY_VERTEX_SHADER),
const fragment = gl.getActiveUniformBlockParameter(program, blockIndex, gl.UNIFORM_BLOCK_REFERENCED_BY_FRAGMENT_SHADER),
const visibility = (vertex) + (fragment);
const binding: BufferBinding = {
location: gl.getActiveUniformBlockParameter(program, blockIndex, gl.UNIFORM_BLOCK_BINDING),
// name: gl.getActiveUniformBlockName(program, blockIndex),
type: 'uniform',
visibility,
minBindingSize: gl.getActiveUniformBlockParameter(program, blockIndex, gl.UNIFORM_BLOCK_DATA_SIZE),
// uniformCount: gl.getActiveUniformBlockParameter(program, blockIndex, gl.UNIFORM_BLOCK_ACTIVE_UNIFORMS),
// uniformIndices: gl.getActiveUniformBlockParameter(program, blockIndex, gl.UNIFORM_BLOCK_ACTIVE_UNIFORM_INDICES),
}
bindings.push(binding);
}
*/
function parseUniformName(name$1) {
	if (name$1[name$1.length - 1] !== "]") return {
		name: name$1,
		length: 1,
		isArray: false
	};
	const matches = /([^[]*)(\[[0-9]+\])?/.exec(name$1);
	if (!matches || matches.length < 2) throw new Error(`Failed to parse GLSL uniform name ${name$1}`);
	return {
		name: matches[1],
		length: matches[2] ? 1 : 0,
		isArray: Boolean(matches[2])
	};
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/helpers/set-uniform.js
/** Set a raw uniform (without type conversion and caching) */
function setUniform(gl, location, type, value) {
	const gl2 = gl;
	let uniformValue = value;
	if (uniformValue === true) uniformValue = 1;
	if (uniformValue === false) uniformValue = 0;
	const arrayValue = typeof uniformValue === "number" ? [uniformValue] : uniformValue;
	switch (type) {
		case 35678:
		case 35680:
		case 35679:
		case 35682:
		case 36289:
		case 36292:
		case 36293:
		case 36298:
		case 36299:
		case 36300:
		case 36303:
		case 36306:
		case 36307:
		case 36308:
		case 36311:
			if (typeof value !== "number") throw new Error("samplers must be set to integers");
			return gl.uniform1i(location, value);
		case 5126: return gl.uniform1fv(location, arrayValue);
		case 35664: return gl.uniform2fv(location, arrayValue);
		case 35665: return gl.uniform3fv(location, arrayValue);
		case 35666: return gl.uniform4fv(location, arrayValue);
		case 5124: return gl.uniform1iv(location, arrayValue);
		case 35667: return gl.uniform2iv(location, arrayValue);
		case 35668: return gl.uniform3iv(location, arrayValue);
		case 35669: return gl.uniform4iv(location, arrayValue);
		case 35670: return gl.uniform1iv(location, arrayValue);
		case 35671: return gl.uniform2iv(location, arrayValue);
		case 35672: return gl.uniform3iv(location, arrayValue);
		case 35673: return gl.uniform4iv(location, arrayValue);
		case 5125: return gl2.uniform1uiv(location, arrayValue, 1);
		case 36294: return gl2.uniform2uiv(location, arrayValue, 2);
		case 36295: return gl2.uniform3uiv(location, arrayValue, 3);
		case 36296: return gl2.uniform4uiv(location, arrayValue, 4);
		case 35674: return gl.uniformMatrix2fv(location, false, arrayValue);
		case 35675: return gl.uniformMatrix3fv(location, false, arrayValue);
		case 35676: return gl.uniformMatrix4fv(location, false, arrayValue);
		case 35685: return gl2.uniformMatrix2x3fv(location, false, arrayValue);
		case 35686: return gl2.uniformMatrix2x4fv(location, false, arrayValue);
		case 35687: return gl2.uniformMatrix3x2fv(location, false, arrayValue);
		case 35688: return gl2.uniformMatrix3x4fv(location, false, arrayValue);
		case 35689: return gl2.uniformMatrix4x2fv(location, false, arrayValue);
		case 35690: return gl2.uniformMatrix4x3fv(location, false, arrayValue);
	}
	throw new Error("Illegal uniform");
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/helpers/webgl-topology-utils.js
/** Get the primitive type for draw */
function getGLDrawMode(topology) {
	switch (topology) {
		case "point-list": return 0;
		case "line-list": return 1;
		case "line-strip": return 3;
		case "triangle-list": return 4;
		case "triangle-strip": return 5;
		default: throw new Error(topology);
	}
}
/** Get the primitive type for transform feedback */
function getGLPrimitive(topology) {
	switch (topology) {
		case "point-list": return 0;
		case "line-list": return 1;
		case "line-strip": return 1;
		case "triangle-list": return 4;
		case "triangle-strip": return 4;
		default: throw new Error(topology);
	}
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/resources/webgl-render-pipeline.js
var LOG_PROGRAM_PERF_PRIORITY = 4;
/** Creates a new render pipeline */
var WEBGLRenderPipeline = class extends RenderPipeline {
	/** The WebGL device that created this render pipeline */
	device;
	/** Handle to underlying WebGL program */
	handle;
	/** vertex shader */
	vs;
	/** fragment shader */
	fs;
	/** The layout extracted from shader by WebGL introspection APIs */
	introspectedLayout;
	/** Uniforms set on this model */
	uniforms = {};
	/** Bindings set on this model */
	bindings = {};
	/** WebGL varyings */
	varyings = null;
	_uniformCount = 0;
	_uniformSetters = {};
	get [Symbol.toStringTag]() {
		return "WEBGLRenderPipeline";
	}
	constructor(device, props) {
		super(device, props);
		this.device = device;
		this.handle = this.props.handle || this.device.gl.createProgram();
		this.device._setWebGLDebugMetadata(this.handle, this, { spector: { id: this.props.id } });
		this.vs = props.vs;
		this.fs = props.fs;
		const { varyings, bufferMode = 35981 } = props;
		if (varyings && varyings.length > 0) {
			this.varyings = varyings;
			this.device.gl.transformFeedbackVaryings(this.handle, varyings, bufferMode);
		}
		this._linkShaders();
		log.time(3, `RenderPipeline ${this.id} - shaderLayout introspection`)();
		this.introspectedLayout = getShaderLayoutFromGLSL(this.device.gl, this.handle);
		log.timeEnd(3, `RenderPipeline ${this.id} - shaderLayout introspection`)();
		this.shaderLayout = props.shaderLayout ? mergeShaderLayout(this.introspectedLayout, props.shaderLayout) : this.introspectedLayout;
	}
	destroy() {
		if (this.handle) {
			this.device.gl.useProgram(null);
			this.device.gl.deleteProgram(this.handle);
			this.destroyed = true;
			this.handle.destroyed = true;
			this.handle = null;
		}
	}
	/**
	* Bindings include: textures, samplers and uniform buffers
	* @todo needed for portable model
	*/
	setBindings(bindings, options) {
		for (const [name$1, value] of Object.entries(bindings)) {
			const binding = this.shaderLayout.bindings.find((binding_) => binding_.name === name$1) || this.shaderLayout.bindings.find((binding_) => binding_.name === `${name$1}Uniforms`);
			if (!binding) {
				const validBindings = this.shaderLayout.bindings.map((binding_) => `"${binding_.name}"`).join(", ");
				if (!options?.disableWarnings) log.warn(`No binding "${name$1}" in render pipeline "${this.id}", expected one of ${validBindings}`, value)();
				continue;
			}
			if (!value) log.warn(`Unsetting binding "${name$1}" in render pipeline "${this.id}"`)();
			switch (binding.type) {
				case "uniform":
					if (!(value instanceof WEBGLBuffer) && !(value.buffer instanceof WEBGLBuffer)) throw new Error("buffer value");
					break;
				case "texture":
					if (!(value instanceof WEBGLTextureView || value instanceof WEBGLTexture || value instanceof WEBGLFramebuffer)) throw new Error(`${this} Bad texture binding for ${name$1}`);
					break;
				case "sampler":
					log.warn(`Ignoring sampler ${name$1}`)();
					break;
				default: throw new Error(binding.type);
			}
			this.bindings[name$1] = value;
		}
	}
	/** @todo needed for portable model
	* @note The WebGL API is offers many ways to draw things
	* This function unifies those ways into a single call using common parameters with sane defaults
	*/
	draw(options) {
		const { renderPass, parameters = this.props.parameters, topology = this.props.topology, vertexArray, vertexCount, instanceCount, isInstanced = false, firstVertex = 0, transformFeedback } = options;
		const glDrawMode = getGLDrawMode(topology);
		const isIndexed = Boolean(vertexArray.indexBuffer);
		const glIndexType = vertexArray.indexBuffer?.glIndexType;
		if (this.linkStatus !== "success") {
			log.info(2, `RenderPipeline:${this.id}.draw() aborted - waiting for shader linking`)();
			return false;
		}
		if (!this._areTexturesRenderable()) {
			log.info(2, `RenderPipeline:${this.id}.draw() aborted - textures not yet loaded`)();
			return false;
		}
		this.device.gl.useProgram(this.handle);
		vertexArray.bindBeforeRender(renderPass);
		if (transformFeedback) transformFeedback.begin(this.props.topology);
		this._applyBindings();
		this._applyUniforms();
		const webglRenderPass = renderPass;
		withDeviceAndGLParameters(this.device, parameters, webglRenderPass.glParameters, () => {
			if (isIndexed && isInstanced) this.device.gl.drawElementsInstanced(glDrawMode, vertexCount || 0, glIndexType, firstVertex, instanceCount || 0);
			else if (isIndexed) this.device.gl.drawElements(glDrawMode, vertexCount || 0, glIndexType, firstVertex);
			else if (isInstanced) this.device.gl.drawArraysInstanced(glDrawMode, firstVertex, vertexCount || 0, instanceCount || 0);
			else this.device.gl.drawArrays(glDrawMode, firstVertex, vertexCount || 0);
			if (transformFeedback) transformFeedback.end();
		});
		vertexArray.unbindAfterRender(renderPass);
		return true;
	}
	async _linkShaders() {
		const { gl } = this.device;
		gl.attachShader(this.handle, this.vs.handle);
		gl.attachShader(this.handle, this.fs.handle);
		log.time(LOG_PROGRAM_PERF_PRIORITY, `linkProgram for ${this.id}`)();
		gl.linkProgram(this.handle);
		log.timeEnd(LOG_PROGRAM_PERF_PRIORITY, `linkProgram for ${this.id}`)();
		if (log.level === 0) {}
		if (!this.device.features.has("compilation-status-async-webgl")) {
			const status$1 = this._getLinkStatus();
			this._reportLinkStatus(status$1);
			return;
		}
		log.once(1, "RenderPipeline linking is asynchronous")();
		await this._waitForLinkComplete();
		log.info(2, `RenderPipeline ${this.id} - async linking complete: ${this.linkStatus}`)();
		const status = this._getLinkStatus();
		this._reportLinkStatus(status);
	}
	/** Report link status. First, check for shader compilation failures if linking fails */
	async _reportLinkStatus(status) {
		switch (status) {
			case "success": return;
			default:
				const errorType = status === "link-error" ? "Link error" : "Validation error";
				switch (this.vs.compilationStatus) {
					case "error":
						this.vs.debugShader();
						throw new Error(`${this} ${errorType} during compilation of ${this.vs}`);
					case "pending":
						await this.vs.asyncCompilationStatus;
						this.vs.debugShader();
						break;
					case "success": break;
				}
				switch (this.fs?.compilationStatus) {
					case "error":
						this.fs.debugShader();
						throw new Error(`${this} ${errorType} during compilation of ${this.fs}`);
					case "pending":
						await this.fs.asyncCompilationStatus;
						this.fs.debugShader();
						break;
					case "success": break;
				}
				const linkErrorLog = this.device.gl.getProgramInfoLog(this.handle);
				this.device.reportError(/* @__PURE__ */ new Error(`${errorType} during ${status}: ${linkErrorLog}`), this)();
				this.device.debug();
		}
	}
	/**
	* Get the shader compilation status
	* TODO - Load log even when no error reported, to catch warnings?
	* https://gamedev.stackexchange.com/questions/30429/how-to-detect-glsl-warnings
	*/
	_getLinkStatus() {
		const { gl } = this.device;
		if (!gl.getProgramParameter(this.handle, 35714)) {
			this.linkStatus = "error";
			return "link-error";
		}
		gl.validateProgram(this.handle);
		if (!gl.getProgramParameter(this.handle, 35715)) {
			this.linkStatus = "error";
			return "validation-error";
		}
		this.linkStatus = "success";
		return "success";
	}
	/** Use KHR_parallel_shader_compile extension if available */
	async _waitForLinkComplete() {
		const waitMs = async (ms) => await new Promise((resolve) => setTimeout(resolve, ms));
		const DELAY_MS = 10;
		if (!this.device.features.has("compilation-status-async-webgl")) {
			await waitMs(DELAY_MS);
			return;
		}
		const { gl } = this.device;
		for (;;) {
			if (gl.getProgramParameter(this.handle, 37297)) return;
			await waitMs(DELAY_MS);
		}
	}
	/**
	* Checks if all texture-values uniforms are renderable (i.e. loaded)
	* Update a texture if needed (e.g. from video)
	* Note: This is currently done before every draw call
	*/
	_areTexturesRenderable() {
		let texturesRenderable = true;
		for (const bindingInfo of this.shaderLayout.bindings) if (!this.bindings[bindingInfo.name] && !this.bindings[bindingInfo.name.replace(/Uniforms$/, "")]) {
			log.warn(`Binding ${bindingInfo.name} not found in ${this.id}`)();
			texturesRenderable = false;
		}
		return texturesRenderable;
	}
	/** Apply any bindings (before each draw call) */
	_applyBindings() {
		if (this.linkStatus !== "success") return;
		const { gl } = this.device;
		gl.useProgram(this.handle);
		let textureUnit = 0;
		let uniformBufferIndex = 0;
		for (const binding of this.shaderLayout.bindings) {
			const value = this.bindings[binding.name] || this.bindings[binding.name.replace(/Uniforms$/, "")];
			if (!value) throw new Error(`No value for binding ${binding.name} in ${this.id}`);
			switch (binding.type) {
				case "uniform":
					const { name: name$1 } = binding;
					const location = gl.getUniformBlockIndex(this.handle, name$1);
					if (location === 4294967295) throw new Error(`Invalid uniform block name ${name$1}`);
					gl.uniformBlockBinding(this.handle, uniformBufferIndex, location);
					if (value instanceof WEBGLBuffer) gl.bindBufferBase(35345, uniformBufferIndex, value.handle);
					else gl.bindBufferRange(35345, uniformBufferIndex, value.buffer.handle, value.offset || 0, value.size || value.buffer.byteLength - value.offset);
					uniformBufferIndex += 1;
					break;
				case "texture":
					if (!(value instanceof WEBGLTextureView || value instanceof WEBGLTexture || value instanceof WEBGLFramebuffer)) throw new Error("texture");
					let texture;
					if (value instanceof WEBGLTextureView) texture = value.texture;
					else if (value instanceof WEBGLTexture) texture = value;
					else if (value instanceof WEBGLFramebuffer && value.colorAttachments[0] instanceof WEBGLTextureView) {
						log.warn("Passing framebuffer in texture binding may be deprecated. Use fbo.colorAttachments[0] instead")();
						texture = value.colorAttachments[0].texture;
					} else throw new Error("No texture");
					gl.activeTexture(33984 + textureUnit);
					gl.bindTexture(texture.glTarget, texture.handle);
					textureUnit += 1;
					break;
				case "sampler": break;
				case "storage":
				case "read-only-storage": throw new Error(`binding type '${binding.type}' not supported in WebGL`);
			}
		}
	}
	/**
	* Due to program sharing, uniforms need to be reset before every draw call
	* (though caching will avoid redundant WebGL calls)
	*/
	_applyUniforms() {
		for (const uniformLayout of this.shaderLayout.uniforms || []) {
			const { name: name$1, location, type, textureUnit } = uniformLayout;
			const value = this.uniforms[name$1] ?? textureUnit;
			if (value !== void 0) setUniform(this.device.gl, location, type, value);
		}
	}
};
/**
* Merges an provided shader layout into a base shader layout
* In WebGL, this allows the auto generated shader layout to be overridden by the application
* Typically to change the format of the vertex attributes (from float32x4 to uint8x4 etc).
* @todo Drop this? Aren't all use cases covered by mergeBufferLayout()?
*/
function mergeShaderLayout(baseLayout, overrideLayout) {
	const mergedLayout = {
		...baseLayout,
		attributes: baseLayout.attributes.map((attribute) => ({ ...attribute }))
	};
	for (const attribute of overrideLayout?.attributes || []) {
		const baseAttribute = mergedLayout.attributes.find((attr) => attr.name === attribute.name);
		if (!baseAttribute) log.warn(`shader layout attribute ${attribute.name} not present in shader`);
		else {
			baseAttribute.type = attribute.type || baseAttribute.type;
			baseAttribute.stepMode = attribute.stepMode || baseAttribute.stepMode;
		}
	}
	return mergedLayout;
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/resources/webgl-command-buffer.js
var WEBGLCommandBuffer = class extends CommandBuffer {
	device;
	handle = null;
	commands = [];
	constructor(device) {
		super(device, {});
		this.device = device;
	}
	_executeCommands(commands = this.commands) {
		for (const command of commands) switch (command.name) {
			case "copy-buffer-to-buffer":
				_copyBufferToBuffer(this.device, command.options);
				break;
			case "copy-buffer-to-texture":
				_copyBufferToTexture(this.device, command.options);
				break;
			case "copy-texture-to-buffer":
				_copyTextureToBuffer(this.device, command.options);
				break;
			case "copy-texture-to-texture":
				_copyTextureToTexture(this.device, command.options);
				break;
			default: throw new Error(command.name);
		}
	}
};
function _copyBufferToBuffer(device, options) {
	const source = options.sourceBuffer;
	const destination = options.destinationBuffer;
	device.gl.bindBuffer(36662, source.handle);
	device.gl.bindBuffer(36663, destination.handle);
	device.gl.copyBufferSubData(36662, 36663, options.sourceOffset ?? 0, options.destinationOffset ?? 0, options.size);
	device.gl.bindBuffer(36662, null);
	device.gl.bindBuffer(36663, null);
}
/**
* Copies data from a Buffer object into a Texture object
* NOTE: doesn't wait for copy to be complete
*/
function _copyBufferToTexture(device, options) {
	throw new Error("Not implemented");
}
/**
* Copies data from a Texture object into a Buffer object.
* NOTE: doesn't wait for copy to be complete
*/
function _copyTextureToBuffer(device, options) {
	const { sourceTexture, mipLevel = 0, aspect = "all", width = options.sourceTexture.width, height = options.sourceTexture.height, depthOrArrayLayers = 0, origin = [0, 0], destinationBuffer, byteOffset = 0, bytesPerRow, rowsPerImage } = options;
	if (aspect !== "all") throw new Error("aspect not supported in WebGL");
	if (mipLevel !== 0 || depthOrArrayLayers !== 0 || bytesPerRow || rowsPerImage) throw new Error("not implemented");
	const { framebuffer, destroyFramebuffer } = getFramebuffer$1(sourceTexture);
	let prevHandle;
	try {
		const webglBuffer = destinationBuffer;
		const sourceWidth = width || framebuffer.width;
		const sourceHeight = height || framebuffer.height;
		const sourceParams = getTextureFormatWebGL(framebuffer.colorAttachments[0].texture.props.format);
		const sourceFormat = sourceParams.format;
		const sourceType = sourceParams.type;
		device.gl.bindBuffer(35051, webglBuffer.handle);
		prevHandle = device.gl.bindFramebuffer(36160, framebuffer.handle);
		device.gl.readPixels(origin[0], origin[1], sourceWidth, sourceHeight, sourceFormat, sourceType, byteOffset);
	} finally {
		device.gl.bindBuffer(35051, null);
		if (prevHandle !== void 0) device.gl.bindFramebuffer(36160, prevHandle);
		if (destroyFramebuffer) framebuffer.destroy();
	}
}
/**
* Copies data from a Framebuffer or a Texture object into a Buffer object.
* NOTE: doesn't wait for copy to be complete, it programs GPU to perform a DMA transfer.
export function readPixelsToBuffer(
source: Framebuffer | Texture,
options?: {
sourceX?: number;
sourceY?: number;
sourceFormat?: number;
target?: Buffer; // A new Buffer object is created when not provided.
targetByteOffset?: number; // byte offset in buffer object
// following parameters are auto deduced if not provided
sourceWidth?: number;
sourceHeight?: number;
sourceType?: number;
}
): Buffer
*/
/**
* Copy a rectangle from a Framebuffer or Texture object into a texture (at an offset)
*/
function _copyTextureToTexture(device, options) {
	const { sourceTexture, destinationMipLevel = 0, origin = [0, 0], destinationOrigin = [0, 0], destinationTexture } = options;
	let { width = options.destinationTexture.width, height = options.destinationTexture.height } = options;
	const { framebuffer, destroyFramebuffer } = getFramebuffer$1(sourceTexture);
	const [sourceX, sourceY] = origin;
	const [destinationX, destinationY, destinationZ] = destinationOrigin;
	const prevHandle = device.gl.bindFramebuffer(36160, framebuffer.handle);
	let texture;
	let textureTarget;
	if (destinationTexture instanceof WEBGLTexture) {
		texture = destinationTexture;
		width = Number.isFinite(width) ? width : texture.width;
		height = Number.isFinite(height) ? height : texture.height;
		texture._bind(0);
		textureTarget = texture.glTarget;
	} else throw new Error("invalid destination");
	switch (textureTarget) {
		case 3553:
		case 34067:
			device.gl.copyTexSubImage2D(textureTarget, destinationMipLevel, destinationX, destinationY, sourceX, sourceY, width, height);
			break;
		case 35866:
		case 32879:
			device.gl.copyTexSubImage3D(textureTarget, destinationMipLevel, destinationX, destinationY, destinationZ, sourceX, sourceY, width, height);
			break;
		default:
	}
	if (texture) texture._unbind();
	device.gl.bindFramebuffer(36160, prevHandle);
	if (destroyFramebuffer) framebuffer.destroy();
}
/** Wrap a texture in a framebuffer so that we can use WebGL APIs that work on framebuffers */
function getFramebuffer$1(source) {
	if (source instanceof Texture) {
		const { width, height, id } = source;
		return {
			framebuffer: source.device.createFramebuffer({
				id: `framebuffer-for-${id}`,
				width,
				height,
				colorAttachments: [source]
			}),
			destroyFramebuffer: true
		};
	}
	return {
		framebuffer: source,
		destroyFramebuffer: false
	};
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/resources/webgl-render-pass.js
var COLOR_CHANNELS = [
	1,
	2,
	4,
	8
];
var WEBGLRenderPass = class extends RenderPass {
	device;
	handle = null;
	/** Parameters that should be applied before each draw call */
	glParameters = {};
	constructor(device, props) {
		super(device, props);
		this.device = device;
		let viewport;
		if (!props?.parameters?.viewport) if (props?.framebuffer) {
			const { width, height } = props.framebuffer;
			viewport = [
				0,
				0,
				width,
				height
			];
		} else {
			const [width, height] = device.getDefaultCanvasContext().getDrawingBufferSize();
			viewport = [
				0,
				0,
				width,
				height
			];
		}
		this.device.pushState();
		this.setParameters({
			viewport,
			...this.props.parameters
		});
		const webglFramebuffer = this.props.framebuffer;
		if (this.props.framebuffer && webglFramebuffer?.handle) {
			const drawBuffers = this.props.framebuffer.colorAttachments.map((_, i) => 36064 + i);
			this.device.gl.drawBuffers(drawBuffers);
		} else this.device.gl.drawBuffers([1029]);
		this.clear();
	}
	end() {
		this.device.popState();
	}
	pushDebugGroup(groupLabel) {}
	popDebugGroup() {}
	insertDebugMarker(markerLabel) {}
	/**
	* Maps RenderPass parameters to GL parameters
	*/
	setParameters(parameters = {}) {
		const glParameters = { ...this.glParameters };
		glParameters.framebuffer = this.props.framebuffer || null;
		if (this.props.depthReadOnly) glParameters.depthMask = !this.props.depthReadOnly;
		glParameters.stencilMask = this.props.stencilReadOnly ? 0 : 1;
		glParameters[35977] = this.props.discard;
		if (parameters.viewport) if (parameters.viewport.length >= 6) {
			glParameters.viewport = parameters.viewport.slice(0, 4);
			glParameters.depthRange = [parameters.viewport[4], parameters.viewport[5]];
		} else glParameters.viewport = parameters.viewport;
		if (parameters.scissorRect) {
			glParameters.scissorTest = true;
			glParameters.scissor = parameters.scissorRect;
		}
		if (parameters.blendConstant) glParameters.blendColor = parameters.blendConstant;
		if (parameters.stencilReference) {
			console.warn("RenderPassParameters.stencilReference not yet implemented in WebGL");
			glParameters[2967] = parameters.stencilReference;
		}
		if ("colorMask" in parameters) glParameters.colorMask = COLOR_CHANNELS.map((channel) => Boolean(channel & parameters.colorMask));
		this.glParameters = glParameters;
		setGLParameters(this.device.gl, glParameters);
	}
	beginOcclusionQuery(queryIndex) {
		this.props.occlusionQuerySet?.beginOcclusionQuery();
	}
	endOcclusionQuery() {
		this.props.occlusionQuerySet?.endOcclusionQuery();
	}
	/**
	* Optionally clears depth, color and stencil buffers based on parameters
	*/
	clear() {
		const glParameters = { ...this.glParameters };
		let clearMask = 0;
		if (this.props.clearColors) this.props.clearColors.forEach((color, drawBufferIndex) => {
			if (color) this.clearColorBuffer(drawBufferIndex, color);
		});
		if (this.props.clearColor !== false && this.props.clearColors === void 0) {
			clearMask |= 16384;
			glParameters.clearColor = this.props.clearColor;
		}
		if (this.props.clearDepth !== false) {
			clearMask |= 256;
			glParameters.clearDepth = this.props.clearDepth;
		}
		if (this.props.clearStencil !== false) {
			clearMask |= 1024;
			glParameters.clearStencil = this.props.clearStencil;
		}
		if (clearMask !== 0) withGLParameters(this.device.gl, glParameters, () => {
			this.device.gl.clear(clearMask);
		});
	}
	/**
	* WebGL2 - clear a specific color buffer
	*/
	clearColorBuffer(drawBuffer = 0, value = [
		0,
		0,
		0,
		0
	]) {
		withGLParameters(this.device.gl, { framebuffer: this.props.framebuffer }, () => {
			switch (value.constructor) {
				case Int8Array:
				case Int16Array:
				case Int32Array:
					this.device.gl.clearBufferiv(6144, drawBuffer, value);
					break;
				case Uint8Array:
				case Uint8ClampedArray:
				case Uint16Array:
				case Uint32Array:
					this.device.gl.clearBufferuiv(6144, drawBuffer, value);
					break;
				case Float32Array:
					this.device.gl.clearBufferfv(6144, drawBuffer, value);
					break;
				default: throw new Error("clearColorBuffer: color must be typed array");
			}
		});
	}
};

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/resources/webgl-command-encoder.js
var WEBGLCommandEncoder = class extends CommandEncoder {
	device;
	handle = null;
	commandBuffer;
	constructor(device, props) {
		super(device, props);
		this.device = device;
		this.commandBuffer = new WEBGLCommandBuffer(device);
	}
	destroy() {}
	finish() {
		return this.commandBuffer;
	}
	beginRenderPass(props) {
		return new WEBGLRenderPass(this.device, props);
	}
	beginComputePass(props) {
		throw new Error("ComputePass not supported in WebGL");
	}
	copyBufferToBuffer(options) {
		this.commandBuffer.commands.push({
			name: "copy-buffer-to-buffer",
			options
		});
	}
	copyBufferToTexture(options) {
		this.commandBuffer.commands.push({
			name: "copy-buffer-to-texture",
			options
		});
	}
	copyTextureToBuffer(options) {
		this.commandBuffer.commands.push({
			name: "copy-texture-to-buffer",
			options
		});
	}
	copyTextureToTexture(options) {
		this.commandBuffer.commands.push({
			name: "copy-texture-to-texture",
			options
		});
	}
	pushDebugGroup(groupLabel) {}
	popDebugGroup() {}
	insertDebugMarker(markerLabel) {}
	resolveQuerySet(querySet, destination, options) {}
};

//#endregion
//#region node_modules/@luma.gl/webgl/dist/utils/fill-array.js
function fillArray(options) {
	const { target: target$1, source, start = 0, count = 1 } = options;
	const length = source.length;
	const total = count * length;
	let copied = 0;
	for (let i = start; copied < length; copied++) target$1[i++] = source[copied];
	while (copied < total) if (copied < total - copied) {
		target$1.copyWithin(start + copied, start, start + copied);
		copied *= 2;
	} else {
		target$1.copyWithin(start + copied, start, start + total - copied);
		copied = total;
	}
	return options.target;
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/resources/webgl-vertex-array.js
/** VertexArrayObject wrapper */
var WEBGLVertexArray = class WEBGLVertexArray extends VertexArray {
	get [Symbol.toStringTag]() {
		return "VertexArray";
	}
	device;
	handle;
	/** Attribute 0 buffer constant */
	buffer = null;
	bufferValue = null;
	/** * Attribute 0 can not be disable on most desktop OpenGL based browsers */
	static isConstantAttributeZeroSupported(device) {
		return getBrowser() === "Chrome";
	}
	constructor(device, props) {
		super(device, props);
		this.device = device;
		this.handle = this.device.gl.createVertexArray();
	}
	destroy() {
		super.destroy();
		if (this.buffer) this.buffer?.destroy();
		if (this.handle) {
			this.device.gl.deleteVertexArray(this.handle);
			this.handle = void 0;
		}
	}
	/**
	// Set (bind/unbind) an elements buffer, for indexed rendering.
	// Must be a Buffer bound to GL.ELEMENT_ARRAY_BUFFER or null. Constants not supported
	*
	* @param elementBuffer
	*/
	setIndexBuffer(indexBuffer) {
		const buffer = indexBuffer;
		if (buffer && buffer.glTarget !== 34963) throw new Error("Use .setBuffer()");
		this.device.gl.bindVertexArray(this.handle);
		this.device.gl.bindBuffer(34963, buffer ? buffer.handle : null);
		this.indexBuffer = buffer;
		this.device.gl.bindVertexArray(null);
	}
	/** Set a location in vertex attributes array to a buffer, enables the location, sets divisor */
	setBuffer(location, attributeBuffer) {
		const buffer = attributeBuffer;
		if (buffer.glTarget === 34963) throw new Error("Use .setIndexBuffer()");
		const { size, type, stride, offset, normalized, integer, divisor } = this._getAccessor(location);
		this.device.gl.bindVertexArray(this.handle);
		this.device.gl.bindBuffer(34962, buffer.handle);
		if (integer) this.device.gl.vertexAttribIPointer(location, size, type, stride, offset);
		else this.device.gl.vertexAttribPointer(location, size, type, normalized, stride, offset);
		this.device.gl.bindBuffer(34962, null);
		this.device.gl.enableVertexAttribArray(location);
		this.device.gl.vertexAttribDivisor(location, divisor || 0);
		this.attributes[location] = buffer;
		this.device.gl.bindVertexArray(null);
	}
	/** Set a location in vertex attributes array to a constant value, disables the location */
	setConstantWebGL(location, value) {
		this._enable(location, false);
		this.attributes[location] = value;
	}
	bindBeforeRender() {
		this.device.gl.bindVertexArray(this.handle);
		this._applyConstantAttributes();
	}
	unbindAfterRender() {
		this.device.gl.bindVertexArray(null);
	}
	/**
	* Constant attributes need to be reset before every draw call
	* Any attribute that is disabled in the current vertex array object
	* is read from the context's global constant value for that attribute location.
	* @note Constant attributes are only supported in WebGL, not in WebGPU
	*/
	_applyConstantAttributes() {
		for (let location = 0; location < this.maxVertexAttributes; ++location) {
			const constant = this.attributes[location];
			if (ArrayBuffer.isView(constant)) this.device.setConstantAttributeWebGL(location, constant);
		}
	}
	/**
	* Set a location in vertex attributes array to a buffer, enables the location, sets divisor
	* @note requires vertex array to be bound
	*/
	/** Get an accessor from the  */
	_getAccessor(location) {
		const attributeInfo = this.attributeInfos[location];
		if (!attributeInfo) throw new Error(`Unknown attribute location ${location}`);
		const glType = getGLFromVertexType(attributeInfo.bufferDataType);
		return {
			size: attributeInfo.bufferComponents,
			type: glType,
			stride: attributeInfo.byteStride,
			offset: attributeInfo.byteOffset,
			normalized: attributeInfo.normalized,
			integer: attributeInfo.integer,
			divisor: attributeInfo.stepMode === "instance" ? 1 : 0
		};
	}
	/**
	* Enabling an attribute location makes it reference the currently bound buffer
	* Disabling an attribute location makes it reference the global constant value
	* TODO - handle single values for size 1 attributes?
	* TODO - convert classic arrays based on known type?
	*/
	_enable(location, enable$1 = true) {
		const canDisableAttribute = WEBGLVertexArray.isConstantAttributeZeroSupported(this.device) || location !== 0;
		if (enable$1 || canDisableAttribute) {
			location = Number(location);
			this.device.gl.bindVertexArray(this.handle);
			if (enable$1) this.device.gl.enableVertexAttribArray(location);
			else this.device.gl.disableVertexAttribArray(location);
			this.device.gl.bindVertexArray(null);
		}
	}
	/**
	* Provide a means to create a buffer that is equivalent to a constant.
	* NOTE: Desktop OpenGL cannot disable attribute 0.
	* https://stackoverflow.com/questions/20305231/webgl-warning-attribute-0-is-disabled-
	* this-has-significant-performance-penalty
	*/
	getConstantBuffer(elementCount, value) {
		const constantValue = normalizeConstantArrayValue(value);
		const byteLength = constantValue.byteLength * elementCount;
		const length = constantValue.length * elementCount;
		if (this.buffer && byteLength !== this.buffer.byteLength) throw new Error(`Buffer size is immutable, byte length ${byteLength} !== ${this.buffer.byteLength}.`);
		let updateNeeded = !this.buffer;
		this.buffer = this.buffer || this.device.createBuffer({ byteLength });
		updateNeeded ||= !compareConstantArrayValues$1(constantValue, this.bufferValue);
		if (updateNeeded) {
			const typedArray = getScratchArray(value.constructor, length);
			fillArray({
				target: typedArray,
				source: constantValue,
				start: 0,
				count: length
			});
			this.buffer.write(typedArray);
			this.bufferValue = value;
		}
		return this.buffer;
	}
};
/**
* TODO - convert Arrays based on known type? (read type from accessor, don't assume Float32Array)
* TODO - handle single values for size 1 attributes?
*/
function normalizeConstantArrayValue(arrayValue) {
	if (Array.isArray(arrayValue)) return new Float32Array(arrayValue);
	return arrayValue;
}
/**
*
*/
function compareConstantArrayValues$1(v1, v2) {
	if (!v1 || !v2 || v1.length !== v2.length || v1.constructor !== v2.constructor) return false;
	for (let i = 0; i < v1.length; ++i) if (v1[i] !== v2[i]) return false;
	return true;
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/resources/webgl-transform-feedback.js
var WEBGLTransformFeedback = class extends TransformFeedback {
	device;
	gl;
	handle;
	/**
	* NOTE: The Model already has this information while drawing, but
	* TransformFeedback currently needs it internally, to look up
	* varying information outside of a draw() call.
	*/
	layout;
	buffers = {};
	unusedBuffers = {};
	/**
	* Allows us to avoid a Chrome bug where a buffer that is already bound to a
	* different target cannot be bound to 'TRANSFORM_FEEDBACK_BUFFER' target.
	* This a major workaround, see: https://github.com/KhronosGroup/WebGL/issues/2346
	*/
	bindOnUse = true;
	_bound = false;
	constructor(device, props) {
		super(device, props);
		this.device = device;
		this.gl = device.gl;
		this.handle = this.props.handle || this.gl.createTransformFeedback();
		this.layout = this.props.layout;
		if (props.buffers) this.setBuffers(props.buffers);
		Object.seal(this);
	}
	destroy() {
		this.gl.deleteTransformFeedback(this.handle);
		super.destroy();
	}
	begin(topology = "point-list") {
		this.gl.bindTransformFeedback(36386, this.handle);
		if (this.bindOnUse) this._bindBuffers();
		this.gl.beginTransformFeedback(getGLPrimitive(topology));
	}
	end() {
		this.gl.endTransformFeedback();
		if (this.bindOnUse) this._unbindBuffers();
		this.gl.bindTransformFeedback(36386, null);
	}
	setBuffers(buffers) {
		this.buffers = {};
		this.unusedBuffers = {};
		this.bind(() => {
			for (const bufferName in buffers) this.setBuffer(bufferName, buffers[bufferName]);
		});
	}
	setBuffer(locationOrName, bufferOrRange) {
		const location = this._getVaryingIndex(locationOrName);
		const { buffer, byteLength, byteOffset } = this._getBufferRange(bufferOrRange);
		if (location < 0) {
			this.unusedBuffers[locationOrName] = buffer;
			log.warn(`${this.id} unusedBuffers varying buffer ${locationOrName}`)();
			return;
		}
		this.buffers[location] = {
			buffer,
			byteLength,
			byteOffset
		};
		if (!this.bindOnUse) this._bindBuffer(location, buffer, byteOffset, byteLength);
	}
	getBuffer(locationOrName) {
		if (isIndex(locationOrName)) return this.buffers[locationOrName] || null;
		const location = this._getVaryingIndex(locationOrName);
		return location >= 0 ? this.buffers[location] : null;
	}
	bind(funcOrHandle = this.handle) {
		if (typeof funcOrHandle !== "function") {
			this.gl.bindTransformFeedback(36386, funcOrHandle);
			return this;
		}
		let value;
		if (!this._bound) {
			this.gl.bindTransformFeedback(36386, this.handle);
			this._bound = true;
			value = funcOrHandle();
			this._bound = false;
			this.gl.bindTransformFeedback(36386, null);
		} else value = funcOrHandle();
		return value;
	}
	unbind() {
		this.bind(null);
	}
	/** Extract offsets for bindBufferRange */
	_getBufferRange(bufferOrRange) {
		if (bufferOrRange instanceof WEBGLBuffer) return {
			buffer: bufferOrRange,
			byteOffset: 0,
			byteLength: bufferOrRange.byteLength
		};
		const { buffer, byteOffset = 0, byteLength = bufferOrRange.buffer.byteLength } = bufferOrRange;
		return {
			buffer,
			byteOffset,
			byteLength
		};
	}
	_getVaryingIndex(locationOrName) {
		if (isIndex(locationOrName)) return Number(locationOrName);
		for (const varying of this.layout.varyings || []) if (locationOrName === varying.name) return varying.location;
		return -1;
	}
	/**
	* Need to avoid chrome bug where buffer that is already bound to a different target
	* cannot be bound to 'TRANSFORM_FEEDBACK_BUFFER' target.
	*/
	_bindBuffers() {
		for (const bufferIndex in this.buffers) {
			const { buffer, byteLength, byteOffset } = this._getBufferRange(this.buffers[bufferIndex]);
			this._bindBuffer(Number(bufferIndex), buffer, byteOffset, byteLength);
		}
	}
	_unbindBuffers() {
		for (const bufferIndex in this.buffers) this.gl.bindBufferBase(35982, Number(bufferIndex), null);
	}
	_bindBuffer(index, buffer, byteOffset = 0, byteLength) {
		const handle = buffer && buffer.handle;
		if (!handle || byteLength === void 0) this.gl.bindBufferBase(35982, index, handle);
		else this.gl.bindBufferRange(35982, index, handle, byteOffset, byteLength);
	}
};
/**
* Returns true if the given value is an integer, or a string that
* trivially converts to an integer (only numeric characters).
*/
function isIndex(value) {
	if (typeof value === "number") return Number.isInteger(value);
	return /^\d+$/.test(value);
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/resources/webgl-query-set.js
/**
* Asynchronous queries for different kinds of information
*/
var WEBGLQuerySet = class extends QuerySet {
	device;
	handle;
	target = null;
	_queryPending = false;
	_pollingPromise = null;
	get [Symbol.toStringTag]() {
		return "Query";
	}
	constructor(device, props) {
		super(device, props);
		this.device = device;
		if (props.count > 1) throw new Error("WebGL QuerySet can only have one value");
		const handle = this.device.gl.createQuery();
		if (!handle) throw new Error("WebGL query not supported");
		this.handle = handle;
		Object.seal(this);
	}
	destroy() {
		this.device.gl.deleteQuery(this.handle);
	}
	/**
	* Shortcut for timer query (dependent on extension in both WebGL1 and 2)
	* Measures GPU time delta between this call and a matching `end` call in the
	* GPU instruction stream.
	*/
	beginTimestampQuery() {
		return this._begin(35007);
	}
	endTimestampQuery() {
		this._end();
	}
	beginOcclusionQuery(options) {
		return this._begin(options?.conservative ? 36202 : 35887);
	}
	endOcclusionQuery() {
		this._end();
	}
	beginTransformFeedbackQuery() {
		return this._begin(35976);
	}
	endTransformFeedbackQuery() {
		this._end();
	}
	async resolveQuery() {
		return [await this.pollQuery()];
	}
	/**
	* Due to OpenGL API limitations, after calling `begin()` on one Query
	* instance, `end()` must be called on that same instance before
	* calling `begin()` on another query. While there can be multiple
	* outstanding queries representing disjoint `begin()`/`end()` intervals.
	* It is not possible to interleave or overlap `begin` and `end` calls.
	*/
	_begin(target$1) {
		if (this._queryPending) return;
		this.target = target$1;
		this.device.gl.beginQuery(this.target, this.handle);
	}
	_end() {
		if (this._queryPending) return;
		if (this.target) {
			this.device.gl.endQuery(this.target);
			this.target = null;
			this._queryPending = true;
		}
	}
	isResultAvailable() {
		if (!this._queryPending) return false;
		const resultAvailable = this.device.gl.getQueryParameter(this.handle, 34919);
		if (resultAvailable) this._queryPending = false;
		return resultAvailable;
	}
	isTimerDisjoint() {
		return this.device.gl.getParameter(36795);
	}
	getResult() {
		return this.device.gl.getQueryParameter(this.handle, 34918);
	}
	getTimerMilliseconds() {
		return this.getResult() / 1e6;
	}
	pollQuery(limit = Number.POSITIVE_INFINITY) {
		if (this._pollingPromise) return this._pollingPromise;
		let counter = 0;
		this._pollingPromise = new Promise((resolve, reject) => {
			const poll = () => {
				if (this.isResultAvailable()) {
					resolve(this.getResult());
					this._pollingPromise = null;
				} else if (counter++ > limit) {
					reject("Timed out");
					this._pollingPromise = null;
				} else requestAnimationFrame(poll);
			};
			requestAnimationFrame(poll);
		});
		return this._pollingPromise;
	}
};

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/helpers/format-utils.js
function glFormatToComponents(format) {
	switch (format) {
		case 6406:
		case 33326:
		case 6403:
		case 36244: return 1;
		case 33339:
		case 33340:
		case 33328:
		case 33320:
		case 33319: return 2;
		case 6407:
		case 36248:
		case 34837: return 3;
		case 6408:
		case 36249:
		case 34836: return 4;
		default: return 0;
	}
}
function glTypeToBytes(type) {
	switch (type) {
		case 5121: return 1;
		case 33635:
		case 32819:
		case 32820: return 2;
		case 5126: return 4;
		default: return 0;
	}
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/converters/shader-formats.js
/** Get shadertypes data type from GL constants */
function convertGLDataTypeToDataType(type) {
	return GL_DATA_TYPE_MAP[type];
}
var GL_DATA_TYPE_MAP = {
	[5124]: "sint32",
	[5125]: "uint32",
	[5122]: "sint16",
	[5123]: "uint16",
	[5120]: "sint8",
	[5121]: "uint8",
	[5126]: "float32",
	[5131]: "float16",
	[33635]: "uint16",
	[32819]: "uint16",
	[32820]: "uint16",
	[33640]: "uint32",
	[35899]: "uint32",
	[35902]: "uint32",
	[34042]: "uint32",
	[36269]: "uint32"
};
/** Get shader data type from GL constants *
export function getPrimitiveTypeFromGL(type: GL): PrimitiveDataType {
switch (type) {
case GL.INT:
return 'i32';
case GL.UNSIGNED_INT:
return 'u32';
case GL.SHORT:
return 'i32';
case GL.UNSIGNED_SHORT:
return 'u32';
case GL.BYTE:
return 'i32';
case GL.UNSIGNED_BYTE:
return 'u32';
case GL.FLOAT:
return 'f32';
case GL.HALF_FLOAT:
return 'f16';
default:
throw new Error(String(type));
}
}

/** Get shader attribute type from GL constants *
export function getShaderAttributeTypeFromGL(
type: GL,
components: 1 | 2 | 3 | 4
): AttributeShaderType {
const dataType = getPrimitiveTypeFromGL(type);
switch (components) {
case 1:
return dataType;
case 2:
return `vec2<${dataType}>`;
case 3:
return `vec2<${dataType}>`;
case 4:
return `vec2<${dataType}>`;
default:
throw new Error(String(components));
}
}
*/
/** GetGL constant from shader data type
export function getGLFromShaderDataType(
type: PrimitiveDataType
): GL.INT | GL.UNSIGNED_INT | GL.FLOAT | GL.HALF_FLOAT {
switch (type) {
// TODO
case 'i32':
return GL.INT;
case 'u32':
return GL.UNSIGNED_INT;
case 'f32':
return GL.FLOAT;
case 'f16':
return GL.HALF_FLOAT;
default:
throw new Error(String(type));
}
}
*/

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/helpers/webgl-texture-utils.js
/**
* Copies data from a type  or a Texture object into ArrayBuffer object.
* App can provide targetPixelArray or have it auto allocated by this method
*  newly allocated by this method unless provided by app.
* @deprecated Use CommandEncoder.copyTextureToBuffer and Buffer.read
* @note Slow requires roundtrip to GPU
*
* @param source
* @param options
* @returns pixel array,
*/
function readPixelsToArray(source, options) {
	const { sourceX = 0, sourceY = 0, sourceAttachment = 0 } = options || {};
	let { target: target$1 = null, sourceWidth, sourceHeight, sourceDepth, sourceFormat, sourceType } = options || {};
	const { framebuffer, deleteFramebuffer } = getFramebuffer(source);
	const { gl, handle } = framebuffer;
	sourceWidth ||= framebuffer.width;
	sourceHeight ||= framebuffer.height;
	const texture = framebuffer.colorAttachments[sourceAttachment]?.texture;
	if (!texture) throw new Error(`Invalid framebuffer attachment ${sourceAttachment}`);
	sourceDepth = texture?.depth || 1;
	sourceFormat ||= texture?.glFormat || 6408;
	sourceType ||= texture?.glType || 5121;
	target$1 = getPixelArray(target$1, sourceType, sourceFormat, sourceWidth, sourceHeight, sourceDepth);
	const signedType = getDataType(target$1);
	sourceType = sourceType || convertDataTypeToGLDataType(signedType);
	const prevHandle = gl.bindFramebuffer(36160, handle);
	gl.readBuffer(36064 + sourceAttachment);
	gl.readPixels(sourceX, sourceY, sourceWidth, sourceHeight, sourceFormat, sourceType, target$1);
	gl.readBuffer(36064);
	gl.bindFramebuffer(36160, prevHandle || null);
	if (deleteFramebuffer) framebuffer.destroy();
	return target$1;
}
/**
* Copies data from a Framebuffer or a Texture object into a Buffer object.
* NOTE: doesn't wait for copy to be complete, it programs GPU to perform a DMA transffer.
* @deprecated Use CommandEncoder
* @param source
* @param options
*/
function readPixelsToBuffer(source, options) {
	const { target: target$1, sourceX = 0, sourceY = 0, sourceFormat = 6408, targetByteOffset = 0 } = options || {};
	let { sourceWidth, sourceHeight, sourceType } = options || {};
	const { framebuffer, deleteFramebuffer } = getFramebuffer(source);
	sourceWidth = sourceWidth || framebuffer.width;
	sourceHeight = sourceHeight || framebuffer.height;
	const webglFramebuffer = framebuffer;
	sourceType = sourceType || 5121;
	let webglBufferTarget = target$1;
	if (!webglBufferTarget) {
		const components = glFormatToComponents(sourceFormat);
		const byteCount = glTypeToBytes(sourceType);
		const byteLength = targetByteOffset + sourceWidth * sourceHeight * components * byteCount;
		webglBufferTarget = webglFramebuffer.device.createBuffer({ byteLength });
	}
	const commandEncoder = source.device.createCommandEncoder();
	commandEncoder.copyTextureToBuffer({
		sourceTexture: source,
		width: sourceWidth,
		height: sourceHeight,
		origin: [sourceX, sourceY],
		destinationBuffer: webglBufferTarget,
		byteOffset: targetByteOffset
	});
	commandEncoder.destroy();
	if (deleteFramebuffer) framebuffer.destroy();
	return webglBufferTarget;
}
function getFramebuffer(source) {
	if (!(source instanceof Framebuffer)) return {
		framebuffer: toFramebuffer(source),
		deleteFramebuffer: true
	};
	return {
		framebuffer: source,
		deleteFramebuffer: false
	};
}
/**
* Wraps a given texture into a framebuffer object, that can be further used
* to read data from the texture object.
*/
function toFramebuffer(texture, props) {
	const { device, width, height, id } = texture;
	return device.createFramebuffer({
		...props,
		id: `framebuffer-for-${id}`,
		width,
		height,
		colorAttachments: [texture]
	});
}
function getPixelArray(pixelArray, glType, glFormat, width, height, depth) {
	if (pixelArray) return pixelArray;
	glType ||= 5121;
	const ArrayType = getTypedArrayConstructor(convertGLDataTypeToDataType(glType));
	const components = glFormatToComponents(glFormat);
	return new ArrayType(width * height * components);
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/webgl-device.js
/** WebGPU style Device API for a WebGL context */
var WebGLDevice = class extends Device {
	/** type of this device */
	type = "webgl";
	/** The underlying WebGL context */
	handle;
	features;
	limits;
	info;
	canvasContext;
	preferredColorFormat = "rgba8unorm";
	preferredDepthFormat = "depth24plus";
	commandEncoder;
	lost;
	_resolveContextLost;
	/** WebGL2 context. */
	gl;
	/** Store constants */
	_constants;
	/** State used by luma.gl classes - TODO - not used? */
	_extensions = {};
	_polyfilled = false;
	/** Instance of Spector.js (if initialized) */
	spectorJS;
	get [Symbol.toStringTag]() {
		return "WebGLDevice";
	}
	toString() {
		return `${this[Symbol.toStringTag]}(${this.id})`;
	}
	isVertexFormatSupported(format) {
		switch (format) {
			case "unorm8x4-bgra": return false;
			default: return true;
		}
	}
	constructor(props) {
		super({
			...props,
			id: props.id || uid("webgl-device")
		});
		const canvasContextProps = Device._getCanvasContextProps(props);
		if (!canvasContextProps) throw new Error("WebGLDevice requires props.createCanvasContext to be set");
		let device = canvasContextProps.canvas?.gl?.device;
		if (device) throw new Error(`WebGL context already attached to device ${device.id}`);
		this.canvasContext = new WebGLCanvasContext(this, canvasContextProps);
		this.lost = new Promise((resolve) => {
			this._resolveContextLost = resolve;
		});
		const webglContextAttributes = { ...props.webgl };
		if (canvasContextProps.alphaMode === "premultiplied") webglContextAttributes.premultipliedAlpha = true;
		if (props.powerPreference !== void 0) webglContextAttributes.powerPreference = props.powerPreference;
		const gl = this.props._handle || createBrowserContext(this.canvasContext.canvas, {
			onContextLost: (event) => this._resolveContextLost?.({
				reason: "destroyed",
				message: "Entered sleep mode, or too many apps or browser tabs are using the GPU."
			}),
			onContextRestored: (event) => console.log("WebGL context restored")
		}, webglContextAttributes);
		if (!gl) throw new Error("WebGL context creation failed");
		device = gl.device;
		if (device) {
			if (props._reuseDevices) {
				log.log(1, `Not creating a new Device, instead returning a reference to Device ${device.id} already attached to WebGL context`, device)();
				device._reused = true;
				return device;
			}
			throw new Error(`WebGL context already attached to device ${device.id}`);
		}
		this.handle = gl;
		this.gl = gl;
		this.spectorJS = initializeSpectorJS({
			...this.props,
			gl: this.handle
		});
		this.gl.device = this;
		this.gl._version = 2;
		this.info = getDeviceInfo(this.gl, this._extensions);
		this.limits = new WebGLDeviceLimits(this.gl);
		this.features = new WebGLDeviceFeatures(this.gl, this._extensions, this.props._disabledFeatures);
		if (this.props._initializeFeatures) this.features.initializeFeatures();
		new WebGLStateTracker(this.gl, { log: (...args) => log.log(1, ...args)() }).trackState(this.gl, { copyState: false });
		const debugWebGL = props.debugWebGL || props.debug;
		const traceWebGL = props.debugWebGL;
		if (debugWebGL) {
			this.gl = makeDebugContext(this.gl, {
				debugWebGL,
				traceWebGL
			});
			log.warn("WebGL debug mode activated. Performance reduced.")();
			if (props.debugWebGL) log.level = Math.max(log.level, 1);
		}
		this.commandEncoder = new WEBGLCommandEncoder(this, { id: `${this}-command-encoder` });
	}
	/**
	* Destroys the device
	*
	* @note "Detaches" from the WebGL context unless _reuseDevices is true.
	*
	* @note The underlying WebGL context is not immediately destroyed,
	* but may be destroyed later through normal JavaScript garbage collection.
	* This is a fundamental limitation since WebGL does not offer any
	* browser API for destroying WebGL contexts.
	*/
	destroy() {
		if (!this.props._reuseDevices && !this._reused) delete this.gl.device;
	}
	get isLost() {
		return this.gl.isContextLost();
	}
	getTextureByteAlignment() {
		return 4;
	}
	createCanvasContext(props) {
		throw new Error("WebGL only supports a single canvas");
	}
	createBuffer(props) {
		const newProps = this._normalizeBufferProps(props);
		return new WEBGLBuffer(this, newProps);
	}
	createTexture(props) {
		return new WEBGLTexture(this, props);
	}
	createExternalTexture(props) {
		throw new Error("createExternalTexture() not implemented");
	}
	createSampler(props) {
		return new WEBGLSampler(this, props);
	}
	createShader(props) {
		return new WEBGLShader(this, props);
	}
	createFramebuffer(props) {
		return new WEBGLFramebuffer(this, props);
	}
	createVertexArray(props) {
		return new WEBGLVertexArray(this, props);
	}
	createTransformFeedback(props) {
		return new WEBGLTransformFeedback(this, props);
	}
	createQuerySet(props) {
		return new WEBGLQuerySet(this, props);
	}
	createRenderPipeline(props) {
		return new WEBGLRenderPipeline(this, props);
	}
	createComputePipeline(props) {
		throw new Error("ComputePipeline not supported in WebGL");
	}
	createCommandEncoder(props = {}) {
		return new WEBGLCommandEncoder(this, props);
	}
	/**
	* Offscreen Canvas Support: Commit the frame
	* https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/commit
	* Chrome's offscreen canvas does not require gl.commit
	*/
	submit(commandBuffer) {
		if (!commandBuffer) {
			commandBuffer = this.commandEncoder.finish();
			this.commandEncoder.destroy();
			this.commandEncoder = this.createCommandEncoder({ id: `${this.id}-default-encoder` });
		}
		commandBuffer._executeCommands();
	}
	/** @deprecated - should use command encoder */
	readPixelsToArrayWebGL(source, options) {
		return readPixelsToArray(source, options);
	}
	/** @deprecated - should use command encoder */
	readPixelsToBufferWebGL(source, options) {
		return readPixelsToBuffer(source, options);
	}
	setParametersWebGL(parameters) {
		setGLParameters(this.gl, parameters);
	}
	getParametersWebGL(parameters) {
		return getGLParameters(this.gl, parameters);
	}
	withParametersWebGL(parameters, func) {
		return withGLParameters(this.gl, parameters, func);
	}
	resetWebGL() {
		log.warn("WebGLDevice.resetWebGL is deprecated, use only for debugging")();
		resetGLParameters(this.gl);
	}
	_getDeviceSpecificTextureFormatCapabilities(capabilities) {
		return getTextureFormatCapabilitiesWebGL(this.gl, capabilities, this._extensions);
	}
	/**
	* Triggers device (or WebGL context) loss.
	* @note primarily intended for testing how application reacts to device loss
	*/
	loseDevice() {
		let deviceLossTriggered = false;
		const ext = this.getExtension("WEBGL_lose_context").WEBGL_lose_context;
		if (ext) {
			deviceLossTriggered = true;
			ext.loseContext();
		}
		this._resolveContextLost?.({
			reason: "destroyed",
			message: "Application triggered context loss"
		});
		return deviceLossTriggered;
	}
	/** Save current WebGL context state onto an internal stack */
	pushState() {
		WebGLStateTracker.get(this.gl).push();
	}
	/** Restores previously saved context state */
	popState() {
		WebGLStateTracker.get(this.gl).pop();
	}
	/**
	* Returns the GL.<KEY> constant that corresponds to a numeric value of a GL constant
	* Be aware that there are some duplicates especially for constants that are 0,
	* so this isn't guaranteed to return the right key in all cases.
	*/
	getGLKey(value, options) {
		const number = Number(value);
		for (const key in this.gl) if (this.gl[key] === number) return `GL.${key}`;
		return options?.emptyIfUnknown ? "" : String(value);
	}
	/**
	* Returns a map with any GL.<KEY> constants mapped to strings, both for keys and values
	*/
	getGLKeys(glParameters) {
		const opts = { emptyIfUnknown: true };
		return Object.entries(glParameters).reduce((keys, [key, value]) => {
			keys[`${key}:${this.getGLKey(key, opts)}`] = `${value}:${this.getGLKey(value, opts)}`;
			return keys;
		}, {});
	}
	/**
	* Set a constant value for a location. Disabled attributes at that location will read from this value
	* @note WebGL constants are stored globally on the WebGL context, not the VertexArray
	* so they need to be updated before every render
	* @todo - remember/cache values to avoid setting them unnecessarily?
	*/
	setConstantAttributeWebGL(location, constant) {
		const maxVertexAttributes = this.limits.maxVertexAttributes;
		this._constants = this._constants || new Array(maxVertexAttributes).fill(null);
		const currentConstant = this._constants[location];
		if (currentConstant && compareConstantArrayValues(currentConstant, constant)) log.info(1, `setConstantAttributeWebGL(${location}) could have been skipped, value unchanged`)();
		this._constants[location] = constant;
		switch (constant.constructor) {
			case Float32Array:
				setConstantFloatArray(this, location, constant);
				break;
			case Int32Array:
				setConstantIntArray(this, location, constant);
				break;
			case Uint32Array:
				setConstantUintArray(this, location, constant);
				break;
			default: throw new Error("constant");
		}
	}
	/** Ensure extensions are only requested once */
	getExtension(name$1) {
		getWebGLExtension(this.gl, name$1, this._extensions);
		return this._extensions;
	}
	/**
	* Storing data on a special field on WebGLObjects makes that data visible in SPECTOR chrome debug extension
	* luma.gl ids and props can be inspected
	*/
	_setWebGLDebugMetadata(handle, resource, options) {
		handle.luma = resource;
		handle.__SPECTOR_Metadata = {
			props: options.spector,
			id: options.spector["id"]
		};
	}
};
/** Set constant float array attribute */
function setConstantFloatArray(device, location, array) {
	switch (array.length) {
		case 1:
			device.gl.vertexAttrib1fv(location, array);
			break;
		case 2:
			device.gl.vertexAttrib2fv(location, array);
			break;
		case 3:
			device.gl.vertexAttrib3fv(location, array);
			break;
		case 4:
			device.gl.vertexAttrib4fv(location, array);
			break;
		default:
	}
}
/** Set constant signed int array attribute */
function setConstantIntArray(device, location, array) {
	device.gl.vertexAttribI4iv(location, array);
}
/** Set constant unsigned int array attribute */
function setConstantUintArray(device, location, array) {
	device.gl.vertexAttribI4uiv(location, array);
}
/**
* Compares contents of two typed arrays
* @todo max length?
*/
function compareConstantArrayValues(v1, v2) {
	if (!v1 || !v2 || v1.length !== v2.length || v1.constructor !== v2.constructor) return false;
	for (let i = 0; i < v1.length; ++i) if (v1[i] !== v2[i]) return false;
	return true;
}

//#endregion
export { RenderPipeline as a, Texture as c, getVariableShaderTypeInfo as i, Sampler as l, getScratchArrayBuffer as n, Shader as o, getAttributeInfosFromLayouts as r, TextureView as s, WebGLDevice as t };
//# sourceMappingURL=webgl-device-Dj1w3AsR.js.map
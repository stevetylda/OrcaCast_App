//#region node_modules/@probe.gl/env/dist/lib/globals.js
var window_ = globalThis;
var document_ = globalThis.document || {};
var process_ = globalThis.process || {};
var console_ = globalThis.console;
var navigator_ = globalThis.navigator || {};

//#endregion
//#region node_modules/@probe.gl/env/dist/lib/is-electron.js
function isElectron(mockUserAgent) {
	if (typeof window !== "undefined" && window.process?.type === "renderer") return true;
	if (typeof process !== "undefined" && Boolean(process.versions?.["electron"])) return true;
	const realUserAgent = typeof navigator !== "undefined" && navigator.userAgent;
	const userAgent = mockUserAgent || realUserAgent;
	return Boolean(userAgent && userAgent.indexOf("Electron") >= 0);
}

//#endregion
//#region node_modules/@probe.gl/env/dist/lib/is-browser.js
/** Check if in browser by duck-typing Node context */
function isBrowser() {
	return !(typeof process === "object" && String(process) === "[object process]" && !process?.browser) || isElectron();
}

//#endregion
//#region node_modules/@probe.gl/env/dist/lib/get-browser.js
function getBrowser(mockUserAgent) {
	if (!mockUserAgent && !isBrowser()) return "Node";
	if (isElectron(mockUserAgent)) return "Electron";
	if ((mockUserAgent || navigator_.userAgent || "").indexOf("Edge") > -1) return "Edge";
	if (globalThis.chrome) return "Chrome";
	if (globalThis.safari) return "Safari";
	if (globalThis.mozInnerScreenX) return "Firefox";
	return "Unknown";
}

//#endregion
//#region node_modules/@probe.gl/env/dist/index.js
const VERSION = "4.1.0";

//#endregion
//#region node_modules/@probe.gl/log/dist/utils/local-storage.js
function getStorage(type) {
	try {
		const storage = window[type];
		const x = "__storage_test__";
		storage.setItem(x, x);
		storage.removeItem(x);
		return storage;
	} catch (e) {
		return null;
	}
}
var LocalStorage = class {
	constructor(id, defaultConfig, type = "sessionStorage") {
		this.storage = getStorage(type);
		this.id = id;
		this.config = defaultConfig;
		this._loadConfiguration();
	}
	getConfiguration() {
		return this.config;
	}
	setConfiguration(configuration) {
		Object.assign(this.config, configuration);
		if (this.storage) {
			const serialized = JSON.stringify(this.config);
			this.storage.setItem(this.id, serialized);
		}
	}
	_loadConfiguration() {
		let configuration = {};
		if (this.storage) {
			const serializedConfiguration = this.storage.getItem(this.id);
			configuration = serializedConfiguration ? JSON.parse(serializedConfiguration) : {};
		}
		Object.assign(this.config, configuration);
		return this;
	}
};

//#endregion
//#region node_modules/@probe.gl/log/dist/utils/formatters.js
/**
* Format time
*/
function formatTime(ms) {
	let formatted;
	if (ms < 10) formatted = `${ms.toFixed(2)}ms`;
	else if (ms < 100) formatted = `${ms.toFixed(1)}ms`;
	else if (ms < 1e3) formatted = `${ms.toFixed(0)}ms`;
	else formatted = `${(ms / 1e3).toFixed(2)}s`;
	return formatted;
}
function leftPad(string, length = 8) {
	const padLength = Math.max(length - string.length, 0);
	return `${" ".repeat(padLength)}${string}`;
}

//#endregion
//#region node_modules/@probe.gl/log/dist/utils/color.js
var COLOR;
(function(COLOR$1) {
	COLOR$1[COLOR$1["BLACK"] = 30] = "BLACK";
	COLOR$1[COLOR$1["RED"] = 31] = "RED";
	COLOR$1[COLOR$1["GREEN"] = 32] = "GREEN";
	COLOR$1[COLOR$1["YELLOW"] = 33] = "YELLOW";
	COLOR$1[COLOR$1["BLUE"] = 34] = "BLUE";
	COLOR$1[COLOR$1["MAGENTA"] = 35] = "MAGENTA";
	COLOR$1[COLOR$1["CYAN"] = 36] = "CYAN";
	COLOR$1[COLOR$1["WHITE"] = 37] = "WHITE";
	COLOR$1[COLOR$1["BRIGHT_BLACK"] = 90] = "BRIGHT_BLACK";
	COLOR$1[COLOR$1["BRIGHT_RED"] = 91] = "BRIGHT_RED";
	COLOR$1[COLOR$1["BRIGHT_GREEN"] = 92] = "BRIGHT_GREEN";
	COLOR$1[COLOR$1["BRIGHT_YELLOW"] = 93] = "BRIGHT_YELLOW";
	COLOR$1[COLOR$1["BRIGHT_BLUE"] = 94] = "BRIGHT_BLUE";
	COLOR$1[COLOR$1["BRIGHT_MAGENTA"] = 95] = "BRIGHT_MAGENTA";
	COLOR$1[COLOR$1["BRIGHT_CYAN"] = 96] = "BRIGHT_CYAN";
	COLOR$1[COLOR$1["BRIGHT_WHITE"] = 97] = "BRIGHT_WHITE";
})(COLOR || (COLOR = {}));
var BACKGROUND_INCREMENT = 10;
function getColor(color) {
	if (typeof color !== "string") return color;
	color = color.toUpperCase();
	return COLOR[color] || COLOR.WHITE;
}
function addColor(string, color, background) {
	if (!isBrowser && typeof string === "string") {
		if (color) string = `\u001b[${getColor(color)}m${string}\u001b[39m`;
		if (background) string = `\u001b[${getColor(background) + BACKGROUND_INCREMENT}m${string}\u001b[49m`;
	}
	return string;
}

//#endregion
//#region node_modules/@probe.gl/log/dist/utils/autobind.js
/**
* Binds the "this" argument of all functions on a class instance to the instance
* @param obj - class instance (typically a react component)
*/
function autobind(obj, predefined = ["constructor"]) {
	const proto = Object.getPrototypeOf(obj);
	const propNames = Object.getOwnPropertyNames(proto);
	const object = obj;
	for (const key of propNames) {
		const value = object[key];
		if (typeof value === "function") {
			if (!predefined.find((name$1) => key === name$1)) object[key] = value.bind(obj);
		}
	}
}

//#endregion
//#region node_modules/@probe.gl/log/dist/utils/assert.js
function assert(condition, message$1) {
	if (!condition) throw new Error(message$1 || "Assertion failed");
}

//#endregion
//#region node_modules/@probe.gl/log/dist/utils/hi-res-timestamp.js
/** Get best timer available. */
function getHiResTimestamp$1() {
	let timestamp;
	if (isBrowser() && window_.performance) timestamp = window_?.performance?.now?.();
	else if ("hrtime" in process_) {
		const timeParts = process_?.hrtime?.();
		timestamp = timeParts[0] * 1e3 + timeParts[1] / 1e6;
	} else timestamp = Date.now();
	return timestamp;
}

//#endregion
//#region node_modules/@probe.gl/log/dist/log.js
var originalConsole = {
	debug: isBrowser() ? console.debug || console.log : console.log,
	log: console.log,
	info: console.info,
	warn: console.warn,
	error: console.error
};
var DEFAULT_LOG_CONFIGURATION = {
	enabled: true,
	level: 0
};
function noop() {}
var cache = {};
var ONCE = { once: true };
/** A console wrapper */
var Log = class {
	constructor({ id } = { id: "" }) {
		this.VERSION = VERSION;
		this._startTs = getHiResTimestamp$1();
		this._deltaTs = getHiResTimestamp$1();
		this.userData = {};
		this.LOG_THROTTLE_TIMEOUT = 0;
		this.id = id;
		this.userData = {};
		this._storage = new LocalStorage(`__probe-${this.id}__`, DEFAULT_LOG_CONFIGURATION);
		this.timeStamp(`${this.id} started`);
		autobind(this);
		Object.seal(this);
	}
	set level(newLevel) {
		this.setLevel(newLevel);
	}
	get level() {
		return this.getLevel();
	}
	isEnabled() {
		return this._storage.config.enabled;
	}
	getLevel() {
		return this._storage.config.level;
	}
	/** @return milliseconds, with fractions */
	getTotal() {
		return Number((getHiResTimestamp$1() - this._startTs).toPrecision(10));
	}
	/** @return milliseconds, with fractions */
	getDelta() {
		return Number((getHiResTimestamp$1() - this._deltaTs).toPrecision(10));
	}
	/** @deprecated use logLevel */
	set priority(newPriority) {
		this.level = newPriority;
	}
	/** @deprecated use logLevel */
	get priority() {
		return this.level;
	}
	/** @deprecated use logLevel */
	getPriority() {
		return this.level;
	}
	enable(enabled = true) {
		this._storage.setConfiguration({ enabled });
		return this;
	}
	setLevel(level) {
		this._storage.setConfiguration({ level });
		return this;
	}
	/** return the current status of the setting */
	get(setting) {
		return this._storage.config[setting];
	}
	set(setting, value) {
		this._storage.setConfiguration({ [setting]: value });
	}
	/** Logs the current settings as a table */
	settings() {
		if (console.table) console.table(this._storage.config);
		else console.log(this._storage.config);
	}
	assert(condition, message$1) {
		if (!condition) throw new Error(message$1 || "Assertion failed");
	}
	warn(message$1) {
		return this._getLogFunction(0, message$1, originalConsole.warn, arguments, ONCE);
	}
	error(message$1) {
		return this._getLogFunction(0, message$1, originalConsole.error, arguments);
	}
	/** Print a deprecation warning */
	deprecated(oldUsage, newUsage) {
		return this.warn(`\`${oldUsage}\` is deprecated and will be removed \
in a later version. Use \`${newUsage}\` instead`);
	}
	/** Print a removal warning */
	removed(oldUsage, newUsage) {
		return this.error(`\`${oldUsage}\` has been removed. Use \`${newUsage}\` instead`);
	}
	probe(logLevel, message$1) {
		return this._getLogFunction(logLevel, message$1, originalConsole.log, arguments, {
			time: true,
			once: true
		});
	}
	log(logLevel, message$1) {
		return this._getLogFunction(logLevel, message$1, originalConsole.debug, arguments);
	}
	info(logLevel, message$1) {
		return this._getLogFunction(logLevel, message$1, console.info, arguments);
	}
	once(logLevel, message$1) {
		return this._getLogFunction(logLevel, message$1, originalConsole.debug || originalConsole.info, arguments, ONCE);
	}
	/** Logs an object as a table */
	table(logLevel, table, columns) {
		if (table) return this._getLogFunction(logLevel, table, console.table || noop, columns && [columns], { tag: getTableHeader(table) });
		return noop;
	}
	time(logLevel, message$1) {
		return this._getLogFunction(logLevel, message$1, console.time ? console.time : console.info);
	}
	timeEnd(logLevel, message$1) {
		return this._getLogFunction(logLevel, message$1, console.timeEnd ? console.timeEnd : console.info);
	}
	timeStamp(logLevel, message$1) {
		return this._getLogFunction(logLevel, message$1, console.timeStamp || noop);
	}
	group(logLevel, message$1, opts = { collapsed: false }) {
		const options = normalizeArguments({
			logLevel,
			message: message$1,
			opts
		});
		const { collapsed } = opts;
		options.method = (collapsed ? console.groupCollapsed : console.group) || console.info;
		return this._getLogFunction(options);
	}
	groupCollapsed(logLevel, message$1, opts = {}) {
		return this.group(logLevel, message$1, Object.assign({}, opts, { collapsed: true }));
	}
	groupEnd(logLevel) {
		return this._getLogFunction(logLevel, "", console.groupEnd || noop);
	}
	withGroup(logLevel, message$1, func) {
		this.group(logLevel, message$1)();
		try {
			func();
		} finally {
			this.groupEnd(logLevel)();
		}
	}
	trace() {
		if (console.trace) console.trace();
	}
	/** Deduces log level from a variety of arguments */
	_shouldLog(logLevel) {
		return this.isEnabled() && this.getLevel() >= normalizeLogLevel(logLevel);
	}
	_getLogFunction(logLevel, message$1, method, args, opts) {
		if (this._shouldLog(logLevel)) {
			opts = normalizeArguments({
				logLevel,
				message: message$1,
				args,
				opts
			});
			method = method || opts.method;
			assert(method);
			opts.total = this.getTotal();
			opts.delta = this.getDelta();
			this._deltaTs = getHiResTimestamp$1();
			const tag = opts.tag || opts.message;
			if (opts.once && tag) if (!cache[tag]) cache[tag] = getHiResTimestamp$1();
			else return noop;
			message$1 = decorateMessage(this.id, opts.message, opts);
			return method.bind(console, message$1, ...opts.args);
		}
		return noop;
	}
};
Log.VERSION = VERSION;
/**
* Get logLevel from first argument:
* - log(logLevel, message, args) => logLevel
* - log(message, args) => 0
* - log({logLevel, ...}, message, args) => logLevel
* - log({logLevel, message, args}) => logLevel
*/
function normalizeLogLevel(logLevel) {
	if (!logLevel) return 0;
	let resolvedLevel;
	switch (typeof logLevel) {
		case "number":
			resolvedLevel = logLevel;
			break;
		case "object":
			resolvedLevel = logLevel.logLevel || logLevel.priority || 0;
			break;
		default: return 0;
	}
	assert(Number.isFinite(resolvedLevel) && resolvedLevel >= 0);
	return resolvedLevel;
}
/**
* "Normalizes" the various argument patterns into an object with known types
* - log(logLevel, message, args) => {logLevel, message, args}
* - log(message, args) => {logLevel: 0, message, args}
* - log({logLevel, ...}, message, args) => {logLevel, message, args}
* - log({logLevel, message, args}) => {logLevel, message, args}
*/
function normalizeArguments(opts) {
	const { logLevel, message: message$1 } = opts;
	opts.logLevel = normalizeLogLevel(logLevel);
	const args = opts.args ? Array.from(opts.args) : [];
	while (args.length && args.shift() !== message$1);
	switch (typeof logLevel) {
		case "string":
		case "function":
			if (message$1 !== void 0) args.unshift(message$1);
			opts.message = logLevel;
			break;
		case "object":
			Object.assign(opts, logLevel);
			break;
		default:
	}
	if (typeof opts.message === "function") opts.message = opts.message();
	const messageType = typeof opts.message;
	assert(messageType === "string" || messageType === "object");
	return Object.assign(opts, { args }, opts.opts);
}
function decorateMessage(id, message$1, opts) {
	if (typeof message$1 === "string") {
		const time = opts.time ? leftPad(formatTime(opts.total)) : "";
		message$1 = opts.time ? `${id}: ${time}  ${message$1}` : `${id}: ${message$1}`;
		message$1 = addColor(message$1, opts.color, opts.background);
	}
	return message$1;
}
function getTableHeader(table) {
	for (const key in table) for (const title in table[key]) return title || "untitled";
	return "empty";
}

//#endregion
//#region node_modules/@probe.gl/log/dist/init.js
globalThis.probe = {};

//#endregion
//#region node_modules/@probe.gl/log/dist/index.js
var dist_default = new Log({ id: "@probe.gl/log" });

//#endregion
//#region node_modules/@probe.gl/stats/dist/utils/hi-res-timestamp.js
function getHiResTimestamp() {
	let timestamp;
	if (typeof window !== "undefined" && window.performance) timestamp = window.performance.now();
	else if (typeof process !== "undefined" && process.hrtime) {
		const timeParts = process.hrtime();
		timestamp = timeParts[0] * 1e3 + timeParts[1] / 1e6;
	} else timestamp = Date.now();
	return timestamp;
}

//#endregion
//#region node_modules/@probe.gl/stats/dist/lib/stat.js
var Stat = class {
	constructor(name$1, type) {
		this.sampleSize = 1;
		this.time = 0;
		this.count = 0;
		this.samples = 0;
		this.lastTiming = 0;
		this.lastSampleTime = 0;
		this.lastSampleCount = 0;
		this._count = 0;
		this._time = 0;
		this._samples = 0;
		this._startTime = 0;
		this._timerPending = false;
		this.name = name$1;
		this.type = type;
		this.reset();
	}
	reset() {
		this.time = 0;
		this.count = 0;
		this.samples = 0;
		this.lastTiming = 0;
		this.lastSampleTime = 0;
		this.lastSampleCount = 0;
		this._count = 0;
		this._time = 0;
		this._samples = 0;
		this._startTime = 0;
		this._timerPending = false;
		return this;
	}
	setSampleSize(samples) {
		this.sampleSize = samples;
		return this;
	}
	/** Call to increment count (+1) */
	incrementCount() {
		this.addCount(1);
		return this;
	}
	/** Call to decrement count (-1) */
	decrementCount() {
		this.subtractCount(1);
		return this;
	}
	/** Increase count */
	addCount(value) {
		this._count += value;
		this._samples++;
		this._checkSampling();
		return this;
	}
	/** Decrease count */
	subtractCount(value) {
		this._count -= value;
		this._samples++;
		this._checkSampling();
		return this;
	}
	/** Add an arbitrary timing and bump the count */
	addTime(time) {
		this._time += time;
		this.lastTiming = time;
		this._samples++;
		this._checkSampling();
		return this;
	}
	/** Start a timer */
	timeStart() {
		this._startTime = getHiResTimestamp();
		this._timerPending = true;
		return this;
	}
	/** End a timer. Adds to time and bumps the timing count. */
	timeEnd() {
		if (!this._timerPending) return this;
		this.addTime(getHiResTimestamp() - this._startTime);
		this._timerPending = false;
		this._checkSampling();
		return this;
	}
	getSampleAverageCount() {
		return this.sampleSize > 0 ? this.lastSampleCount / this.sampleSize : 0;
	}
	/** Calculate average time / count for the previous window */
	getSampleAverageTime() {
		return this.sampleSize > 0 ? this.lastSampleTime / this.sampleSize : 0;
	}
	/** Calculate counts per second for the previous window */
	getSampleHz() {
		return this.lastSampleTime > 0 ? this.sampleSize / (this.lastSampleTime / 1e3) : 0;
	}
	getAverageCount() {
		return this.samples > 0 ? this.count / this.samples : 0;
	}
	/** Calculate average time / count */
	getAverageTime() {
		return this.samples > 0 ? this.time / this.samples : 0;
	}
	/** Calculate counts per second */
	getHz() {
		return this.time > 0 ? this.samples / (this.time / 1e3) : 0;
	}
	_checkSampling() {
		if (this._samples === this.sampleSize) {
			this.lastSampleTime = this._time;
			this.lastSampleCount = this._count;
			this.count += this._count;
			this.time += this._time;
			this.samples += this._samples;
			this._time = 0;
			this._count = 0;
			this._samples = 0;
		}
	}
};

//#endregion
//#region node_modules/@probe.gl/stats/dist/lib/stats.js
/** A "bag" of `Stat` objects, can be visualized using `StatsWidget` */
var Stats = class {
	constructor(options) {
		this.stats = {};
		this.id = options.id;
		this.stats = {};
		this._initializeStats(options.stats);
		Object.seal(this);
	}
	/** Acquire a stat. Create if it doesn't exist. */
	get(name$1, type = "count") {
		return this._getOrCreate({
			name: name$1,
			type
		});
	}
	get size() {
		return Object.keys(this.stats).length;
	}
	/** Reset all stats */
	reset() {
		for (const stat of Object.values(this.stats)) stat.reset();
		return this;
	}
	forEach(fn) {
		for (const stat of Object.values(this.stats)) fn(stat);
	}
	getTable() {
		const table = {};
		this.forEach((stat) => {
			table[stat.name] = {
				time: stat.time || 0,
				count: stat.count || 0,
				average: stat.getAverageTime() || 0,
				hz: stat.getHz() || 0
			};
		});
		return table;
	}
	_initializeStats(stats = []) {
		stats.forEach((stat) => this._getOrCreate(stat));
	}
	_getOrCreate(stat) {
		const { name: name$1, type } = stat;
		let result = this.stats[name$1];
		if (!result) {
			if (stat instanceof Stat) result = stat;
			else result = new Stat(name$1, type);
			this.stats[name$1] = result;
		}
		return result;
	}
};

//#endregion
//#region node_modules/@luma.gl/core/dist/utils/stats-manager.js
/**
* Helper class managing a collection of probe.gl stats objects
*/
var StatsManager = class {
	stats = /* @__PURE__ */ new Map();
	getStats(name$1) {
		return this.get(name$1);
	}
	get(name$1) {
		if (!this.stats.has(name$1)) this.stats.set(name$1, new Stats({ id: name$1 }));
		return this.stats.get(name$1);
	}
};
/** Global stats for all luma.gl devices */
const lumaStats = new StatsManager();

//#endregion
//#region node_modules/@luma.gl/core/dist/utils/log.js
/** Global log instance */
const log = new Log({ id: "luma.gl" });

//#endregion
//#region node_modules/@luma.gl/core/dist/utils/uid.js
var uidCounters$1 = {};
/**
* Returns a UID.
* @param id= - Identifier base name
* @return uid
**/
function uid$1(id = "id") {
	uidCounters$1[id] = uidCounters$1[id] || 1;
	return `${id}-${uidCounters$1[id]++}`;
}

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/resources/resource.js
/**
* Base class for GPU (WebGPU/WebGL) Resources
*/
var Resource = class {
	/** Default properties for resource */
	static defaultProps = {
		id: "undefined",
		handle: void 0,
		userData: void 0
	};
	toString() {
		return `${this[Symbol.toStringTag] || this.constructor.name}:"${this.id}"`;
	}
	/** props.id, for debugging. */
	id;
	props;
	userData = {};
	_device;
	/** Whether this resource has been destroyed */
	destroyed = false;
	/** For resources that allocate GPU memory */
	allocatedBytes = 0;
	/** Attached resources will be destroyed when this resource is destroyed. Tracks auto-created "sub" resources. */
	_attachedResources = /* @__PURE__ */ new Set();
	/**
	* Create a new Resource. Called from Subclass
	*/
	constructor(device, props, defaultProps) {
		if (!device) throw new Error("no device");
		this._device = device;
		this.props = selectivelyMerge(props, defaultProps);
		const id = this.props.id !== "undefined" ? this.props.id : uid$1(this[Symbol.toStringTag]);
		this.props.id = id;
		this.id = id;
		this.userData = this.props.userData || {};
		this.addStats();
	}
	/**
	* destroy can be called on any resource to release it before it is garbage collected.
	*/
	destroy() {
		this.destroyResource();
	}
	/** @deprecated Use destroy() */
	delete() {
		this.destroy();
		return this;
	}
	/**
	* Combines a map of user props and default props, only including props from defaultProps
	* @returns returns a map of overridden default props
	*/
	getProps() {
		return this.props;
	}
	/**
	* Attaches a resource. Attached resources are auto destroyed when this resource is destroyed
	* Called automatically when sub resources are auto created but can be called by application
	*/
	attachResource(resource) {
		this._attachedResources.add(resource);
	}
	/**
	* Detach an attached resource. The resource will no longer be auto-destroyed when this resource is destroyed.
	*/
	detachResource(resource) {
		this._attachedResources.delete(resource);
	}
	/**
	* Destroys a resource (only if owned), and removes from the owned (auto-destroy) list for this resource.
	*/
	destroyAttachedResource(resource) {
		if (this._attachedResources.delete(resource)) resource.destroy();
	}
	/** Destroy all owned resources. Make sure the resources are no longer needed before calling. */
	destroyAttachedResources() {
		for (const resource of Object.values(this._attachedResources)) resource.destroy();
		this._attachedResources = /* @__PURE__ */ new Set();
	}
	/** Perform all destroy steps. Can be called by derived resources when overriding destroy() */
	destroyResource() {
		this.destroyAttachedResources();
		this.removeStats();
		this.destroyed = true;
	}
	/** Called by .destroy() to track object destruction. Subclass must call if overriding destroy() */
	removeStats() {
		const stats = this._device.statsManager.getStats("Resource Counts");
		const name$1 = this[Symbol.toStringTag];
		stats.get(`${name$1}s Active`).decrementCount();
	}
	/** Called by subclass to track memory allocations */
	trackAllocatedMemory(bytes, name$1 = this[Symbol.toStringTag]) {
		const stats = this._device.statsManager.getStats("Resource Counts");
		stats.get("GPU Memory").addCount(bytes);
		stats.get(`${name$1} Memory`).addCount(bytes);
		this.allocatedBytes = bytes;
	}
	/** Called by subclass to track memory deallocations */
	trackDeallocatedMemory(name$1 = this[Symbol.toStringTag]) {
		const stats = this._device.statsManager.getStats("Resource Counts");
		stats.get("GPU Memory").subtractCount(this.allocatedBytes);
		stats.get(`${name$1} Memory`).subtractCount(this.allocatedBytes);
		this.allocatedBytes = 0;
	}
	/** Called by resource constructor to track object creation */
	addStats() {
		const stats = this._device.statsManager.getStats("Resource Counts");
		const name$1 = this[Symbol.toStringTag];
		stats.get("Resources Created").incrementCount();
		stats.get(`${name$1}s Created`).incrementCount();
		stats.get(`${name$1}s Active`).incrementCount();
	}
};
/**
* Combines a map of user props and default props, only including props from defaultProps
* @param props
* @param defaultProps
* @returns returns a map of overridden default props
*/
function selectivelyMerge(props, defaultProps) {
	const mergedProps = { ...defaultProps };
	for (const key in props) if (props[key] !== void 0) mergedProps[key] = props[key];
	return mergedProps;
}

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/resources/buffer.js
/** Abstract GPU buffer */
var Buffer = class Buffer extends Resource {
	/** Index buffer */
	static INDEX = 16;
	/** Vertex buffer */
	static VERTEX = 32;
	/** Uniform buffer */
	static UNIFORM = 64;
	/** Storage buffer */
	static STORAGE = 128;
	static INDIRECT = 256;
	static QUERY_RESOLVE = 512;
	static MAP_READ = 1;
	static MAP_WRITE = 2;
	static COPY_SRC = 4;
	static COPY_DST = 8;
	get [Symbol.toStringTag]() {
		return "Buffer";
	}
	/** The usage with which this buffer was created */
	usage;
	/** For index buffers, whether indices are 8, 16 or 32 bit. Note: uint8 indices are automatically converted to uint16 for WebGPU compatibility */
	indexType;
	/** "Time" of last update, can be used to check if redraw is needed */
	updateTimestamp;
	constructor(device, props) {
		const deducedProps = { ...props };
		if ((props.usage || 0) & Buffer.INDEX && !props.indexType) {
			if (props.data instanceof Uint32Array) deducedProps.indexType = "uint32";
			else if (props.data instanceof Uint16Array) deducedProps.indexType = "uint16";
			else if (props.data instanceof Uint8Array) deducedProps.indexType = "uint8";
		}
		delete deducedProps.data;
		super(device, deducedProps, Buffer.defaultProps);
		this.usage = deducedProps.usage || 0;
		this.indexType = deducedProps.indexType;
		this.updateTimestamp = device.incrementTimestamp();
	}
	/**
	* Create a copy of this Buffer with new byteLength, with same props but of the specified size.
	* @note Does not copy contents of the cloned Buffer.
	*/
	clone(props) {
		return this.device.createBuffer({
			...this.props,
			...props
		});
	}
	/** Max amount of debug data saved. Two vec4's */
	static DEBUG_DATA_MAX_LENGTH = 32;
	/** A partial CPU-side copy of the data in this buffer, for debugging purposes */
	debugData = /* @__PURE__ */ new ArrayBuffer(0);
	/** This doesn't handle partial non-zero offset updates correctly */
	_setDebugData(data, byteOffset, byteLength) {
		const arrayBuffer$1 = ArrayBuffer.isView(data) ? data.buffer : data;
		const debugDataLength = Math.min(data ? data.byteLength : byteLength, Buffer.DEBUG_DATA_MAX_LENGTH);
		if (arrayBuffer$1 === null) this.debugData = new ArrayBuffer(debugDataLength);
		else if (byteOffset === 0 && byteLength === arrayBuffer$1.byteLength) this.debugData = arrayBuffer$1.slice(0, debugDataLength);
		else this.debugData = arrayBuffer$1.slice(byteOffset, byteOffset + debugDataLength);
	}
	static defaultProps = {
		...Resource.defaultProps,
		usage: 0,
		byteLength: 0,
		byteOffset: 0,
		data: null,
		indexType: "uint16",
		onMapped: void 0
	};
};

//#endregion
//#region node_modules/@luma.gl/core/dist/shadertypes/data-types/decode-data-types.js
/**
* Gets info about a data type constant (signed or normalized)
* @returns underlying primitive / signed types, byte length, normalization, integer, signed flags
*/
function getDataTypeInfo(type) {
	const [signedType, primitiveType, byteLength] = NORMALIZED_TYPE_MAP[type];
	const normalized = type.includes("norm");
	return {
		signedType,
		primitiveType,
		byteLength,
		normalized,
		integer: !normalized && !type.startsWith("float"),
		signed: type.startsWith("s")
	};
}
/** Build a vertex format from a signed data type and a component */
function getNormalizedDataType(signedDataType) {
	const dataType = signedDataType;
	switch (dataType) {
		case "uint8": return "unorm8";
		case "sint8": return "snorm8";
		case "uint16": return "unorm16";
		case "sint16": return "snorm16";
		default: return dataType;
	}
}
/** Align offset to 1, 2 or 4 elements (4, 8 or 16 bytes) */
function alignTo(size, count) {
	switch (count) {
		case 1: return size;
		case 2: return size + size % 2;
		default: return size + (4 - size % 4) % 4;
	}
}
/** Returns the VariableShaderType that corresponds to a typed array */
function getDataType(arrayOrType) {
	const Constructor = ArrayBuffer.isView(arrayOrType) ? arrayOrType.constructor : arrayOrType;
	if (Constructor === Uint8ClampedArray) return "uint8";
	const info = Object.values(NORMALIZED_TYPE_MAP).find((entry) => Constructor === entry[4]);
	if (!info) throw new Error(Constructor.name);
	return info[0];
}
/** Returns the TypedArray that corresponds to a shader data type */
function getTypedArrayConstructor(type) {
	const [, , , , Constructor] = NORMALIZED_TYPE_MAP[type];
	return Constructor;
}
var NORMALIZED_TYPE_MAP = {
	uint8: [
		"uint8",
		"u32",
		1,
		false,
		Uint8Array
	],
	sint8: [
		"sint8",
		"i32",
		1,
		false,
		Int8Array
	],
	unorm8: [
		"uint8",
		"f32",
		1,
		true,
		Uint8Array
	],
	snorm8: [
		"sint8",
		"f32",
		1,
		true,
		Int8Array
	],
	uint16: [
		"uint16",
		"u32",
		2,
		false,
		Uint16Array
	],
	sint16: [
		"sint16",
		"i32",
		2,
		false,
		Int16Array
	],
	unorm16: [
		"uint16",
		"u32",
		2,
		true,
		Uint16Array
	],
	snorm16: [
		"sint16",
		"i32",
		2,
		true,
		Int16Array
	],
	float16: [
		"float16",
		"f16",
		2,
		false,
		Uint16Array
	],
	float32: [
		"float32",
		"f32",
		4,
		false,
		Float32Array
	],
	uint32: [
		"uint32",
		"u32",
		4,
		false,
		Uint32Array
	],
	sint32: [
		"sint32",
		"i32",
		4,
		false,
		Int32Array
	]
};

//#endregion
//#region node_modules/@luma.gl/core/dist/shadertypes/vertex-arrays/decode-vertex-format.js
/**
* Decodes a vertex format, returning type, components, byte  length and flags (integer, signed, normalized)
*/
function getVertexFormatInfo(format) {
	let webglOnly;
	if (format.endsWith("-webgl")) {
		format.replace("-webgl", "");
		webglOnly = true;
	}
	const [type_, count] = format.split("x");
	const type = type_;
	const components = count ? parseInt(count) : 1;
	const decodedType = getDataTypeInfo(type);
	const result = {
		type,
		components,
		byteLength: decodedType.byteLength * components,
		integer: decodedType.integer,
		signed: decodedType.signed,
		normalized: decodedType.normalized
	};
	if (webglOnly) result.webglOnly = true;
	return result;
}
/** Build a vertex format from a signed data type and a component */
function makeVertexFormat(signedDataType, components, normalized) {
	const dataType = normalized ? getNormalizedDataType(signedDataType) : signedDataType;
	switch (dataType) {
		case "unorm8":
			if (components === 1) return "unorm8";
			if (components === 3) return "unorm8x3-webgl";
			return `${dataType}x${components}`;
		case "snorm8":
		case "uint8":
		case "sint8":
		case "uint16":
		case "sint16":
		case "unorm16":
		case "snorm16":
		case "float16":
			if (components === 1 || components === 3) throw new Error(`size: ${components}`);
			return `${dataType}x${components}`;
		default: return components === 1 ? dataType : `${dataType}x${components}`;
	}
}
/** Get the vertex format for an attribute with TypedArray and size */
function getVertexFormatFromAttribute(typedArray, size, normalized) {
	if (!size || size > 4) throw new Error(`size ${size}`);
	const components = size;
	return makeVertexFormat(getDataType(typedArray), components, normalized);
}
/** Return a "default" vertex format for a certain shader data type
The simplest vertex format that matches the shader attribute's data type */
function getCompatibleVertexFormat(opts) {
	let vertexType;
	switch (opts.primitiveType) {
		case "f32":
			vertexType = "float32";
			break;
		case "i32":
			vertexType = "sint32";
			break;
		case "u32":
			vertexType = "uint32";
			break;
		case "f16": return opts.components <= 2 ? "float16x2" : "float16x4";
	}
	if (opts.components === 1) return vertexType;
	return `${vertexType}x${opts.components}`;
}

//#endregion
//#region node_modules/@luma.gl/core/dist/shadertypes/textures/texture-format-table.js
var texture_compression_bc = "texture-compression-bc";
var texture_compression_astc = "texture-compression-astc";
var texture_compression_etc2 = "texture-compression-etc2";
var texture_compression_etc1_webgl = "texture-compression-etc1-webgl";
var texture_compression_pvrtc_webgl = "texture-compression-pvrtc-webgl";
var texture_compression_atc_webgl = "texture-compression-atc-webgl";
var float32_renderable = "float32-renderable-webgl";
var float16_renderable = "float16-renderable-webgl";
var rgb9e5ufloat_renderable = "rgb9e5ufloat-renderable-webgl";
var snorm8_renderable = "snorm8-renderable-webgl";
var norm16_renderable = "norm16-renderable-webgl";
var snorm16_renderable = "snorm16-renderable-webgl";
var float32_filterable = "float32-filterable";
var float16_filterable = "float16-filterable-webgl";
function getTextureFormatDefinition(format) {
	const info = TEXTURE_FORMAT_TABLE[format];
	if (!info) throw new Error(`Unsupported texture format ${format}`);
	return info;
}
var TEXTURE_FORMAT_COLOR_DEPTH_TABLE = {
	"r8unorm": {},
	"rg8unorm": {},
	"rgb8unorm-webgl": {},
	"rgba8unorm": {},
	"rgba8unorm-srgb": {},
	"r8snorm": { render: snorm8_renderable },
	"rg8snorm": { render: snorm8_renderable },
	"rgb8snorm-webgl": {},
	"rgba8snorm": { render: snorm8_renderable },
	"r8uint": {},
	"rg8uint": {},
	"rgba8uint": {},
	"r8sint": {},
	"rg8sint": {},
	"rgba8sint": {},
	"bgra8unorm": {},
	"bgra8unorm-srgb": {},
	"r16unorm": { f: norm16_renderable },
	"rg16unorm": { render: norm16_renderable },
	"rgb16unorm-webgl": { f: norm16_renderable },
	"rgba16unorm": { render: norm16_renderable },
	"r16snorm": { f: snorm16_renderable },
	"rg16snorm": { render: snorm16_renderable },
	"rgb16snorm-webgl": { f: norm16_renderable },
	"rgba16snorm": { render: snorm16_renderable },
	"r16uint": {},
	"rg16uint": {},
	"rgba16uint": {},
	"r16sint": {},
	"rg16sint": {},
	"rgba16sint": {},
	"r16float": {
		render: float16_renderable,
		filter: "float16-filterable-webgl"
	},
	"rg16float": {
		render: float16_renderable,
		filter: float16_filterable
	},
	"rgba16float": {
		render: float16_renderable,
		filter: float16_filterable
	},
	"r32uint": {},
	"rg32uint": {},
	"rgba32uint": {},
	"r32sint": {},
	"rg32sint": {},
	"rgba32sint": {},
	"r32float": {
		render: float32_renderable,
		filter: float32_filterable
	},
	"rg32float": {
		render: false,
		filter: float32_filterable
	},
	"rgb32float-webgl": {
		render: float32_renderable,
		filter: float32_filterable
	},
	"rgba32float": {
		render: float32_renderable,
		filter: float32_filterable
	},
	"rgba4unorm-webgl": {
		channels: "rgba",
		bitsPerChannel: [
			4,
			4,
			4,
			4
		],
		packed: true
	},
	"rgb565unorm-webgl": {
		channels: "rgb",
		bitsPerChannel: [
			5,
			6,
			5,
			0
		],
		packed: true
	},
	"rgb5a1unorm-webgl": {
		channels: "rgba",
		bitsPerChannel: [
			5,
			5,
			5,
			1
		],
		packed: true
	},
	"rgb9e5ufloat": {
		channels: "rgb",
		packed: true,
		render: rgb9e5ufloat_renderable
	},
	"rg11b10ufloat": {
		channels: "rgb",
		bitsPerChannel: [
			11,
			11,
			10,
			0
		],
		packed: true,
		p: 1,
		render: float32_renderable
	},
	"rgb10a2unorm": {
		channels: "rgba",
		bitsPerChannel: [
			10,
			10,
			10,
			2
		],
		packed: true,
		p: 1
	},
	"rgb10a2uint": {
		channels: "rgba",
		bitsPerChannel: [
			10,
			10,
			10,
			2
		],
		packed: true,
		p: 1
	},
	stencil8: {
		attachment: "stencil",
		bitsPerChannel: [
			8,
			0,
			0,
			0
		],
		dataType: "uint8"
	},
	"depth16unorm": {
		attachment: "depth",
		bitsPerChannel: [
			16,
			0,
			0,
			0
		],
		dataType: "uint16"
	},
	"depth24plus": {
		attachment: "depth",
		bitsPerChannel: [
			24,
			0,
			0,
			0
		],
		dataType: "uint32"
	},
	"depth32float": {
		attachment: "depth",
		bitsPerChannel: [
			32,
			0,
			0,
			0
		],
		dataType: "float32"
	},
	"depth24plus-stencil8": {
		attachment: "depth-stencil",
		bitsPerChannel: [
			24,
			8,
			0,
			0
		],
		packed: true
	},
	"depth32float-stencil8": {
		attachment: "depth-stencil",
		bitsPerChannel: [
			32,
			8,
			0,
			0
		],
		packed: true
	}
};
var TEXTURE_FORMAT_COMPRESSED_TABLE = {
	"bc1-rgb-unorm-webgl": { f: texture_compression_bc },
	"bc1-rgb-unorm-srgb-webgl": { f: texture_compression_bc },
	"bc1-rgba-unorm": { f: texture_compression_bc },
	"bc1-rgba-unorm-srgb": { f: texture_compression_bc },
	"bc2-rgba-unorm": { f: texture_compression_bc },
	"bc2-rgba-unorm-srgb": { f: texture_compression_bc },
	"bc3-rgba-unorm": { f: texture_compression_bc },
	"bc3-rgba-unorm-srgb": { f: texture_compression_bc },
	"bc4-r-unorm": { f: texture_compression_bc },
	"bc4-r-snorm": { f: texture_compression_bc },
	"bc5-rg-unorm": { f: texture_compression_bc },
	"bc5-rg-snorm": { f: texture_compression_bc },
	"bc6h-rgb-ufloat": { f: texture_compression_bc },
	"bc6h-rgb-float": { f: texture_compression_bc },
	"bc7-rgba-unorm": { f: texture_compression_bc },
	"bc7-rgba-unorm-srgb": { f: texture_compression_bc },
	"etc2-rgb8unorm": { f: texture_compression_etc2 },
	"etc2-rgb8unorm-srgb": { f: texture_compression_etc2 },
	"etc2-rgb8a1unorm": { f: texture_compression_etc2 },
	"etc2-rgb8a1unorm-srgb": { f: texture_compression_etc2 },
	"etc2-rgba8unorm": { f: texture_compression_etc2 },
	"etc2-rgba8unorm-srgb": { f: texture_compression_etc2 },
	"eac-r11unorm": { f: texture_compression_etc2 },
	"eac-r11snorm": { f: texture_compression_etc2 },
	"eac-rg11unorm": { f: texture_compression_etc2 },
	"eac-rg11snorm": { f: texture_compression_etc2 },
	"astc-4x4-unorm": { f: texture_compression_astc },
	"astc-4x4-unorm-srgb": { f: texture_compression_astc },
	"astc-5x4-unorm": { f: texture_compression_astc },
	"astc-5x4-unorm-srgb": { f: texture_compression_astc },
	"astc-5x5-unorm": { f: texture_compression_astc },
	"astc-5x5-unorm-srgb": { f: texture_compression_astc },
	"astc-6x5-unorm": { f: texture_compression_astc },
	"astc-6x5-unorm-srgb": { f: texture_compression_astc },
	"astc-6x6-unorm": { f: texture_compression_astc },
	"astc-6x6-unorm-srgb": { f: texture_compression_astc },
	"astc-8x5-unorm": { f: texture_compression_astc },
	"astc-8x5-unorm-srgb": { f: texture_compression_astc },
	"astc-8x6-unorm": { f: texture_compression_astc },
	"astc-8x6-unorm-srgb": { f: texture_compression_astc },
	"astc-8x8-unorm": { f: texture_compression_astc },
	"astc-8x8-unorm-srgb": { f: texture_compression_astc },
	"astc-10x5-unorm": { f: texture_compression_astc },
	"astc-10x5-unorm-srgb": { f: texture_compression_astc },
	"astc-10x6-unorm": { f: texture_compression_astc },
	"astc-10x6-unorm-srgb": { f: texture_compression_astc },
	"astc-10x8-unorm": { f: texture_compression_astc },
	"astc-10x8-unorm-srgb": { f: texture_compression_astc },
	"astc-10x10-unorm": { f: texture_compression_astc },
	"astc-10x10-unorm-srgb": { f: texture_compression_astc },
	"astc-12x10-unorm": { f: texture_compression_astc },
	"astc-12x10-unorm-srgb": { f: texture_compression_astc },
	"astc-12x12-unorm": { f: texture_compression_astc },
	"astc-12x12-unorm-srgb": { f: texture_compression_astc },
	"pvrtc-rgb4unorm-webgl": { f: texture_compression_pvrtc_webgl },
	"pvrtc-rgba4unorm-webgl": { f: texture_compression_pvrtc_webgl },
	"pvrtc-rbg2unorm-webgl": { f: texture_compression_pvrtc_webgl },
	"pvrtc-rgba2unorm-webgl": { f: texture_compression_pvrtc_webgl },
	"etc1-rbg-unorm-webgl": { f: texture_compression_etc1_webgl },
	"atc-rgb-unorm-webgl": { f: texture_compression_atc_webgl },
	"atc-rgba-unorm-webgl": { f: texture_compression_atc_webgl },
	"atc-rgbai-unorm-webgl": { f: texture_compression_atc_webgl }
};
const TEXTURE_FORMAT_TABLE = {
	...TEXTURE_FORMAT_COLOR_DEPTH_TABLE,
	...TEXTURE_FORMAT_COMPRESSED_TABLE
};

//#endregion
//#region node_modules/@luma.gl/core/dist/shadertypes/textures/texture-format-decoder.js
var COMPRESSED_TEXTURE_FORMAT_PREFIXES = [
	"bc1",
	"bc2",
	"bc3",
	"bc4",
	"bc5",
	"bc6",
	"bc7",
	"etc1",
	"etc2",
	"eac",
	"atc",
	"astc",
	"pvrtc"
];
var RGB_FORMAT_REGEX = /^(r|rg|rgb|rgba|bgra)([0-9]*)([a-z]*)(-srgb)?(-webgl)?$/;
var TextureFormatDecoder = class {
	/** Returns information about a texture format, e.g. attatchment type, components, byte length and flags (integer, signed, normalized) */
	getInfo(format) {
		return getTextureFormatInfo(format);
	}
	/** Checks if a texture format is color */
	isColor(format) {
		return format.startsWith("rgba") || format.startsWith("bgra") || format.startsWith("rgb");
	}
	/** Checks if a texture format is depth or stencil */
	isDepthStencil(format) {
		return format.startsWith("depth") || format.startsWith("stencil");
	}
	/** Checks if a texture format is compressed */
	isCompressed(format) {
		return COMPRESSED_TEXTURE_FORMAT_PREFIXES.some((prefix) => format.startsWith(prefix));
	}
	/**
	* Returns the "static" capabilities of a texture format.
	* @note Needs to be checked against current device
	*/
	getCapabilities(format) {
		const info = getTextureFormatDefinition(format);
		const formatCapabilities = {
			format,
			create: info.f ?? true,
			render: info.render ?? true,
			filter: info.filter ?? true,
			blend: info.blend ?? true,
			store: info.store ?? true
		};
		const formatInfo = getTextureFormatInfo(format);
		const isDepthStencil = format.startsWith("depth") || format.startsWith("stencil");
		const isSigned = formatInfo?.signed;
		const isInteger = formatInfo?.integer;
		const isWebGLSpecific = formatInfo?.webgl;
		formatCapabilities.render &&= !isSigned;
		formatCapabilities.filter &&= !isDepthStencil && !isSigned && !isInteger && !isWebGLSpecific;
		return formatCapabilities;
	}
};
const textureFormatDecoder = new TextureFormatDecoder();
/**
* Decodes a texture format, returning e.g. attatchment type, components, byte length and flags (integer, signed, normalized)
*/
function getTextureFormatInfo(format) {
	let formatInfo = getTextureFormatInfoUsingTable(format);
	if (textureFormatDecoder.isCompressed(format)) {
		formatInfo.channels = "rgb";
		formatInfo.components = 3;
		formatInfo.bytesPerPixel = 1;
		formatInfo.srgb = false;
		formatInfo.compressed = true;
		const blockSize = getCompressedTextureBlockSize(format);
		if (blockSize) {
			formatInfo.blockWidth = blockSize.blockWidth;
			formatInfo.blockHeight = blockSize.blockHeight;
		}
	}
	const matches = RGB_FORMAT_REGEX.exec(format);
	if (matches) {
		const [, channels, length, type, srgb, suffix] = matches;
		const decodedType = getDataTypeInfo(`${type}${length}`);
		const bits = decodedType.byteLength * 8;
		const components = channels.length;
		const bitsPerChannel = [
			bits,
			components >= 2 ? bits : 0,
			components >= 3 ? bits : 0,
			components >= 4 ? bits : 0
		];
		formatInfo = {
			format,
			attachment: formatInfo.attachment,
			dataType: decodedType.signedType,
			components,
			channels,
			integer: decodedType.integer,
			signed: decodedType.signed,
			normalized: decodedType.normalized,
			bitsPerChannel,
			bytesPerPixel: decodedType.byteLength * channels.length,
			packed: formatInfo.packed,
			srgb: formatInfo.srgb
		};
		if (suffix === "-webgl") formatInfo.webgl = true;
		if (srgb === "-srgb") formatInfo.srgb = true;
	}
	if (format.endsWith("-webgl")) formatInfo.webgl = true;
	if (format.endsWith("-srgb")) formatInfo.srgb = true;
	return formatInfo;
}
/** Decode texture format info from the table */
function getTextureFormatInfoUsingTable(format) {
	const info = getTextureFormatDefinition(format);
	const bytesPerPixel = info.bytesPerPixel || 1;
	const bitsPerChannel = info.bitsPerChannel || [
		8,
		8,
		8,
		8
	];
	delete info.bitsPerChannel;
	delete info.bytesPerPixel;
	delete info.f;
	delete info.render;
	delete info.filter;
	delete info.blend;
	delete info.store;
	return {
		...info,
		format,
		attachment: info.attachment || "color",
		channels: info.channels || "r",
		components: info.components || info.channels?.length || 1,
		bytesPerPixel,
		bitsPerChannel,
		dataType: info.dataType || "uint8",
		srgb: info.srgb ?? false,
		packed: info.packed ?? false,
		webgl: info.webgl ?? false,
		integer: info.integer ?? false,
		signed: info.signed ?? false,
		normalized: info.normalized ?? false,
		compressed: info.compressed ?? false
	};
}
/** Parses ASTC block widths from format string */
function getCompressedTextureBlockSize(format) {
	const matches = /.*-(\d+)x(\d+)-.*/.exec(format);
	if (matches) {
		const [, blockWidth, blockHeight] = matches;
		return {
			blockWidth: Number(blockWidth),
			blockHeight: Number(blockHeight)
		};
	}
	return null;
}

//#endregion
//#region node_modules/@luma.gl/core/dist/image-utils/image-types.js
/** Check if data is an external image */
function isExternalImage(data) {
	return typeof ImageData !== "undefined" && data instanceof ImageData || typeof ImageBitmap !== "undefined" && data instanceof ImageBitmap || typeof HTMLImageElement !== "undefined" && data instanceof HTMLImageElement || typeof HTMLVideoElement !== "undefined" && data instanceof HTMLVideoElement || typeof VideoFrame !== "undefined" && data instanceof VideoFrame || typeof HTMLCanvasElement !== "undefined" && data instanceof HTMLCanvasElement || typeof OffscreenCanvas !== "undefined" && data instanceof OffscreenCanvas;
}
/** Determine size (width and height) of provided image data */
function getExternalImageSize(data) {
	if (typeof ImageData !== "undefined" && data instanceof ImageData || typeof ImageBitmap !== "undefined" && data instanceof ImageBitmap || typeof HTMLCanvasElement !== "undefined" && data instanceof HTMLCanvasElement || typeof OffscreenCanvas !== "undefined" && data instanceof OffscreenCanvas) return {
		width: data.width,
		height: data.height
	};
	if (typeof HTMLImageElement !== "undefined" && data instanceof HTMLImageElement) return {
		width: data.naturalWidth,
		height: data.naturalHeight
	};
	if (typeof HTMLVideoElement !== "undefined" && data instanceof HTMLVideoElement) return {
		width: data.videoWidth,
		height: data.videoHeight
	};
	if (typeof VideoFrame !== "undefined" && data instanceof VideoFrame) return {
		width: data.displayWidth,
		height: data.displayHeight
	};
	throw new Error("Unknown image type");
}

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/device.js
/** Limits for a device (max supported sizes of resources, max number of bindings etc) */
var DeviceLimits = class {};
/** Set-like class for features (lets apps check for WebGL / WebGPU extensions) */
var DeviceFeatures = class {
	features;
	disabledFeatures;
	constructor(features = [], disabledFeatures) {
		this.features = new Set(features);
		this.disabledFeatures = disabledFeatures || {};
	}
	*[Symbol.iterator]() {
		yield* this.features;
	}
	has(feature) {
		return !this.disabledFeatures?.[feature] && this.features.has(feature);
	}
};
/**
* WebGPU Device/WebGL context abstraction
*/
var Device = class Device {
	static defaultProps = {
		id: null,
		powerPreference: "high-performance",
		failIfMajorPerformanceCaveat: false,
		createCanvasContext: void 0,
		webgl: {},
		onError: (error, context) => {},
		onResize: (context, info) => {
			const [width, height] = context.getDevicePixelSize();
			log.log(1, `${context} resized => ${width}x${height}px`)();
		},
		onPositionChange: (context, info) => {
			const [left, top] = context.getPosition();
			log.log(1, `${context} repositioned => ${left},${top}`)();
		},
		onVisibilityChange: (context) => log.log(1, `${context} Visibility changed ${context.isVisible}`)(),
		onDevicePixelRatioChange: (context, info) => log.log(1, `${context} DPR changed ${info.oldRatio} => ${context.devicePixelRatio}`)(),
		debug: log.get("debug") || void 0,
		debugShaders: log.get("debug-shaders") || void 0,
		debugFramebuffers: Boolean(log.get("debug-framebuffers")),
		debugFactories: Boolean(log.get("debug-factories")),
		debugWebGL: Boolean(log.get("debug-webgl")),
		debugSpectorJS: void 0,
		debugSpectorJSUrl: void 0,
		_reuseDevices: false,
		_requestMaxLimits: true,
		_cacheShaders: false,
		_cachePipelines: false,
		_cacheDestroyPolicy: "unused",
		_initializeFeatures: true,
		_disabledFeatures: { "compilation-status-async-webgl": true },
		_handle: void 0
	};
	get [Symbol.toStringTag]() {
		return "Device";
	}
	toString() {
		return `Device(${this.id})`;
	}
	/** id of this device, primarily for debugging */
	id;
	/** A copy of the device props  */
	props;
	/** Available for the application to store data on the device */
	userData = {};
	/** stats */
	statsManager = lumaStats;
	/** An abstract timestamp used for change tracking */
	timestamp = 0;
	/** True if this device has been reused during device creation (app has multiple references) */
	_reused = false;
	/** Used by other luma.gl modules to store data on the device */
	_lumaData = {};
	_textureCaps = {};
	constructor(props) {
		this.props = {
			...Device.defaultProps,
			...props
		};
		this.id = this.props.id || uid$1(this[Symbol.toStringTag].toLowerCase());
	}
	getVertexFormatInfo(format) {
		return getVertexFormatInfo(format);
	}
	isVertexFormatSupported(format) {
		return true;
	}
	/** Returns information about a texture format, such as data type, channels, bits per channel, compression etc */
	getTextureFormatInfo(format) {
		return textureFormatDecoder.getInfo(format);
	}
	/** Determines what operations are supported on a texture format on this particular device (checks against supported device features) */
	getTextureFormatCapabilities(format) {
		let textureCaps = this._textureCaps[format];
		if (!textureCaps) {
			const capabilities = this._getDeviceTextureFormatCapabilities(format);
			textureCaps = this._getDeviceSpecificTextureFormatCapabilities(capabilities);
			this._textureCaps[format] = textureCaps;
		}
		return textureCaps;
	}
	/** Calculates the number of mip levels for a texture of width, height and in case of 3d textures only, depth */
	getMipLevelCount(width, height, depth3d = 1) {
		const maxSize = Math.max(width, height, depth3d);
		return 1 + Math.floor(Math.log2(maxSize));
	}
	/** Check if data is an external image */
	isExternalImage(data) {
		return isExternalImage(data);
	}
	/** Get the size of an external image */
	getExternalImageSize(data) {
		return getExternalImageSize(data);
	}
	/** Check if device supports a specific texture format (creation and `nearest` sampling) */
	isTextureFormatSupported(format) {
		return this.getTextureFormatCapabilities(format).create;
	}
	/** Check if linear filtering (sampler interpolation) is supported for a specific texture format */
	isTextureFormatFilterable(format) {
		return this.getTextureFormatCapabilities(format).filter;
	}
	/** Check if device supports rendering to a framebuffer color attachment of a specific texture format */
	isTextureFormatRenderable(format) {
		return this.getTextureFormatCapabilities(format).render;
	}
	/** Check if a specific texture format is GPU compressed */
	isTextureFormatCompressed(format) {
		return textureFormatDecoder.isCompressed(format);
	}
	pushDebugGroup(groupLabel) {
		this.commandEncoder.pushDebugGroup(groupLabel);
	}
	popDebugGroup() {
		this.commandEncoder?.popDebugGroup();
	}
	insertDebugMarker(markerLabel) {
		this.commandEncoder?.insertDebugMarker(markerLabel);
	}
	/**
	* Trigger device loss.
	* @returns `true` if context loss could actually be triggered.
	* @note primarily intended for testing how application reacts to device loss
	*/
	loseDevice() {
		return false;
	}
	/** A monotonic counter for tracking buffer and texture updates */
	incrementTimestamp() {
		return this.timestamp++;
	}
	/**
	* Reports Device errors in a way that optimizes for developer experience / debugging.
	* - Logs so that the console error links directly to the source code that generated the error.
	* - Includes the object that reported the error in the log message, even if the error is asynchronous.
	*
	* Conventions when calling reportError():
	* - Always call the returned function - to ensure error is logged, at the error site
	* - Follow with a call to device.debug() - to ensure that the debugger breaks at the error site
	*
	* @param error - the error to report. If needed, just create a new Error object with the appropriate message.
	* @param context - pass `this` as context, otherwise it may not be available in the debugger for async errors.
	* @returns the logger function returned by device.props.onError() so that it can be called from the error site.
	*
	* @example
	*   device.reportError(new Error(...), this)();
	*   device.debug();
	*/
	reportError(error, context, ...args) {
		if (!this.props.onError(error, context)) return log.error(error.message, context, ...args);
		return () => {};
	}
	/** Break in the debugger - if device.props.debug is true */
	debug() {
		if (this.props.debug) debugger;
		else log.once(0, `\
'Type luma.log.set({debug: true}) in console to enable debug breakpoints',
or create a device with the 'debug: true' prop.`)();
	}
	/** Returns the default / primary canvas context. Throws an error if no canvas context is available (a WebGPU compute device) */
	getDefaultCanvasContext() {
		if (!this.canvasContext) throw new Error("Device has no default CanvasContext. See props.createCanvasContext");
		return this.canvasContext;
	}
	/** Create a RenderPass using the default CommandEncoder */
	beginRenderPass(props) {
		return this.commandEncoder.beginRenderPass(props);
	}
	/** Create a ComputePass using the default CommandEncoder*/
	beginComputePass(props) {
		return this.commandEncoder.beginComputePass(props);
	}
	/** @deprecated Use getDefaultCanvasContext() */
	getCanvasContext() {
		return this.getDefaultCanvasContext();
	}
	/** @deprecated - will be removed - should use command encoder */
	readPixelsToArrayWebGL(source, options) {
		throw new Error("not implemented");
	}
	/** @deprecated - will be removed - should use command encoder */
	readPixelsToBufferWebGL(source, options) {
		throw new Error("not implemented");
	}
	/** @deprecated - will be removed - should use WebGPU parameters (pipeline) */
	setParametersWebGL(parameters) {
		throw new Error("not implemented");
	}
	/** @deprecated - will be removed - should use WebGPU parameters (pipeline) */
	getParametersWebGL(parameters) {
		throw new Error("not implemented");
	}
	/** @deprecated - will be removed - should use WebGPU parameters (pipeline) */
	withParametersWebGL(parameters, func) {
		throw new Error("not implemented");
	}
	/** @deprecated - will be removed - should use clear arguments in RenderPass */
	clearWebGL(options) {
		throw new Error("not implemented");
	}
	/** @deprecated - will be removed - should use for debugging only */
	resetWebGL() {
		throw new Error("not implemented");
	}
	/** Helper to get the canvas context props */
	static _getCanvasContextProps(props) {
		return props.createCanvasContext === true ? {} : props.createCanvasContext;
	}
	_getDeviceTextureFormatCapabilities(format) {
		const genericCapabilities = textureFormatDecoder.getCapabilities(format);
		const checkFeature = (feature) => (typeof feature === "string" ? this.features.has(feature) : feature) ?? true;
		const supported = checkFeature(genericCapabilities.create);
		return {
			format,
			create: supported,
			render: supported && checkFeature(genericCapabilities.render),
			filter: supported && checkFeature(genericCapabilities.filter),
			blend: supported && checkFeature(genericCapabilities.blend),
			store: supported && checkFeature(genericCapabilities.store)
		};
	}
	/** Subclasses use this to support .createBuffer() overloads */
	_normalizeBufferProps(props) {
		if (props instanceof ArrayBuffer || ArrayBuffer.isView(props)) props = { data: props };
		const newProps = { ...props };
		if ((props.usage || 0) & Buffer.INDEX) {
			if (!props.indexType) {
				if (props.data instanceof Uint32Array) newProps.indexType = "uint32";
				else if (props.data instanceof Uint16Array) newProps.indexType = "uint16";
				else if (props.data instanceof Uint8Array) {
					newProps.data = new Uint16Array(props.data);
					newProps.indexType = "uint16";
				}
			}
			if (!newProps.indexType) throw new Error("indices buffer content must be of type uint16 or uint32");
		}
		return newProps;
	}
};

//#endregion
//#region node_modules/@luma.gl/core/dist/utils/promise-utils.js
function withResolvers() {
	let resolve;
	let reject;
	return {
		promise: new Promise((_resolve, _reject) => {
			resolve = _resolve;
			reject = _reject;
		}),
		resolve,
		reject
	};
}

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/canvas-context.js
/**
* Manages a canvas. Supports both HTML or offscreen canvas
* - Creates a new canvas or looks up a canvas from the DOM
* - Provides check for DOM loaded
* @todo commit() @see https://github.com/w3ctag/design-reviews/issues/288
* @todo transferControlToOffscreen: @see https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement/transferControlToOffscreen
*/
var CanvasContext = class CanvasContext {
	static isHTMLCanvas(canvas) {
		return typeof HTMLCanvasElement !== "undefined" && canvas instanceof HTMLCanvasElement;
	}
	static isOffscreenCanvas(canvas) {
		return typeof OffscreenCanvas !== "undefined" && canvas instanceof OffscreenCanvas;
	}
	static defaultProps = {
		id: void 0,
		canvas: null,
		width: 800,
		height: 600,
		useDevicePixels: true,
		autoResize: true,
		container: null,
		visible: true,
		alphaMode: "opaque",
		colorSpace: "srgb",
		trackPosition: false
	};
	id;
	props;
	canvas;
	/** Handle to HTML canvas */
	htmlCanvas;
	/** Handle to wrapped OffScreenCanvas */
	offscreenCanvas;
	type;
	/** Promise that resolved once the resize observer has updated the pixel size */
	initialized;
	isInitialized = false;
	/** Visibility is automatically updated (via an IntersectionObserver) */
	isVisible = true;
	/** Width of canvas in CSS units (tracked by a ResizeObserver) */
	cssWidth;
	/** Height of canvas in CSS units (tracked by a ResizeObserver) */
	cssHeight;
	/** Device pixel ratio. Automatically updated via media queries */
	devicePixelRatio;
	/** Exact width of canvas in physical pixels (tracked by a ResizeObserver) */
	devicePixelWidth;
	/** Exact height of canvas in physical pixels (tracked by a ResizeObserver) */
	devicePixelHeight;
	/** Width of drawing buffer: automatically tracks this.pixelWidth if props.autoResize is true */
	drawingBufferWidth;
	/** Height of drawing buffer: automatically tracks this.pixelHeight if props.autoResize is true */
	drawingBufferHeight;
	_initializedResolvers = withResolvers();
	_resizeObserver;
	_intersectionObserver;
	_position;
	destroyed = false;
	toString() {
		return `${this[Symbol.toStringTag]}(${this.id})`;
	}
	constructor(props) {
		this.props = {
			...CanvasContext.defaultProps,
			...props
		};
		props = this.props;
		this.initialized = this._initializedResolvers.promise;
		if (!isBrowser()) this.canvas = {
			width: props.width || 1,
			height: props.height || 1
		};
		else if (!props.canvas) this.canvas = createCanvasElement(props);
		else if (typeof props.canvas === "string") this.canvas = getCanvasFromDOM(props.canvas);
		else this.canvas = props.canvas;
		if (CanvasContext.isHTMLCanvas(this.canvas)) {
			this.id = props.id || this.canvas.id;
			this.type = "html-canvas";
			this.htmlCanvas = this.canvas;
		} else if (CanvasContext.isOffscreenCanvas(this.canvas)) {
			this.id = props.id || "offscreen-canvas";
			this.type = "offscreen-canvas";
			this.offscreenCanvas = this.canvas;
		} else {
			this.id = props.id || "node-canvas-context";
			this.type = "node";
		}
		this.cssWidth = this.htmlCanvas?.clientWidth || this.canvas.width;
		this.cssHeight = this.htmlCanvas?.clientHeight || this.canvas.height;
		this.devicePixelWidth = this.canvas.width;
		this.devicePixelHeight = this.canvas.height;
		this.drawingBufferWidth = this.canvas.width;
		this.drawingBufferHeight = this.canvas.height;
		this.devicePixelRatio = globalThis.devicePixelRatio || 1;
		this._position = [0, 0];
		if (CanvasContext.isHTMLCanvas(this.canvas)) {
			this._intersectionObserver = new IntersectionObserver((entries) => this._handleIntersection(entries));
			this._intersectionObserver.observe(this.canvas);
			this._resizeObserver = new ResizeObserver((entries) => this._handleResize(entries));
			try {
				this._resizeObserver.observe(this.canvas, { box: "device-pixel-content-box" });
			} catch {
				this._resizeObserver.observe(this.canvas, { box: "content-box" });
			}
			setTimeout(() => this._observeDevicePixelRatio(), 0);
			if (this.props.trackPosition) this._trackPosition();
		}
	}
	destroy() {
		this.destroyed = true;
	}
	setProps(props) {
		if ("useDevicePixels" in props) {
			this.props.useDevicePixels = props.useDevicePixels || false;
			this._updateDrawingBufferSize();
		}
		return this;
	}
	/**
	* Returns the size covered by the canvas in CSS pixels
	* @note This can be different from the actual device pixel size of a canvas due to DPR scaling, and rounding to integer pixels
	* @note This is independent of the canvas' internal drawing buffer size (.width, .height).
	*/
	getCSSSize() {
		return [this.cssWidth, this.cssHeight];
	}
	getPosition() {
		return this._position;
	}
	/**
	* Returns the size covered by the canvas in actual device pixels.
	* @note This can be different from the 'CSS' size of a canvas due to DPR scaling, and rounding to integer pixels
	* @note This is independent of the canvas' internal drawing buffer size (.width, .height).
	*/
	getDevicePixelSize() {
		return [this.devicePixelWidth, this.devicePixelHeight];
	}
	/** Get the drawing buffer size (number of pixels GPU is rendering into, can be different from CSS size) */
	getDrawingBufferSize() {
		return [this.drawingBufferWidth, this.drawingBufferHeight];
	}
	/** Returns the biggest allowed framebuffer size. @todo Allow the application to limit this? */
	getMaxDrawingBufferSize() {
		const maxTextureDimension = this.device.limits.maxTextureDimension2D;
		return [maxTextureDimension, maxTextureDimension];
	}
	/** Update the canvas drawing buffer size. Called automatically if props.autoResize is true. */
	setDrawingBufferSize(width, height) {
		this.canvas.width = width;
		this.canvas.height = height;
		this.drawingBufferWidth = width;
		this.drawingBufferHeight = height;
	}
	/**
	* Returns the current DPR (number of physical pixels per CSS pixel), if props.useDevicePixels is true
	* @note This can be a fractional (non-integer) number, e.g. when the user zooms in the browser.
	* @note This function handles the non-HTML canvas cases
	*/
	getDevicePixelRatio() {
		return typeof window !== "undefined" && window.devicePixelRatio || 1;
	}
	/**
	* Maps CSS pixel position to device pixel position
	*/
	cssToDevicePixels(cssPixel, yInvert = true) {
		const ratio = this.cssToDeviceRatio();
		const [width, height] = this.getDrawingBufferSize();
		return scalePixels(cssPixel, ratio, width, height, yInvert);
	}
	/** @deprecated - use .getDevicePixelSize() */
	getPixelSize() {
		return this.getDevicePixelSize();
	}
	/** @deprecated - TODO which values should we use for aspect */
	getAspect() {
		const [width, height] = this.getDevicePixelSize();
		return width / height;
	}
	/** @deprecated Returns multiplier need to convert CSS size to Device size */
	cssToDeviceRatio() {
		try {
			const [drawingBufferWidth] = this.getDrawingBufferSize();
			const [cssWidth] = this.getCSSSize();
			return cssWidth ? drawingBufferWidth / cssWidth : 1;
		} catch {
			return 1;
		}
	}
	/** @deprecated Use canvasContext.setDrawingBufferSize() */
	resize(size) {
		this.setDrawingBufferSize(size.width, size.height);
	}
	/**
	* Allows subclass constructor to override the canvas id for auto created canvases.
	* This can really help when debugging DOM in apps that create multiple devices
	*/
	_setAutoCreatedCanvasId(id) {
		if (this.htmlCanvas?.id === "lumagl-auto-created-canvas") this.htmlCanvas.id = id;
	}
	/** reacts to an observed intersection */
	_handleIntersection(entries) {
		const entry = entries.find((entry_) => entry_.target === this.canvas);
		if (!entry) return;
		const isVisible = entry.isIntersecting;
		if (this.isVisible !== isVisible) {
			this.isVisible = isVisible;
			this.device.props.onVisibilityChange(this);
		}
	}
	/**
	* Reacts to an observed resize by using the most accurate pixel size information the browser can provide
	* @see https://web.dev/articles/device-pixel-content-box
	* @see https://webgpufundamentals.org/webgpu/lessons/webgpu-resizing-the-canvas.html
	*/
	_handleResize(entries) {
		const entry = entries.find((entry_) => entry_.target === this.canvas);
		if (!entry) return;
		this.cssWidth = entry.contentBoxSize[0].inlineSize;
		this.cssHeight = entry.contentBoxSize[0].blockSize;
		const oldPixelSize = this.getDevicePixelSize();
		const devicePixelWidth = entry.devicePixelContentBoxSize?.[0].inlineSize || entry.contentBoxSize[0].inlineSize * devicePixelRatio;
		const devicePixelHeight = entry.devicePixelContentBoxSize?.[0].blockSize || entry.contentBoxSize[0].blockSize * devicePixelRatio;
		const [maxDevicePixelWidth, maxDevicePixelHeight] = this.getMaxDrawingBufferSize();
		this.devicePixelWidth = Math.max(1, Math.min(devicePixelWidth, maxDevicePixelWidth));
		this.devicePixelHeight = Math.max(1, Math.min(devicePixelHeight, maxDevicePixelHeight));
		this._updateDrawingBufferSize();
		this.device.props.onResize(this, { oldPixelSize });
	}
	_updateDrawingBufferSize() {
		if (this.props.autoResize) {
			if (typeof this.props.useDevicePixels === "number") {
				const dpr = this.props.useDevicePixels;
				this.setDrawingBufferSize(this.cssWidth * dpr, this.cssHeight * dpr);
			} else if (this.props.useDevicePixels) this.setDrawingBufferSize(this.devicePixelWidth, this.devicePixelHeight);
			else this.setDrawingBufferSize(this.cssWidth, this.cssHeight);
			this._updateDevice();
		}
		this._initializedResolvers.resolve();
		this.isInitialized = true;
		this.updatePosition();
	}
	/** Monitor DPR changes */
	_observeDevicePixelRatio() {
		const oldRatio = this.devicePixelRatio;
		this.devicePixelRatio = window.devicePixelRatio;
		this.updatePosition();
		this.device.props.onDevicePixelRatioChange(this, { oldRatio });
		matchMedia(`(resolution: ${this.devicePixelRatio}dppx)`).addEventListener("change", () => this._observeDevicePixelRatio(), { once: true });
	}
	/** Start tracking positions with a timer */
	_trackPosition(intervalMs = 100) {
		const intervalId = setInterval(() => {
			if (this.destroyed) clearInterval(intervalId);
			else this.updatePosition();
		}, intervalMs);
	}
	/**
	* Calculated the absolute position of the canvas
	* @note - getBoundingClientRect() is normally cheap but can be expensive
	* if called before browser has finished a reflow. Should not be the case here.
	*/
	updatePosition() {
		const newRect = this.htmlCanvas?.getBoundingClientRect();
		if (newRect) {
			const position = [newRect.left, newRect.top];
			this._position ??= position;
			if (position[0] !== this._position[0] || position[1] !== this._position[1]) {
				const oldPosition = this._position;
				this._position = position;
				this.device.props.onPositionChange?.(this, { oldPosition });
			}
		}
	}
};
/** Get a container element from a string or DOM element */
function getContainer(container) {
	if (typeof container === "string") {
		const element = document.getElementById(container);
		if (!element) throw new Error(`${container} is not an HTML element`);
		return element;
	}
	if (container) return container;
	return document.body;
}
/** Get a Canvas element from DOM id */
function getCanvasFromDOM(canvasId) {
	const canvas = document.getElementById(canvasId);
	if (!CanvasContext.isHTMLCanvas(canvas)) throw new Error("Object is not a canvas element");
	return canvas;
}
/** Create a new canvas */
function createCanvasElement(props) {
	const { width, height } = props;
	const newCanvas = document.createElement("canvas");
	newCanvas.id = uid$1("lumagl-auto-created-canvas");
	newCanvas.width = width || 1;
	newCanvas.height = height || 1;
	newCanvas.style.width = Number.isFinite(width) ? `${width}px` : "100%";
	newCanvas.style.height = Number.isFinite(height) ? `${height}px` : "100%";
	if (!props?.visible) newCanvas.style.visibility = "hidden";
	const container = getContainer(props?.container || null);
	container.insertBefore(newCanvas, container.firstChild);
	return newCanvas;
}
/**
* Scales pixels linearly, handles edge cases
* @param pixel
* @param ratio
* @param width
* @param height
* @param yInvert
* @returns
*/
function scalePixels(pixel, ratio, width, height, yInvert) {
	const point = pixel;
	const x = scaleX(point[0], ratio, width);
	let y = scaleY(point[1], ratio, height, yInvert);
	let t = scaleX(point[0] + 1, ratio, width);
	const xHigh = t === width - 1 ? t : t - 1;
	t = scaleY(point[1] + 1, ratio, height, yInvert);
	let yHigh;
	if (yInvert) {
		t = t === 0 ? t : t + 1;
		yHigh = y;
		y = t;
	} else yHigh = t === height - 1 ? t : t - 1;
	return {
		x,
		y,
		width: Math.max(xHigh - x + 1, 1),
		height: Math.max(yHigh - y + 1, 1)
	};
}
function scaleX(x, ratio, width) {
	return Math.min(Math.round(x * ratio), width - 1);
}
function scaleY(y, ratio, height, yInvert) {
	return yInvert ? Math.max(0, height - 1 - Math.round(y * ratio)) : Math.min(Math.round(y * ratio), height - 1);
}

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/resources/sampler.js
/** Immutable Sampler object */
var Sampler = class Sampler extends Resource {
	static defaultProps = {
		...Resource.defaultProps,
		type: "color-sampler",
		addressModeU: "clamp-to-edge",
		addressModeV: "clamp-to-edge",
		addressModeW: "clamp-to-edge",
		magFilter: "nearest",
		minFilter: "nearest",
		mipmapFilter: "none",
		lodMinClamp: 0,
		lodMaxClamp: 32,
		compare: "less-equal",
		maxAnisotropy: 1
	};
	get [Symbol.toStringTag]() {
		return "Sampler";
	}
	constructor(device, props) {
		props = Sampler.normalizeProps(device, props);
		super(device, props, Sampler.defaultProps);
	}
	static normalizeProps(device, props) {
		return props;
	}
};

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/resources/texture.js
var BASE_DIMENSIONS = {
	"1d": "1d",
	"2d": "2d",
	"2d-array": "2d",
	cube: "2d",
	"cube-array": "2d",
	"3d": "3d"
};
/**
* Abstract Texture interface
* Texture Object
* https://gpuweb.github.io/gpuweb/#gputexture
*/
var Texture = class Texture extends Resource {
	/** The texture can be bound for use as a sampled texture in a shader */
	static SAMPLE = 4;
	/** The texture can be bound for use as a storage texture in a shader */
	static STORAGE = 8;
	/** The texture can be used as a color or depth/stencil attachment in a render pass */
	static RENDER = 16;
	/** The texture can be used as the source of a copy operation */
	static COPY_SRC = 1;
	/** he texture can be used as the destination of a copy or write operation */
	static COPY_DST = 2;
	/** @deprecated Use Texture.SAMPLE */
	static TEXTURE = 4;
	/** @deprecated Use Texture.RENDER */
	static RENDER_ATTACHMENT = 16;
	/** dimension of this texture */
	dimension;
	/** base dimension of this texture */
	baseDimension;
	/** format of this texture */
	format;
	/** width in pixels of this texture */
	width;
	/** height in pixels of this texture */
	height;
	/** depth of this texture */
	depth;
	/** mip levels in this texture */
	mipLevels;
	/** "Time" of last update. Monotonically increasing timestamp. TODO move to AsyncTexture? */
	updateTimestamp;
	get [Symbol.toStringTag]() {
		return "Texture";
	}
	toString() {
		return `Texture(${this.id},${this.format},${this.width}x${this.height})`;
	}
	/** Do not use directly. Create with device.createTexture() */
	constructor(device, props) {
		props = Texture.normalizeProps(device, props);
		super(device, props, Texture.defaultProps);
		this.dimension = this.props.dimension;
		this.baseDimension = BASE_DIMENSIONS[this.dimension];
		this.format = this.props.format;
		this.width = this.props.width;
		this.height = this.props.height;
		this.depth = this.props.depth;
		this.mipLevels = this.props.mipLevels;
		if (this.props.width === void 0 || this.props.height === void 0) if (device.isExternalImage(props.data)) {
			const size = device.getExternalImageSize(props.data);
			this.width = size?.width || 1;
			this.height = size?.height || 1;
		} else {
			this.width = 1;
			this.height = 1;
			if (this.props.width === void 0 || this.props.height === void 0) log.warn(`${this} created with undefined width or height. This is deprecated. Use AsyncTexture instead.`)();
		}
		this.updateTimestamp = device.incrementTimestamp();
	}
	/** Set sampler props associated with this texture */
	setSampler(sampler) {
		this.sampler = sampler instanceof Sampler ? sampler : this.device.createSampler(sampler);
	}
	/**
	* Create a new texture with the same parameters and optionally a different size
	* @note Textures are immutable and cannot be resized after creation, but we can create a similar texture with the same parameters but a new size.
	* @note Does not copy contents of the texture
	*/
	clone(size) {
		return this.device.createTexture({
			...this.props,
			...size
		});
	}
	/** Ensure we have integer coordinates */
	static normalizeProps(device, props) {
		const newProps = { ...props };
		const { width, height } = newProps;
		if (typeof width === "number") newProps.width = Math.max(1, Math.ceil(width));
		if (typeof height === "number") newProps.height = Math.max(1, Math.ceil(height));
		return newProps;
	}
	/** Initialize texture with supplied props */
	_initializeData(data) {
		if (this.device.isExternalImage(data)) this.copyExternalImage({
			image: data,
			width: this.width,
			height: this.height,
			depth: this.depth,
			mipLevel: 0,
			x: 0,
			y: 0,
			z: 0,
			aspect: "all",
			colorSpace: "srgb",
			premultipliedAlpha: false,
			flipY: false
		});
		else if (data) this.copyImageData({
			data,
			mipLevel: 0,
			x: 0,
			y: 0,
			z: 0,
			aspect: "all"
		});
	}
	_normalizeCopyImageDataOptions(options_) {
		const { width, height, depth } = this;
		const options = {
			...Texture.defaultCopyDataOptions,
			width,
			height,
			depth,
			...options_
		};
		const info = this.device.getTextureFormatInfo(this.format);
		if (!options_.bytesPerRow && !info.bytesPerPixel) throw new Error(`bytesPerRow must be provided for texture format ${this.format}`);
		options.bytesPerRow = options_.bytesPerRow || width * (info.bytesPerPixel || 4);
		options.rowsPerImage = options_.rowsPerImage || height;
		return options;
	}
	_normalizeCopyExternalImageOptions(options_) {
		const size = this.device.getExternalImageSize(options_.image);
		const options = {
			...Texture.defaultCopyExternalImageOptions,
			...size,
			...options_
		};
		options.width = Math.min(options.width, this.width - options.x);
		options.height = Math.min(options.height, this.height - options.y);
		return options;
	}
	/** Default options */
	static defaultProps = {
		...Resource.defaultProps,
		data: null,
		dimension: "2d",
		format: "rgba8unorm",
		usage: Texture.TEXTURE | Texture.RENDER_ATTACHMENT | Texture.COPY_DST,
		width: void 0,
		height: void 0,
		depth: 1,
		mipLevels: 1,
		samples: void 0,
		sampler: {},
		view: void 0
	};
	static defaultCopyDataOptions = {
		data: void 0,
		byteOffset: 0,
		bytesPerRow: void 0,
		rowsPerImage: void 0,
		mipLevel: 0,
		x: 0,
		y: 0,
		z: 0,
		aspect: "all"
	};
	/** Default options */
	static defaultCopyExternalImageOptions = {
		image: void 0,
		sourceX: 0,
		sourceY: 0,
		width: void 0,
		height: void 0,
		depth: 1,
		mipLevel: 0,
		x: 0,
		y: 0,
		z: 0,
		aspect: "all",
		colorSpace: "srgb",
		premultipliedAlpha: false,
		flipY: false
	};
};

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/resources/texture-view.js
/** Immutable TextureView object */
var TextureView = class TextureView extends Resource {
	get [Symbol.toStringTag]() {
		return "TextureView";
	}
	/** Should not be constructed directly. Use `texture.createView(props)` */
	constructor(device, props) {
		super(device, props, TextureView.defaultProps);
	}
	static defaultProps = {
		...Resource.defaultProps,
		format: void 0,
		dimension: void 0,
		aspect: "all",
		baseMipLevel: 0,
		mipLevelCount: void 0,
		baseArrayLayer: 0,
		arrayLayerCount: void 0
	};
};

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter-utils/format-compiler-log.js
/** @returns annotated errors or warnings */
function formatCompilerLog(shaderLog, source, options) {
	let formattedLog = "";
	const lines = source.split(/\r?\n/);
	const log$1 = shaderLog.slice().sort((a, b) => a.lineNum - b.lineNum);
	switch (options?.showSourceCode || "no") {
		case "all":
			let currentMessage = 0;
			for (let lineNum = 1; lineNum <= lines.length; lineNum++) {
				formattedLog += getNumberedLine(lines[lineNum - 1], lineNum, options);
				while (log$1.length > currentMessage && log$1[currentMessage].lineNum === lineNum) {
					const message$1 = log$1[currentMessage++];
					formattedLog += formatCompilerMessage(message$1, lines, message$1.lineNum, {
						...options,
						inlineSource: false
					});
				}
			}
			while (log$1.length > currentMessage) {
				const message$1 = log$1[currentMessage++];
				formattedLog += formatCompilerMessage(message$1, [], 0, {
					...options,
					inlineSource: false
				});
			}
			return formattedLog;
		case "issues":
		case "no":
			for (const message$1 of shaderLog) formattedLog += formatCompilerMessage(message$1, lines, message$1.lineNum, { inlineSource: options?.showSourceCode !== "no" });
			return formattedLog;
	}
}
/** Format one message */
function formatCompilerMessage(message$1, lines, lineNum, options) {
	if (options?.inlineSource) return `
${getNumberedLines(lines, lineNum)}${message$1.linePos > 0 ? `${" ".repeat(message$1.linePos + 5)}^^^\n` : ""}${message$1.type.toUpperCase()}: ${message$1.message}

`;
	const color = message$1.type === "error" ? "red" : "#8B4000";
	return options?.html ? `<div class='luma-compiler-log-error' style="color:${color};"><b> ${message$1.type.toUpperCase()}: ${message$1.message}</b></div>` : `${message$1.type.toUpperCase()}: ${message$1.message}`;
}
function getNumberedLines(lines, lineNum, options) {
	let numberedLines = "";
	for (let lineIndex = lineNum - 2; lineIndex <= lineNum; lineIndex++) {
		const sourceLine = lines[lineIndex - 1];
		if (sourceLine !== void 0) numberedLines += getNumberedLine(sourceLine, lineNum, options);
	}
	return numberedLines;
}
function getNumberedLine(line, lineNum, options) {
	const escapedLine = options?.html ? escapeHTML(line) : line;
	return `${padLeft(String(lineNum), 4)}: ${escapedLine}${options?.html ? "<br/>" : "\n"}`;
}
/**
* Pads a string with a number of spaces (space characters) to the left
* @param {String} string - string to pad
* @param {Number} digits - number of spaces to add
* @return {String} string - The padded string
*/
function padLeft(string, paddedLength) {
	let result = "";
	for (let i = string.length; i < paddedLength; ++i) result += " ";
	return result + string;
}
function escapeHTML(unsafe) {
	return unsafe.replaceAll("&", "&amp;").replaceAll("<", "&lt;").replaceAll(">", "&gt;").replaceAll("\"", "&quot;").replaceAll("'", "&#039;");
}

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/resources/shader.js
/**
* Immutable Shader object
* In WebGPU the handle can be copied between threads
*/
var Shader = class Shader extends Resource {
	get [Symbol.toStringTag]() {
		return "Shader";
	}
	/** The stage of this shader */
	stage;
	/** The source code of this shader */
	source;
	/** The compilation status of the shader. 'pending' if compilation is asynchronous, and on production */
	compilationStatus = "pending";
	/** Create a new Shader instance */
	constructor(device, props) {
		props = {
			...props,
			debugShaders: props.debugShaders || device.props.debugShaders || "errors"
		};
		super(device, {
			id: getShaderIdFromProps(props),
			...props
		}, Shader.defaultProps);
		this.stage = this.props.stage;
		this.source = this.props.source;
	}
	/** Get compiler log synchronously (WebGL only) */
	getCompilationInfoSync() {
		return null;
	}
	/** Get translated shader source in host platform's native language (HLSL, GLSL, and even GLSL ES), if available */
	getTranslatedSource() {
		return null;
	}
	/** In browser logging of errors */
	async debugShader() {
		const trigger = this.props.debugShaders;
		switch (trigger) {
			case "never": return;
			case "errors":
				if (this.compilationStatus === "success") return;
				break;
			case "warnings":
			case "always": break;
		}
		const messages = await this.getCompilationInfo();
		if (trigger === "warnings" && messages?.length === 0) return;
		this._displayShaderLog(messages, this.id);
	}
	/**
	* In-browser UI logging of errors
	* TODO - this HTML formatting code should not be in Device, should be pluggable
	*/
	_displayShaderLog(messages, shaderId) {
		if (typeof document === "undefined" || !document?.createElement) return;
		const shaderName = shaderId;
		const shaderTitle = `${this.stage} shader "${shaderName}"`;
		let htmlLog = formatCompilerLog(messages, this.source, {
			showSourceCode: "all",
			html: true
		});
		const translatedSource = this.getTranslatedSource();
		if (translatedSource) htmlLog += `<br /><br /><h1>Translated Source</h1><br /><br /><code style="user-select:text;"><pre>${translatedSource}</pre></code>`;
		const button = document.createElement("Button");
		button.innerHTML = `
<h1>Compilation error in ${shaderTitle}</h1><br /><br />
<code style="user-select:text;"><pre>
${htmlLog}
</pre></code>`;
		button.style.top = "10px";
		button.style.left = "10px";
		button.style.position = "absolute";
		button.style.zIndex = "9999";
		button.style.width = "100%";
		button.style.textAlign = "left";
		document.body.appendChild(button);
		document.getElementsByClassName("luma-compiler-log-error")[0]?.scrollIntoView();
		button.onclick = () => {
			const dataURI = `data:text/plain,${encodeURIComponent(this.source)}`;
			navigator.clipboard.writeText(dataURI);
		};
	}
	static defaultProps = {
		...Resource.defaultProps,
		language: "auto",
		stage: void 0,
		source: "",
		sourceMap: null,
		entryPoint: "main",
		debugShaders: void 0
	};
};
/** Deduce an id, from shader source, or supplied id, or shader type */
function getShaderIdFromProps(props) {
	return getShaderName(props.source) || props.id || uid$1(`unnamed ${props.stage}-shader`);
}
/** Extracts GLSLIFY style naming of shaders: `#define SHADER_NAME ...` */
function getShaderName(shader, defaultName = "unnamed") {
	const match = /#define[\s*]SHADER_NAME[\s*]([A-Za-z0-9_-]+)[\s*]/.exec(shader);
	return match ? match[1] : defaultName;
}

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/resources/framebuffer.js
/**
* Create new textures with correct size for all attachments.
* @note resize() destroys existing textures (if size has changed).
*/
var Framebuffer = class Framebuffer extends Resource {
	get [Symbol.toStringTag]() {
		return "Framebuffer";
	}
	/** Width of all attachments in this framebuffer */
	width;
	/** Height of all attachments in this framebuffer */
	height;
	constructor(device, props = {}) {
		super(device, props, Framebuffer.defaultProps);
		this.width = this.props.width;
		this.height = this.props.height;
	}
	/**
	* Create a copy of this framebuffer with new attached textures, with same props but of the specified size.
	* @note Does not copy contents of the attached textures.
	*/
	clone(size) {
		const colorAttachments = this.colorAttachments.map((colorAttachment) => colorAttachment.texture.clone(size));
		const depthStencilAttachment = this.depthStencilAttachment && this.depthStencilAttachment.texture.clone(size);
		return this.device.createFramebuffer({
			...this.props,
			colorAttachments,
			depthStencilAttachment
		});
	}
	resize(size) {
		let updateSize = !size;
		if (size) {
			const [width, height] = Array.isArray(size) ? size : [size.width, size.height];
			updateSize = updateSize || height !== this.height || width !== this.width;
			this.width = width;
			this.height = height;
		}
		if (updateSize) {
			log.log(2, `Resizing framebuffer ${this.id} to ${this.width}x${this.height}`)();
			this.resizeAttachments(this.width, this.height);
		}
	}
	/** Auto creates any textures */
	autoCreateAttachmentTextures() {
		if (this.props.colorAttachments.length === 0 && !this.props.depthStencilAttachment) throw new Error("Framebuffer has noattachments");
		this.colorAttachments = this.props.colorAttachments.map((attachment$1, index) => {
			if (typeof attachment$1 === "string") {
				const texture = this.createColorTexture(attachment$1, index);
				this.attachResource(texture);
				return texture.view;
			}
			if (attachment$1 instanceof Texture) return attachment$1.view;
			return attachment$1;
		});
		const attachment = this.props.depthStencilAttachment;
		if (attachment) if (typeof attachment === "string") {
			const texture = this.createDepthStencilTexture(attachment);
			this.attachResource(texture);
			this.depthStencilAttachment = texture.view;
		} else if (attachment instanceof Texture) this.depthStencilAttachment = attachment.view;
		else this.depthStencilAttachment = attachment;
	}
	/** Create a color texture */
	createColorTexture(format, index) {
		return this.device.createTexture({
			id: `${this.id}-color-attachment-${index}`,
			usage: Texture.RENDER_ATTACHMENT,
			format,
			width: this.width,
			height: this.height,
			sampler: {
				magFilter: "linear",
				minFilter: "linear"
			}
		});
	}
	/** Create depth stencil texture */
	createDepthStencilTexture(format) {
		return this.device.createTexture({
			id: `${this.id}-depth-stencil-attachment`,
			usage: Texture.RENDER_ATTACHMENT,
			format,
			width: this.width,
			height: this.height
		});
	}
	/**
	* Default implementation of resize
	* Creates new textures with correct size for all attachments.
	* and destroys existing textures if owned
	*/
	resizeAttachments(width, height) {
		for (let i = 0; i < this.colorAttachments.length; ++i) if (this.colorAttachments[i]) {
			const resizedTexture = this.colorAttachments[i].texture.clone({
				width,
				height
			});
			this.destroyAttachedResource(this.colorAttachments[i]);
			this.colorAttachments[i] = resizedTexture.view;
			this.attachResource(resizedTexture.view);
		}
		if (this.depthStencilAttachment) {
			const resizedTexture = this.depthStencilAttachment.texture.clone({
				width,
				height
			});
			this.destroyAttachedResource(this.depthStencilAttachment);
			this.depthStencilAttachment = resizedTexture.view;
			this.attachResource(resizedTexture);
		}
		this.updateAttachments();
	}
	static defaultProps = {
		...Resource.defaultProps,
		width: 1,
		height: 1,
		colorAttachments: [],
		depthStencilAttachment: null
	};
};

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/resources/render-pipeline.js
/**
* A compiled and linked shader program
*/
var RenderPipeline = class RenderPipeline extends Resource {
	get [Symbol.toStringTag]() {
		return "RenderPipeline";
	}
	/** The merged layout */
	shaderLayout;
	/** Buffer map describing buffer interleaving etc */
	bufferLayout;
	/** The linking status of the pipeline. 'pending' if linking is asynchronous, and on production */
	linkStatus = "pending";
	/** The hash of the pipeline */
	hash = "";
	constructor(device, props) {
		super(device, props, RenderPipeline.defaultProps);
		this.shaderLayout = this.props.shaderLayout;
		this.bufferLayout = this.props.bufferLayout || [];
	}
	static defaultProps = {
		...Resource.defaultProps,
		vs: null,
		vertexEntryPoint: "vertexMain",
		vsConstants: {},
		fs: null,
		fragmentEntryPoint: "fragmentMain",
		fsConstants: {},
		shaderLayout: null,
		bufferLayout: [],
		topology: "triangle-list",
		colorAttachmentFormats: void 0,
		depthStencilAttachmentFormat: void 0,
		parameters: {},
		bindings: {},
		uniforms: {}
	};
};

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/resources/render-pass.js
/**
* A RenderPass instance is a required parameter to all draw calls.
*
* It holds a combination of
* - render targets (specified via a framebuffer)
* - clear colors, read/write, discard information for the framebuffer attachments
* - a couple of mutable parameters ()
*/
var RenderPass = class RenderPass extends Resource {
	/** TODO - should be [0, 0, 0, 0], update once deck.gl tests run clean */
	static defaultClearColor = [
		0,
		0,
		0,
		1
	];
	/** Depth 1.0 represents the far plance */
	static defaultClearDepth = 1;
	/** Clears all stencil bits */
	static defaultClearStencil = 0;
	get [Symbol.toStringTag]() {
		return "RenderPass";
	}
	constructor(device, props) {
		props = RenderPass.normalizeProps(device, props);
		super(device, props, RenderPass.defaultProps);
	}
	static normalizeProps(device, props) {
		return props;
	}
	/** Default properties for RenderPass */
	static defaultProps = {
		...Resource.defaultProps,
		framebuffer: null,
		parameters: void 0,
		clearColor: RenderPass.defaultClearColor,
		clearColors: void 0,
		clearDepth: RenderPass.defaultClearDepth,
		clearStencil: RenderPass.defaultClearStencil,
		depthReadOnly: false,
		stencilReadOnly: false,
		discard: false,
		occlusionQuerySet: void 0,
		timestampQuerySet: void 0,
		beginTimestampIndex: void 0,
		endTimestampIndex: void 0
	};
};

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/resources/command-encoder.js
/**
* Encodes commands to queue that can be executed later
*/
var CommandEncoder = class CommandEncoder extends Resource {
	get [Symbol.toStringTag]() {
		return "CommandEncoder";
	}
	constructor(device, props) {
		super(device, props, CommandEncoder.defaultProps);
	}
	static defaultProps = {
		...Resource.defaultProps,
		measureExecutionTime: void 0
	};
};

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/resources/command-buffer.js
/**
* Encodes commands to queue that can be executed later
*/
var CommandBuffer = class CommandBuffer extends Resource {
	get [Symbol.toStringTag]() {
		return "CommandBuffer";
	}
	constructor(device, props) {
		super(device, props, CommandBuffer.defaultProps);
	}
	static defaultProps = { ...Resource.defaultProps };
};

//#endregion
//#region node_modules/@luma.gl/core/dist/shadertypes/data-types/decode-shader-types.js
/** Split a uniform type string into type and components */
function getVariableShaderTypeInfo(format) {
	return UNIFORM_FORMATS[format];
}
/** Decodes a vertex type, returning byte length and flags (integer, signed, normalized) */
function getAttributeShaderTypeInfo(attributeType) {
	const [primitiveType, components] = TYPE_INFO[attributeType];
	const integer = primitiveType === "i32" || primitiveType === "u32";
	const signed = primitiveType !== "u32";
	return {
		primitiveType,
		components,
		byteLength: PRIMITIVE_TYPE_SIZES[primitiveType] * components,
		integer,
		signed
	};
}
var PRIMITIVE_TYPE_SIZES = {
	f32: 4,
	f16: 2,
	i32: 4,
	u32: 4
};
/** All valid shader attribute types. A table guarantees exhaustive list and fast execution */
var TYPE_INFO = {
	f32: ["f32", 1],
	"vec2<f32>": ["f32", 2],
	"vec3<f32>": ["f32", 3],
	"vec4<f32>": ["f32", 4],
	f16: ["f16", 1],
	"vec2<f16>": ["f16", 2],
	"vec3<f16>": ["f16", 3],
	"vec4<f16>": ["f16", 4],
	i32: ["i32", 1],
	"vec2<i32>": ["i32", 2],
	"vec3<i32>": ["i32", 3],
	"vec4<i32>": ["i32", 4],
	u32: ["u32", 1],
	"vec2<u32>": ["u32", 2],
	"vec3<u32>": ["u32", 3],
	"vec4<u32>": ["u32", 4]
};
/** @todo These tables are quite big, consider parsing type strings instead */
var UNIFORM_FORMATS = {
	f32: {
		type: "f32",
		components: 1
	},
	f16: {
		type: "f16",
		components: 1
	},
	i32: {
		type: "i32",
		components: 1
	},
	u32: {
		type: "u32",
		components: 1
	},
	"vec2<f32>": {
		type: "f32",
		components: 2
	},
	"vec3<f32>": {
		type: "f32",
		components: 3
	},
	"vec4<f32>": {
		type: "f32",
		components: 4
	},
	"vec2<f16>": {
		type: "f16",
		components: 2
	},
	"vec3<f16>": {
		type: "f16",
		components: 3
	},
	"vec4<f16>": {
		type: "f16",
		components: 4
	},
	"vec2<i32>": {
		type: "i32",
		components: 2
	},
	"vec3<i32>": {
		type: "i32",
		components: 3
	},
	"vec4<i32>": {
		type: "i32",
		components: 4
	},
	"vec2<u32>": {
		type: "u32",
		components: 2
	},
	"vec3<u32>": {
		type: "u32",
		components: 3
	},
	"vec4<u32>": {
		type: "u32",
		components: 4
	},
	"mat2x2<f32>": {
		type: "f32",
		components: 4
	},
	"mat2x3<f32>": {
		type: "f32",
		components: 6
	},
	"mat2x4<f32>": {
		type: "f32",
		components: 8
	},
	"mat3x2<f32>": {
		type: "f32",
		components: 6
	},
	"mat3x3<f32>": {
		type: "f32",
		components: 9
	},
	"mat3x4<f32>": {
		type: "f32",
		components: 12
	},
	"mat4x2<f32>": {
		type: "f32",
		components: 8
	},
	"mat4x3<f32>": {
		type: "f32",
		components: 12
	},
	"mat4x4<f32>": {
		type: "f32",
		components: 16
	},
	"mat2x2<f16>": {
		type: "f16",
		components: 4
	},
	"mat2x3<f16>": {
		type: "f16",
		components: 6
	},
	"mat2x4<f16>": {
		type: "f16",
		components: 8
	},
	"mat3x2<f16>": {
		type: "f16",
		components: 6
	},
	"mat3x3<f16>": {
		type: "f16",
		components: 9
	},
	"mat3x4<f16>": {
		type: "f16",
		components: 12
	},
	"mat4x2<f16>": {
		type: "f16",
		components: 8
	},
	"mat4x3<f16>": {
		type: "f16",
		components: 12
	},
	"mat4x4<f16>": {
		type: "f16",
		components: 16
	},
	"mat2x2<i32>": {
		type: "i32",
		components: 4
	},
	"mat2x3<i32>": {
		type: "i32",
		components: 6
	},
	"mat2x4<i32>": {
		type: "i32",
		components: 8
	},
	"mat3x2<i32>": {
		type: "i32",
		components: 6
	},
	"mat3x3<i32>": {
		type: "i32",
		components: 9
	},
	"mat3x4<i32>": {
		type: "i32",
		components: 12
	},
	"mat4x2<i32>": {
		type: "i32",
		components: 8
	},
	"mat4x3<i32>": {
		type: "i32",
		components: 12
	},
	"mat4x4<i32>": {
		type: "i32",
		components: 16
	},
	"mat2x2<u32>": {
		type: "u32",
		components: 4
	},
	"mat2x3<u32>": {
		type: "u32",
		components: 6
	},
	"mat2x4<u32>": {
		type: "u32",
		components: 8
	},
	"mat3x2<u32>": {
		type: "u32",
		components: 6
	},
	"mat3x3<u32>": {
		type: "u32",
		components: 9
	},
	"mat3x4<u32>": {
		type: "u32",
		components: 12
	},
	"mat4x2<u32>": {
		type: "u32",
		components: 8
	},
	"mat4x3<u32>": {
		type: "u32",
		components: 12
	},
	"mat4x4<u32>": {
		type: "u32",
		components: 16
	}
};
/**  Predeclared aliases @see https://www.w3.org/TR/WGSL/#vector-types */
const WGSL_ATTRIBUTE_TYPE_ALIAS_MAP = {
	vec2i: "vec2<i32>",
	vec3i: "vec3<i32>",
	vec4i: "vec4<i32>",
	vec2u: "vec2<u32>",
	vec3u: "vec3<u32>",
	vec4u: "vec4<u32>",
	vec2f: "vec2<f32>",
	vec3f: "vec3<f32>",
	vec4f: "vec4<f32>",
	vec2h: "vec2<f16>",
	vec3h: "vec3<f16>",
	vec4h: "vec4<f16>"
};
/** @todo These tables are quite big, consider parsing alias strings instead */
const WGSL_VARIABLE_TYPE_ALIAS_MAP = {
	...WGSL_ATTRIBUTE_TYPE_ALIAS_MAP,
	mat2x2f: "mat2x2<f32>",
	mat2x3f: "mat2x3<f32>",
	mat2x4f: "mat2x4<f32>",
	mat3x2f: "mat3x2<f32>",
	mat3x3f: "mat3x3<f32>",
	mat3x4f: "mat3x4<f32>",
	mat4x2f: "mat4x2<f32>",
	mat4x3f: "mat4x3<f32>",
	mat4x4f: "mat4x4<f32>",
	mat2x2i: "mat2x2<i32>",
	mat2x3i: "mat2x3<i32>",
	mat2x4i: "mat2x4<i32>",
	mat3x2i: "mat3x2<i32>",
	mat3x3i: "mat3x3<i32>",
	mat3x4i: "mat3x4<i32>",
	mat4x2i: "mat4x2<i32>",
	mat4x3i: "mat4x3<i32>",
	mat4x4i: "mat4x4<i32>",
	mat2x2u: "mat2x2<u32>",
	mat2x3u: "mat2x3<u32>",
	mat2x4u: "mat2x4<u32>",
	mat3x2u: "mat3x2<u32>",
	mat3x3u: "mat3x3<u32>",
	mat3x4u: "mat3x4<u32>",
	mat4x2u: "mat4x2<u32>",
	mat4x3u: "mat4x3<u32>",
	mat4x4u: "mat4x4<u32>",
	mat2x2h: "mat2x2<f16>",
	mat2x3h: "mat2x3<f16>",
	mat2x4h: "mat2x4<f16>",
	mat3x2h: "mat3x2<f16>",
	mat3x3h: "mat3x3<f16>",
	mat3x4h: "mat3x4<f16>",
	mat4x2h: "mat4x2<f16>",
	mat4x3h: "mat4x3<f16>",
	mat4x4h: "mat4x4<f16>"
};

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter-utils/get-attribute-from-layouts.js
/**
* Map from "attribute names" to "resolved attribute infos"
* containing information about both buffer layouts and shader attribute declarations
*/
function getAttributeInfosFromLayouts(shaderLayout, bufferLayout) {
	const attributeInfos = {};
	for (const attribute of shaderLayout.attributes) {
		const attributeInfo = getAttributeInfoFromLayouts(shaderLayout, bufferLayout, attribute.name);
		if (attributeInfo) attributeInfos[attribute.name] = attributeInfo;
	}
	return attributeInfos;
}
/**
* Array indexed by "location" holding "resolved attribute infos"
*/
function getAttributeInfosByLocation(shaderLayout, bufferLayout, maxVertexAttributes = 16) {
	const attributeInfos = getAttributeInfosFromLayouts(shaderLayout, bufferLayout);
	const locationInfos = new Array(maxVertexAttributes).fill(null);
	for (const attributeInfo of Object.values(attributeInfos)) locationInfos[attributeInfo.location] = attributeInfo;
	return locationInfos;
}
/**
* Get the combined information from a shader layout and a buffer layout for a specific attribute
*/
function getAttributeInfoFromLayouts(shaderLayout, bufferLayout, name$1) {
	const shaderDeclaration = getAttributeFromShaderLayout(shaderLayout, name$1);
	const bufferMapping = getAttributeFromBufferLayout(bufferLayout, name$1);
	if (!shaderDeclaration) return null;
	const attributeTypeInfo = getAttributeShaderTypeInfo(shaderDeclaration.type);
	const defaultVertexFormat = getCompatibleVertexFormat(attributeTypeInfo);
	const vertexFormat = bufferMapping?.vertexFormat || defaultVertexFormat;
	const vertexFormatInfo = getVertexFormatInfo(vertexFormat);
	return {
		attributeName: bufferMapping?.attributeName || shaderDeclaration.name,
		bufferName: bufferMapping?.bufferName || shaderDeclaration.name,
		location: shaderDeclaration.location,
		shaderType: shaderDeclaration.type,
		primitiveType: attributeTypeInfo.primitiveType,
		shaderComponents: attributeTypeInfo.components,
		vertexFormat,
		bufferDataType: vertexFormatInfo.type,
		bufferComponents: vertexFormatInfo.components,
		normalized: vertexFormatInfo.normalized,
		integer: attributeTypeInfo.integer,
		stepMode: bufferMapping?.stepMode || shaderDeclaration.stepMode || "vertex",
		byteOffset: bufferMapping?.byteOffset || 0,
		byteStride: bufferMapping?.byteStride || 0
	};
}
function getAttributeFromShaderLayout(shaderLayout, name$1) {
	const attribute = shaderLayout.attributes.find((attr) => attr.name === name$1);
	if (!attribute) log.warn(`shader layout attribute "${name$1}" not present in shader`);
	return attribute || null;
}
function getAttributeFromBufferLayout(bufferLayouts, name$1) {
	checkBufferLayouts(bufferLayouts);
	let bufferLayoutInfo = getAttributeFromShortHand(bufferLayouts, name$1);
	if (bufferLayoutInfo) return bufferLayoutInfo;
	bufferLayoutInfo = getAttributeFromAttributesList(bufferLayouts, name$1);
	if (bufferLayoutInfo) return bufferLayoutInfo;
	log.warn(`layout for attribute "${name$1}" not present in buffer layout`);
	return null;
}
/** Check that bufferLayouts are valid (each either has format or attribute) */
function checkBufferLayouts(bufferLayouts) {
	for (const bufferLayout of bufferLayouts) if (bufferLayout.attributes && bufferLayout.format || !bufferLayout.attributes && !bufferLayout.format) log.warn(`BufferLayout ${name} must have either 'attributes' or 'format' field`);
}
/** Get attribute from format shorthand if specified */
function getAttributeFromShortHand(bufferLayouts, name$1) {
	for (const bufferLayout of bufferLayouts) if (bufferLayout.format && bufferLayout.name === name$1) return {
		attributeName: bufferLayout.name,
		bufferName: name$1,
		stepMode: bufferLayout.stepMode,
		vertexFormat: bufferLayout.format,
		byteOffset: 0,
		byteStride: bufferLayout.byteStride || 0
	};
	return null;
}
/**
* Search attribute mappings (e.g. interleaved attributes) for buffer mapping.
* Not the name of the buffer might be the same as one of the interleaved attributes.
*/
function getAttributeFromAttributesList(bufferLayouts, name$1) {
	for (const bufferLayout of bufferLayouts) {
		let byteStride = bufferLayout.byteStride;
		if (typeof bufferLayout.byteStride !== "number") for (const attributeMapping$1 of bufferLayout.attributes || []) {
			const info = getVertexFormatInfo(attributeMapping$1.format);
			byteStride += info.byteLength;
		}
		const attributeMapping = bufferLayout.attributes?.find((mapping) => mapping.attribute === name$1);
		if (attributeMapping) return {
			attributeName: attributeMapping.attribute,
			bufferName: bufferLayout.name,
			stepMode: bufferLayout.stepMode,
			vertexFormat: attributeMapping.format,
			byteOffset: attributeMapping.byteOffset,
			byteStride
		};
	}
	return null;
}

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/resources/vertex-array.js
/**
* Stores attribute bindings.
* Makes it easy to share a render pipeline and use separate vertex arrays.
* @note On WebGL, VertexArray allows non-constant bindings to be performed in advance
* reducing the number of WebGL calls per draw call.
* @note On WebGPU this is just a convenience class that collects the bindings.
*/
var VertexArray = class VertexArray extends Resource {
	static defaultProps = {
		...Resource.defaultProps,
		shaderLayout: void 0,
		bufferLayout: []
	};
	get [Symbol.toStringTag]() {
		return "VertexArray";
	}
	/** Max number of vertex attributes */
	maxVertexAttributes;
	/** Attribute infos indexed by location - TODO only needed by webgl module? */
	attributeInfos;
	/** Index buffer */
	indexBuffer = null;
	/** Attributes indexed by buffer slot */
	attributes;
	constructor(device, props) {
		super(device, props, VertexArray.defaultProps);
		this.maxVertexAttributes = device.limits.maxVertexAttributes;
		this.attributes = new Array(this.maxVertexAttributes).fill(null);
		this.attributeInfos = getAttributeInfosByLocation(props.shaderLayout, props.bufferLayout, this.maxVertexAttributes);
	}
	/** @deprecated Set constant attributes (WebGL only) */
	setConstantWebGL(location, value) {
		this.device.reportError(/* @__PURE__ */ new Error("constant attributes not supported"), this)();
	}
};

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/resources/transform-feedback.js
/** Holds a set of output buffers for pipeline (WebGL only) */
var TransformFeedback = class TransformFeedback extends Resource {
	static defaultProps = {
		...Resource.defaultProps,
		layout: void 0,
		buffers: {}
	};
	get [Symbol.toStringTag]() {
		return "TransformFeedback";
	}
	constructor(device, props) {
		super(device, props, TransformFeedback.defaultProps);
	}
};

//#endregion
//#region node_modules/@luma.gl/core/dist/adapter/resources/query-set.js
/** Immutable QuerySet object */
var QuerySet = class QuerySet extends Resource {
	get [Symbol.toStringTag]() {
		return "QuerySet";
	}
	constructor(device, props) {
		super(device, props, QuerySet.defaultProps);
	}
	static defaultProps = {
		...Resource.defaultProps,
		type: void 0,
		count: void 0
	};
};

//#endregion
//#region node_modules/@luma.gl/core/dist/utils/array-utils-flat.js
var arrayBuffer;
function getScratchArrayBuffer(byteLength) {
	if (!arrayBuffer || arrayBuffer.byteLength < byteLength) arrayBuffer = new ArrayBuffer(byteLength);
	return arrayBuffer;
}
function getScratchArray(Type, length) {
	return new Type(getScratchArrayBuffer(Type.BYTES_PER_ELEMENT * length), 0, length);
}

//#endregion
//#region node_modules/@luma.gl/constants/dist/webgl-constants.js
/**
* Standard WebGL, WebGL2 and extension constants (OpenGL constants)
* @note (Most) of these constants are also defined on the WebGLRenderingContext interface.
* @see https://developer.mozilla.org/en-US/docs/Web/API/WebGL_API/Constants
* @privateRemarks Locally called `GLEnum` instead of `GL`, because `babel-plugin-inline-webl-constants`
*  both depends on and processes this module, but shouldn't replace these declarations.
*/
var GLEnum;
(function(GLEnum$1) {
	/** Passed to clear to clear the current depth buffer. */
	GLEnum$1[GLEnum$1["DEPTH_BUFFER_BIT"] = 256] = "DEPTH_BUFFER_BIT";
	/** Passed to clear to clear the current stencil buffer. */
	GLEnum$1[GLEnum$1["STENCIL_BUFFER_BIT"] = 1024] = "STENCIL_BUFFER_BIT";
	/** Passed to clear to clear the current color buffer. */
	GLEnum$1[GLEnum$1["COLOR_BUFFER_BIT"] = 16384] = "COLOR_BUFFER_BIT";
	/** Passed to drawElements or drawArrays to draw single points. */
	GLEnum$1[GLEnum$1["POINTS"] = 0] = "POINTS";
	/** Passed to drawElements or drawArrays to draw lines. Each vertex connects to the one after it. */
	GLEnum$1[GLEnum$1["LINES"] = 1] = "LINES";
	/** Passed to drawElements or drawArrays to draw lines. Each set of two vertices is treated as a separate line segment. */
	GLEnum$1[GLEnum$1["LINE_LOOP"] = 2] = "LINE_LOOP";
	/** Passed to drawElements or drawArrays to draw a connected group of line segments from the first vertex to the last. */
	GLEnum$1[GLEnum$1["LINE_STRIP"] = 3] = "LINE_STRIP";
	/** Passed to drawElements or drawArrays to draw triangles. Each set of three vertices creates a separate triangle. */
	GLEnum$1[GLEnum$1["TRIANGLES"] = 4] = "TRIANGLES";
	/** Passed to drawElements or drawArrays to draw a connected group of triangles. */
	GLEnum$1[GLEnum$1["TRIANGLE_STRIP"] = 5] = "TRIANGLE_STRIP";
	/** Passed to drawElements or drawArrays to draw a connected group of triangles. Each vertex connects to the previous and the first vertex in the fan. */
	GLEnum$1[GLEnum$1["TRIANGLE_FAN"] = 6] = "TRIANGLE_FAN";
	/** Passed to blendFunc or blendFuncSeparate to turn off a component. */
	GLEnum$1[GLEnum$1["ZERO"] = 0] = "ZERO";
	/** Passed to blendFunc or blendFuncSeparate to turn on a component. */
	GLEnum$1[GLEnum$1["ONE"] = 1] = "ONE";
	/** Passed to blendFunc or blendFuncSeparate to multiply a component by the source elements color. */
	GLEnum$1[GLEnum$1["SRC_COLOR"] = 768] = "SRC_COLOR";
	/** Passed to blendFunc or blendFuncSeparate to multiply a component by one minus the source elements color. */
	GLEnum$1[GLEnum$1["ONE_MINUS_SRC_COLOR"] = 769] = "ONE_MINUS_SRC_COLOR";
	/** Passed to blendFunc or blendFuncSeparate to multiply a component by the source's alpha. */
	GLEnum$1[GLEnum$1["SRC_ALPHA"] = 770] = "SRC_ALPHA";
	/** Passed to blendFunc or blendFuncSeparate to multiply a component by one minus the source's alpha. */
	GLEnum$1[GLEnum$1["ONE_MINUS_SRC_ALPHA"] = 771] = "ONE_MINUS_SRC_ALPHA";
	/** Passed to blendFunc or blendFuncSeparate to multiply a component by the destination's alpha. */
	GLEnum$1[GLEnum$1["DST_ALPHA"] = 772] = "DST_ALPHA";
	/** Passed to blendFunc or blendFuncSeparate to multiply a component by one minus the destination's alpha. */
	GLEnum$1[GLEnum$1["ONE_MINUS_DST_ALPHA"] = 773] = "ONE_MINUS_DST_ALPHA";
	/** Passed to blendFunc or blendFuncSeparate to multiply a component by the destination's color. */
	GLEnum$1[GLEnum$1["DST_COLOR"] = 774] = "DST_COLOR";
	/** Passed to blendFunc or blendFuncSeparate to multiply a component by one minus the destination's color. */
	GLEnum$1[GLEnum$1["ONE_MINUS_DST_COLOR"] = 775] = "ONE_MINUS_DST_COLOR";
	/** Passed to blendFunc or blendFuncSeparate to multiply a component by the minimum of source's alpha or one minus the destination's alpha. */
	GLEnum$1[GLEnum$1["SRC_ALPHA_SATURATE"] = 776] = "SRC_ALPHA_SATURATE";
	/** Passed to blendFunc or blendFuncSeparate to specify a constant color blend function. */
	GLEnum$1[GLEnum$1["CONSTANT_COLOR"] = 32769] = "CONSTANT_COLOR";
	/** Passed to blendFunc or blendFuncSeparate to specify one minus a constant color blend function. */
	GLEnum$1[GLEnum$1["ONE_MINUS_CONSTANT_COLOR"] = 32770] = "ONE_MINUS_CONSTANT_COLOR";
	/** Passed to blendFunc or blendFuncSeparate to specify a constant alpha blend function. */
	GLEnum$1[GLEnum$1["CONSTANT_ALPHA"] = 32771] = "CONSTANT_ALPHA";
	/** Passed to blendFunc or blendFuncSeparate to specify one minus a constant alpha blend function. */
	GLEnum$1[GLEnum$1["ONE_MINUS_CONSTANT_ALPHA"] = 32772] = "ONE_MINUS_CONSTANT_ALPHA";
	/** Passed to blendEquation or blendEquationSeparate to set an addition blend function. */
	/** Passed to blendEquation or blendEquationSeparate to specify a subtraction blend function (source - destination). */
	/** Passed to blendEquation or blendEquationSeparate to specify a reverse subtraction blend function (destination - source). */
	GLEnum$1[GLEnum$1["FUNC_ADD"] = 32774] = "FUNC_ADD";
	GLEnum$1[GLEnum$1["FUNC_SUBTRACT"] = 32778] = "FUNC_SUBTRACT";
	GLEnum$1[GLEnum$1["FUNC_REVERSE_SUBTRACT"] = 32779] = "FUNC_REVERSE_SUBTRACT";
	/** Passed to getParameter to get the current RGB blend function. */
	GLEnum$1[GLEnum$1["BLEND_EQUATION"] = 32777] = "BLEND_EQUATION";
	/** Passed to getParameter to get the current RGB blend function. Same as BLEND_EQUATION */
	GLEnum$1[GLEnum$1["BLEND_EQUATION_RGB"] = 32777] = "BLEND_EQUATION_RGB";
	/** Passed to getParameter to get the current alpha blend function. Same as BLEND_EQUATION */
	GLEnum$1[GLEnum$1["BLEND_EQUATION_ALPHA"] = 34877] = "BLEND_EQUATION_ALPHA";
	/** Passed to getParameter to get the current destination RGB blend function. */
	GLEnum$1[GLEnum$1["BLEND_DST_RGB"] = 32968] = "BLEND_DST_RGB";
	/** Passed to getParameter to get the current destination RGB blend function. */
	GLEnum$1[GLEnum$1["BLEND_SRC_RGB"] = 32969] = "BLEND_SRC_RGB";
	/** Passed to getParameter to get the current destination alpha blend function. */
	GLEnum$1[GLEnum$1["BLEND_DST_ALPHA"] = 32970] = "BLEND_DST_ALPHA";
	/** Passed to getParameter to get the current source alpha blend function. */
	GLEnum$1[GLEnum$1["BLEND_SRC_ALPHA"] = 32971] = "BLEND_SRC_ALPHA";
	/** Passed to getParameter to return a the current blend color. */
	GLEnum$1[GLEnum$1["BLEND_COLOR"] = 32773] = "BLEND_COLOR";
	/** Passed to getParameter to get the array buffer binding. */
	GLEnum$1[GLEnum$1["ARRAY_BUFFER_BINDING"] = 34964] = "ARRAY_BUFFER_BINDING";
	/** Passed to getParameter to get the current element array buffer. */
	GLEnum$1[GLEnum$1["ELEMENT_ARRAY_BUFFER_BINDING"] = 34965] = "ELEMENT_ARRAY_BUFFER_BINDING";
	/** Passed to getParameter to get the current lineWidth (set by the lineWidth method). */
	GLEnum$1[GLEnum$1["LINE_WIDTH"] = 2849] = "LINE_WIDTH";
	/** Passed to getParameter to get the current size of a point drawn with gl.POINTS */
	GLEnum$1[GLEnum$1["ALIASED_POINT_SIZE_RANGE"] = 33901] = "ALIASED_POINT_SIZE_RANGE";
	/** Passed to getParameter to get the range of available widths for a line. Returns a length-2 array with the lo value at 0, and hight at 1. */
	GLEnum$1[GLEnum$1["ALIASED_LINE_WIDTH_RANGE"] = 33902] = "ALIASED_LINE_WIDTH_RANGE";
	/** Passed to getParameter to get the current value of cullFace. Should return FRONT, BACK, or FRONT_AND_BACK */
	GLEnum$1[GLEnum$1["CULL_FACE_MODE"] = 2885] = "CULL_FACE_MODE";
	/** Passed to getParameter to determine the current value of frontFace. Should return CW or CCW. */
	GLEnum$1[GLEnum$1["FRONT_FACE"] = 2886] = "FRONT_FACE";
	/** Passed to getParameter to return a length-2 array of floats giving the current depth range. */
	GLEnum$1[GLEnum$1["DEPTH_RANGE"] = 2928] = "DEPTH_RANGE";
	/** Passed to getParameter to determine if the depth write mask is enabled. */
	GLEnum$1[GLEnum$1["DEPTH_WRITEMASK"] = 2930] = "DEPTH_WRITEMASK";
	/** Passed to getParameter to determine the current depth clear value. */
	GLEnum$1[GLEnum$1["DEPTH_CLEAR_VALUE"] = 2931] = "DEPTH_CLEAR_VALUE";
	/** Passed to getParameter to get the current depth function. Returns NEVER, ALWAYS, LESS, EQUAL, LEQUAL, GREATER, GEQUAL, or NOTEQUAL. */
	GLEnum$1[GLEnum$1["DEPTH_FUNC"] = 2932] = "DEPTH_FUNC";
	/** Passed to getParameter to get the value the stencil will be cleared to. */
	GLEnum$1[GLEnum$1["STENCIL_CLEAR_VALUE"] = 2961] = "STENCIL_CLEAR_VALUE";
	/** Passed to getParameter to get the current stencil function. Returns NEVER, ALWAYS, LESS, EQUAL, LEQUAL, GREATER, GEQUAL, or NOTEQUAL. */
	GLEnum$1[GLEnum$1["STENCIL_FUNC"] = 2962] = "STENCIL_FUNC";
	/** Passed to getParameter to get the current stencil fail function. Should return KEEP, REPLACE, INCR, DECR, INVERT, INCR_WRAP, or DECR_WRAP. */
	GLEnum$1[GLEnum$1["STENCIL_FAIL"] = 2964] = "STENCIL_FAIL";
	/** Passed to getParameter to get the current stencil fail function should the depth buffer test fail. Should return KEEP, REPLACE, INCR, DECR, INVERT, INCR_WRAP, or DECR_WRAP. */
	GLEnum$1[GLEnum$1["STENCIL_PASS_DEPTH_FAIL"] = 2965] = "STENCIL_PASS_DEPTH_FAIL";
	/** Passed to getParameter to get the current stencil fail function should the depth buffer test pass. Should return KEEP, REPLACE, INCR, DECR, INVERT, INCR_WRAP, or DECR_WRAP. */
	GLEnum$1[GLEnum$1["STENCIL_PASS_DEPTH_PASS"] = 2966] = "STENCIL_PASS_DEPTH_PASS";
	/** Passed to getParameter to get the reference value used for stencil tests. */
	GLEnum$1[GLEnum$1["STENCIL_REF"] = 2967] = "STENCIL_REF";
	GLEnum$1[GLEnum$1["STENCIL_VALUE_MASK"] = 2963] = "STENCIL_VALUE_MASK";
	GLEnum$1[GLEnum$1["STENCIL_WRITEMASK"] = 2968] = "STENCIL_WRITEMASK";
	GLEnum$1[GLEnum$1["STENCIL_BACK_FUNC"] = 34816] = "STENCIL_BACK_FUNC";
	GLEnum$1[GLEnum$1["STENCIL_BACK_FAIL"] = 34817] = "STENCIL_BACK_FAIL";
	GLEnum$1[GLEnum$1["STENCIL_BACK_PASS_DEPTH_FAIL"] = 34818] = "STENCIL_BACK_PASS_DEPTH_FAIL";
	GLEnum$1[GLEnum$1["STENCIL_BACK_PASS_DEPTH_PASS"] = 34819] = "STENCIL_BACK_PASS_DEPTH_PASS";
	GLEnum$1[GLEnum$1["STENCIL_BACK_REF"] = 36003] = "STENCIL_BACK_REF";
	GLEnum$1[GLEnum$1["STENCIL_BACK_VALUE_MASK"] = 36004] = "STENCIL_BACK_VALUE_MASK";
	GLEnum$1[GLEnum$1["STENCIL_BACK_WRITEMASK"] = 36005] = "STENCIL_BACK_WRITEMASK";
	/** An Int32Array with four elements for the current viewport dimensions. */
	GLEnum$1[GLEnum$1["VIEWPORT"] = 2978] = "VIEWPORT";
	/** An Int32Array with four elements for the current scissor box dimensions. */
	GLEnum$1[GLEnum$1["SCISSOR_BOX"] = 3088] = "SCISSOR_BOX";
	GLEnum$1[GLEnum$1["COLOR_CLEAR_VALUE"] = 3106] = "COLOR_CLEAR_VALUE";
	GLEnum$1[GLEnum$1["COLOR_WRITEMASK"] = 3107] = "COLOR_WRITEMASK";
	GLEnum$1[GLEnum$1["UNPACK_ALIGNMENT"] = 3317] = "UNPACK_ALIGNMENT";
	GLEnum$1[GLEnum$1["PACK_ALIGNMENT"] = 3333] = "PACK_ALIGNMENT";
	GLEnum$1[GLEnum$1["MAX_TEXTURE_SIZE"] = 3379] = "MAX_TEXTURE_SIZE";
	GLEnum$1[GLEnum$1["MAX_VIEWPORT_DIMS"] = 3386] = "MAX_VIEWPORT_DIMS";
	GLEnum$1[GLEnum$1["SUBPIXEL_BITS"] = 3408] = "SUBPIXEL_BITS";
	GLEnum$1[GLEnum$1["RED_BITS"] = 3410] = "RED_BITS";
	GLEnum$1[GLEnum$1["GREEN_BITS"] = 3411] = "GREEN_BITS";
	GLEnum$1[GLEnum$1["BLUE_BITS"] = 3412] = "BLUE_BITS";
	GLEnum$1[GLEnum$1["ALPHA_BITS"] = 3413] = "ALPHA_BITS";
	GLEnum$1[GLEnum$1["DEPTH_BITS"] = 3414] = "DEPTH_BITS";
	GLEnum$1[GLEnum$1["STENCIL_BITS"] = 3415] = "STENCIL_BITS";
	GLEnum$1[GLEnum$1["POLYGON_OFFSET_UNITS"] = 10752] = "POLYGON_OFFSET_UNITS";
	GLEnum$1[GLEnum$1["POLYGON_OFFSET_FACTOR"] = 32824] = "POLYGON_OFFSET_FACTOR";
	GLEnum$1[GLEnum$1["TEXTURE_BINDING_2D"] = 32873] = "TEXTURE_BINDING_2D";
	GLEnum$1[GLEnum$1["SAMPLE_BUFFERS"] = 32936] = "SAMPLE_BUFFERS";
	GLEnum$1[GLEnum$1["SAMPLES"] = 32937] = "SAMPLES";
	GLEnum$1[GLEnum$1["SAMPLE_COVERAGE_VALUE"] = 32938] = "SAMPLE_COVERAGE_VALUE";
	GLEnum$1[GLEnum$1["SAMPLE_COVERAGE_INVERT"] = 32939] = "SAMPLE_COVERAGE_INVERT";
	GLEnum$1[GLEnum$1["COMPRESSED_TEXTURE_FORMATS"] = 34467] = "COMPRESSED_TEXTURE_FORMATS";
	GLEnum$1[GLEnum$1["VENDOR"] = 7936] = "VENDOR";
	GLEnum$1[GLEnum$1["RENDERER"] = 7937] = "RENDERER";
	GLEnum$1[GLEnum$1["VERSION"] = 7938] = "VERSION";
	GLEnum$1[GLEnum$1["IMPLEMENTATION_COLOR_READ_TYPE"] = 35738] = "IMPLEMENTATION_COLOR_READ_TYPE";
	GLEnum$1[GLEnum$1["IMPLEMENTATION_COLOR_READ_FORMAT"] = 35739] = "IMPLEMENTATION_COLOR_READ_FORMAT";
	GLEnum$1[GLEnum$1["BROWSER_DEFAULT_WEBGL"] = 37444] = "BROWSER_DEFAULT_WEBGL";
	/** Passed to bufferData as a hint about whether the contents of the buffer are likely to be used often and not change often. */
	GLEnum$1[GLEnum$1["STATIC_DRAW"] = 35044] = "STATIC_DRAW";
	/** Passed to bufferData as a hint about whether the contents of the buffer are likely to not be used often. */
	GLEnum$1[GLEnum$1["STREAM_DRAW"] = 35040] = "STREAM_DRAW";
	/** Passed to bufferData as a hint about whether the contents of the buffer are likely to be used often and change often. */
	GLEnum$1[GLEnum$1["DYNAMIC_DRAW"] = 35048] = "DYNAMIC_DRAW";
	/** Passed to bindBuffer or bufferData to specify the type of buffer being used. */
	GLEnum$1[GLEnum$1["ARRAY_BUFFER"] = 34962] = "ARRAY_BUFFER";
	/** Passed to bindBuffer or bufferData to specify the type of buffer being used. */
	GLEnum$1[GLEnum$1["ELEMENT_ARRAY_BUFFER"] = 34963] = "ELEMENT_ARRAY_BUFFER";
	/** Passed to getBufferParameter to get a buffer's size. */
	GLEnum$1[GLEnum$1["BUFFER_SIZE"] = 34660] = "BUFFER_SIZE";
	/** Passed to getBufferParameter to get the hint for the buffer passed in when it was created. */
	GLEnum$1[GLEnum$1["BUFFER_USAGE"] = 34661] = "BUFFER_USAGE";
	/** Passed to getVertexAttrib to read back the current vertex attribute. */
	GLEnum$1[GLEnum$1["CURRENT_VERTEX_ATTRIB"] = 34342] = "CURRENT_VERTEX_ATTRIB";
	GLEnum$1[GLEnum$1["VERTEX_ATTRIB_ARRAY_ENABLED"] = 34338] = "VERTEX_ATTRIB_ARRAY_ENABLED";
	GLEnum$1[GLEnum$1["VERTEX_ATTRIB_ARRAY_SIZE"] = 34339] = "VERTEX_ATTRIB_ARRAY_SIZE";
	GLEnum$1[GLEnum$1["VERTEX_ATTRIB_ARRAY_STRIDE"] = 34340] = "VERTEX_ATTRIB_ARRAY_STRIDE";
	GLEnum$1[GLEnum$1["VERTEX_ATTRIB_ARRAY_TYPE"] = 34341] = "VERTEX_ATTRIB_ARRAY_TYPE";
	GLEnum$1[GLEnum$1["VERTEX_ATTRIB_ARRAY_NORMALIZED"] = 34922] = "VERTEX_ATTRIB_ARRAY_NORMALIZED";
	GLEnum$1[GLEnum$1["VERTEX_ATTRIB_ARRAY_POINTER"] = 34373] = "VERTEX_ATTRIB_ARRAY_POINTER";
	GLEnum$1[GLEnum$1["VERTEX_ATTRIB_ARRAY_BUFFER_BINDING"] = 34975] = "VERTEX_ATTRIB_ARRAY_BUFFER_BINDING";
	/** Passed to enable/disable to turn on/off culling. Can also be used with getParameter to find the current culling method. */
	GLEnum$1[GLEnum$1["CULL_FACE"] = 2884] = "CULL_FACE";
	/** Passed to cullFace to specify that only front faces should be culled. */
	GLEnum$1[GLEnum$1["FRONT"] = 1028] = "FRONT";
	/** Passed to cullFace to specify that only back faces should be culled. */
	GLEnum$1[GLEnum$1["BACK"] = 1029] = "BACK";
	/** Passed to cullFace to specify that front and back faces should be culled. */
	GLEnum$1[GLEnum$1["FRONT_AND_BACK"] = 1032] = "FRONT_AND_BACK";
	/** Passed to enable/disable to turn on/off blending. Can also be used with getParameter to find the current blending method. */
	GLEnum$1[GLEnum$1["BLEND"] = 3042] = "BLEND";
	/** Passed to enable/disable to turn on/off the depth test. Can also be used with getParameter to query the depth test. */
	GLEnum$1[GLEnum$1["DEPTH_TEST"] = 2929] = "DEPTH_TEST";
	/** Passed to enable/disable to turn on/off dithering. Can also be used with getParameter to find the current dithering method. */
	GLEnum$1[GLEnum$1["DITHER"] = 3024] = "DITHER";
	/** Passed to enable/disable to turn on/off the polygon offset. Useful for rendering hidden-line images, decals, and or solids with highlighted edges. Can also be used with getParameter to query the scissor test. */
	GLEnum$1[GLEnum$1["POLYGON_OFFSET_FILL"] = 32823] = "POLYGON_OFFSET_FILL";
	/** Passed to enable/disable to turn on/off the alpha to coverage. Used in multi-sampling alpha channels. */
	GLEnum$1[GLEnum$1["SAMPLE_ALPHA_TO_COVERAGE"] = 32926] = "SAMPLE_ALPHA_TO_COVERAGE";
	/** Passed to enable/disable to turn on/off the sample coverage. Used in multi-sampling. */
	GLEnum$1[GLEnum$1["SAMPLE_COVERAGE"] = 32928] = "SAMPLE_COVERAGE";
	/** Passed to enable/disable to turn on/off the scissor test. Can also be used with getParameter to query the scissor test. */
	GLEnum$1[GLEnum$1["SCISSOR_TEST"] = 3089] = "SCISSOR_TEST";
	/** Passed to enable/disable to turn on/off the stencil test. Can also be used with getParameter to query the stencil test. */
	GLEnum$1[GLEnum$1["STENCIL_TEST"] = 2960] = "STENCIL_TEST";
	/** Returned from getError(). */
	GLEnum$1[GLEnum$1["NO_ERROR"] = 0] = "NO_ERROR";
	/** Returned from getError(). */
	GLEnum$1[GLEnum$1["INVALID_ENUM"] = 1280] = "INVALID_ENUM";
	/** Returned from getError(). */
	GLEnum$1[GLEnum$1["INVALID_VALUE"] = 1281] = "INVALID_VALUE";
	/** Returned from getError(). */
	GLEnum$1[GLEnum$1["INVALID_OPERATION"] = 1282] = "INVALID_OPERATION";
	/** Returned from getError(). */
	GLEnum$1[GLEnum$1["OUT_OF_MEMORY"] = 1285] = "OUT_OF_MEMORY";
	/** Returned from getError(). */
	GLEnum$1[GLEnum$1["CONTEXT_LOST_WEBGL"] = 37442] = "CONTEXT_LOST_WEBGL";
	/** Passed to frontFace to specify the front face of a polygon is drawn in the clockwise direction */
	GLEnum$1[GLEnum$1["CW"] = 2304] = "CW";
	/** Passed to frontFace to specify the front face of a polygon is drawn in the counter clockwise direction */
	GLEnum$1[GLEnum$1["CCW"] = 2305] = "CCW";
	/** There is no preference for this behavior. */
	GLEnum$1[GLEnum$1["DONT_CARE"] = 4352] = "DONT_CARE";
	/** The most efficient behavior should be used. */
	GLEnum$1[GLEnum$1["FASTEST"] = 4353] = "FASTEST";
	/** The most correct or the highest quality option should be used. */
	GLEnum$1[GLEnum$1["NICEST"] = 4354] = "NICEST";
	/** Hint for the quality of filtering when generating mipmap images with WebGLRenderingContext.generateMipmap(). */
	GLEnum$1[GLEnum$1["GENERATE_MIPMAP_HINT"] = 33170] = "GENERATE_MIPMAP_HINT";
	GLEnum$1[GLEnum$1["BYTE"] = 5120] = "BYTE";
	GLEnum$1[GLEnum$1["UNSIGNED_BYTE"] = 5121] = "UNSIGNED_BYTE";
	GLEnum$1[GLEnum$1["SHORT"] = 5122] = "SHORT";
	GLEnum$1[GLEnum$1["UNSIGNED_SHORT"] = 5123] = "UNSIGNED_SHORT";
	GLEnum$1[GLEnum$1["INT"] = 5124] = "INT";
	GLEnum$1[GLEnum$1["UNSIGNED_INT"] = 5125] = "UNSIGNED_INT";
	GLEnum$1[GLEnum$1["FLOAT"] = 5126] = "FLOAT";
	GLEnum$1[GLEnum$1["DOUBLE"] = 5130] = "DOUBLE";
	GLEnum$1[GLEnum$1["DEPTH_COMPONENT"] = 6402] = "DEPTH_COMPONENT";
	GLEnum$1[GLEnum$1["ALPHA"] = 6406] = "ALPHA";
	GLEnum$1[GLEnum$1["RGB"] = 6407] = "RGB";
	GLEnum$1[GLEnum$1["RGBA"] = 6408] = "RGBA";
	GLEnum$1[GLEnum$1["LUMINANCE"] = 6409] = "LUMINANCE";
	GLEnum$1[GLEnum$1["LUMINANCE_ALPHA"] = 6410] = "LUMINANCE_ALPHA";
	GLEnum$1[GLEnum$1["UNSIGNED_SHORT_4_4_4_4"] = 32819] = "UNSIGNED_SHORT_4_4_4_4";
	GLEnum$1[GLEnum$1["UNSIGNED_SHORT_5_5_5_1"] = 32820] = "UNSIGNED_SHORT_5_5_5_1";
	GLEnum$1[GLEnum$1["UNSIGNED_SHORT_5_6_5"] = 33635] = "UNSIGNED_SHORT_5_6_5";
	/** Passed to createShader to define a fragment shader. */
	GLEnum$1[GLEnum$1["FRAGMENT_SHADER"] = 35632] = "FRAGMENT_SHADER";
	/** Passed to createShader to define a vertex shader */
	GLEnum$1[GLEnum$1["VERTEX_SHADER"] = 35633] = "VERTEX_SHADER";
	/** Passed to getShaderParameter to get the status of the compilation. Returns false if the shader was not compiled. You can then query getShaderInfoLog to find the exact error */
	GLEnum$1[GLEnum$1["COMPILE_STATUS"] = 35713] = "COMPILE_STATUS";
	/** Passed to getShaderParameter to determine if a shader was deleted via deleteShader. Returns true if it was, false otherwise. */
	GLEnum$1[GLEnum$1["DELETE_STATUS"] = 35712] = "DELETE_STATUS";
	/** Passed to getProgramParameter after calling linkProgram to determine if a program was linked correctly. Returns false if there were errors. Use getProgramInfoLog to find the exact error. */
	GLEnum$1[GLEnum$1["LINK_STATUS"] = 35714] = "LINK_STATUS";
	/** Passed to getProgramParameter after calling validateProgram to determine if it is valid. Returns false if errors were found. */
	GLEnum$1[GLEnum$1["VALIDATE_STATUS"] = 35715] = "VALIDATE_STATUS";
	/** Passed to getProgramParameter after calling attachShader to determine if the shader was attached correctly. Returns false if errors occurred. */
	GLEnum$1[GLEnum$1["ATTACHED_SHADERS"] = 35717] = "ATTACHED_SHADERS";
	/** Passed to getProgramParameter to get the number of attributes active in a program. */
	GLEnum$1[GLEnum$1["ACTIVE_ATTRIBUTES"] = 35721] = "ACTIVE_ATTRIBUTES";
	/** Passed to getProgramParameter to get the number of uniforms active in a program. */
	GLEnum$1[GLEnum$1["ACTIVE_UNIFORMS"] = 35718] = "ACTIVE_UNIFORMS";
	/** The maximum number of entries possible in the vertex attribute list. */
	GLEnum$1[GLEnum$1["MAX_VERTEX_ATTRIBS"] = 34921] = "MAX_VERTEX_ATTRIBS";
	GLEnum$1[GLEnum$1["MAX_VERTEX_UNIFORM_VECTORS"] = 36347] = "MAX_VERTEX_UNIFORM_VECTORS";
	GLEnum$1[GLEnum$1["MAX_VARYING_VECTORS"] = 36348] = "MAX_VARYING_VECTORS";
	GLEnum$1[GLEnum$1["MAX_COMBINED_TEXTURE_IMAGE_UNITS"] = 35661] = "MAX_COMBINED_TEXTURE_IMAGE_UNITS";
	GLEnum$1[GLEnum$1["MAX_VERTEX_TEXTURE_IMAGE_UNITS"] = 35660] = "MAX_VERTEX_TEXTURE_IMAGE_UNITS";
	/** Implementation dependent number of maximum texture units. At least 8. */
	GLEnum$1[GLEnum$1["MAX_TEXTURE_IMAGE_UNITS"] = 34930] = "MAX_TEXTURE_IMAGE_UNITS";
	GLEnum$1[GLEnum$1["MAX_FRAGMENT_UNIFORM_VECTORS"] = 36349] = "MAX_FRAGMENT_UNIFORM_VECTORS";
	GLEnum$1[GLEnum$1["SHADER_TYPE"] = 35663] = "SHADER_TYPE";
	GLEnum$1[GLEnum$1["SHADING_LANGUAGE_VERSION"] = 35724] = "SHADING_LANGUAGE_VERSION";
	GLEnum$1[GLEnum$1["CURRENT_PROGRAM"] = 35725] = "CURRENT_PROGRAM";
	/** Passed to depthFunction or stencilFunction to specify depth or stencil tests will never pass, i.e., nothing will be drawn. */
	GLEnum$1[GLEnum$1["NEVER"] = 512] = "NEVER";
	/** Passed to depthFunction or stencilFunction to specify depth or stencil tests will pass if the new depth value is less than the stored value. */
	GLEnum$1[GLEnum$1["LESS"] = 513] = "LESS";
	/** Passed to depthFunction or stencilFunction to specify depth or stencil tests will pass if the new depth value is equals to the stored value. */
	GLEnum$1[GLEnum$1["EQUAL"] = 514] = "EQUAL";
	/** Passed to depthFunction or stencilFunction to specify depth or stencil tests will pass if the new depth value is less than or equal to the stored value. */
	GLEnum$1[GLEnum$1["LEQUAL"] = 515] = "LEQUAL";
	/** Passed to depthFunction or stencilFunction to specify depth or stencil tests will pass if the new depth value is greater than the stored value. */
	GLEnum$1[GLEnum$1["GREATER"] = 516] = "GREATER";
	/** Passed to depthFunction or stencilFunction to specify depth or stencil tests will pass if the new depth value is not equal to the stored value. */
	GLEnum$1[GLEnum$1["NOTEQUAL"] = 517] = "NOTEQUAL";
	/** Passed to depthFunction or stencilFunction to specify depth or stencil tests will pass if the new depth value is greater than or equal to the stored value. */
	GLEnum$1[GLEnum$1["GEQUAL"] = 518] = "GEQUAL";
	/** Passed to depthFunction or stencilFunction to specify depth or stencil tests will always pass, i.e., pixels will be drawn in the order they are drawn. */
	GLEnum$1[GLEnum$1["ALWAYS"] = 519] = "ALWAYS";
	GLEnum$1[GLEnum$1["KEEP"] = 7680] = "KEEP";
	GLEnum$1[GLEnum$1["REPLACE"] = 7681] = "REPLACE";
	GLEnum$1[GLEnum$1["INCR"] = 7682] = "INCR";
	GLEnum$1[GLEnum$1["DECR"] = 7683] = "DECR";
	GLEnum$1[GLEnum$1["INVERT"] = 5386] = "INVERT";
	GLEnum$1[GLEnum$1["INCR_WRAP"] = 34055] = "INCR_WRAP";
	GLEnum$1[GLEnum$1["DECR_WRAP"] = 34056] = "DECR_WRAP";
	GLEnum$1[GLEnum$1["NEAREST"] = 9728] = "NEAREST";
	GLEnum$1[GLEnum$1["LINEAR"] = 9729] = "LINEAR";
	GLEnum$1[GLEnum$1["NEAREST_MIPMAP_NEAREST"] = 9984] = "NEAREST_MIPMAP_NEAREST";
	GLEnum$1[GLEnum$1["LINEAR_MIPMAP_NEAREST"] = 9985] = "LINEAR_MIPMAP_NEAREST";
	GLEnum$1[GLEnum$1["NEAREST_MIPMAP_LINEAR"] = 9986] = "NEAREST_MIPMAP_LINEAR";
	GLEnum$1[GLEnum$1["LINEAR_MIPMAP_LINEAR"] = 9987] = "LINEAR_MIPMAP_LINEAR";
	/** The texture magnification function is used when the pixel being textured maps to an area less than or equal to one texture element. It sets the texture magnification function to either GL_NEAREST or GL_LINEAR (see below). GL_NEAREST is generally faster than GL_LINEAR, but it can produce textured images with sharper edges because the transition between texture elements is not as smooth. Default: GL_LINEAR.  */
	GLEnum$1[GLEnum$1["TEXTURE_MAG_FILTER"] = 10240] = "TEXTURE_MAG_FILTER";
	/** The texture minifying function is used whenever the pixel being textured maps to an area greater than one texture element. There are six defined minifying functions. Two of them use the nearest one or nearest four texture elements to compute the texture value. The other four use mipmaps. Default: GL_NEAREST_MIPMAP_LINEAR */
	GLEnum$1[GLEnum$1["TEXTURE_MIN_FILTER"] = 10241] = "TEXTURE_MIN_FILTER";
	/** Sets the wrap parameter for texture coordinate  to either GL_CLAMP_TO_EDGE, GL_MIRRORED_REPEAT, or GL_REPEAT. G */
	GLEnum$1[GLEnum$1["TEXTURE_WRAP_S"] = 10242] = "TEXTURE_WRAP_S";
	/** Sets the wrap parameter for texture coordinate  to either GL_CLAMP_TO_EDGE, GL_MIRRORED_REPEAT, or GL_REPEAT. G */
	GLEnum$1[GLEnum$1["TEXTURE_WRAP_T"] = 10243] = "TEXTURE_WRAP_T";
	GLEnum$1[GLEnum$1["TEXTURE_2D"] = 3553] = "TEXTURE_2D";
	GLEnum$1[GLEnum$1["TEXTURE"] = 5890] = "TEXTURE";
	GLEnum$1[GLEnum$1["TEXTURE_CUBE_MAP"] = 34067] = "TEXTURE_CUBE_MAP";
	GLEnum$1[GLEnum$1["TEXTURE_BINDING_CUBE_MAP"] = 34068] = "TEXTURE_BINDING_CUBE_MAP";
	GLEnum$1[GLEnum$1["TEXTURE_CUBE_MAP_POSITIVE_X"] = 34069] = "TEXTURE_CUBE_MAP_POSITIVE_X";
	GLEnum$1[GLEnum$1["TEXTURE_CUBE_MAP_NEGATIVE_X"] = 34070] = "TEXTURE_CUBE_MAP_NEGATIVE_X";
	GLEnum$1[GLEnum$1["TEXTURE_CUBE_MAP_POSITIVE_Y"] = 34071] = "TEXTURE_CUBE_MAP_POSITIVE_Y";
	GLEnum$1[GLEnum$1["TEXTURE_CUBE_MAP_NEGATIVE_Y"] = 34072] = "TEXTURE_CUBE_MAP_NEGATIVE_Y";
	GLEnum$1[GLEnum$1["TEXTURE_CUBE_MAP_POSITIVE_Z"] = 34073] = "TEXTURE_CUBE_MAP_POSITIVE_Z";
	GLEnum$1[GLEnum$1["TEXTURE_CUBE_MAP_NEGATIVE_Z"] = 34074] = "TEXTURE_CUBE_MAP_NEGATIVE_Z";
	GLEnum$1[GLEnum$1["MAX_CUBE_MAP_TEXTURE_SIZE"] = 34076] = "MAX_CUBE_MAP_TEXTURE_SIZE";
	GLEnum$1[GLEnum$1["TEXTURE0"] = 33984] = "TEXTURE0";
	GLEnum$1[GLEnum$1["ACTIVE_TEXTURE"] = 34016] = "ACTIVE_TEXTURE";
	GLEnum$1[GLEnum$1["REPEAT"] = 10497] = "REPEAT";
	GLEnum$1[GLEnum$1["CLAMP_TO_EDGE"] = 33071] = "CLAMP_TO_EDGE";
	GLEnum$1[GLEnum$1["MIRRORED_REPEAT"] = 33648] = "MIRRORED_REPEAT";
	GLEnum$1[GLEnum$1["TEXTURE_WIDTH"] = 4096] = "TEXTURE_WIDTH";
	GLEnum$1[GLEnum$1["TEXTURE_HEIGHT"] = 4097] = "TEXTURE_HEIGHT";
	GLEnum$1[GLEnum$1["FLOAT_VEC2"] = 35664] = "FLOAT_VEC2";
	GLEnum$1[GLEnum$1["FLOAT_VEC3"] = 35665] = "FLOAT_VEC3";
	GLEnum$1[GLEnum$1["FLOAT_VEC4"] = 35666] = "FLOAT_VEC4";
	GLEnum$1[GLEnum$1["INT_VEC2"] = 35667] = "INT_VEC2";
	GLEnum$1[GLEnum$1["INT_VEC3"] = 35668] = "INT_VEC3";
	GLEnum$1[GLEnum$1["INT_VEC4"] = 35669] = "INT_VEC4";
	GLEnum$1[GLEnum$1["BOOL"] = 35670] = "BOOL";
	GLEnum$1[GLEnum$1["BOOL_VEC2"] = 35671] = "BOOL_VEC2";
	GLEnum$1[GLEnum$1["BOOL_VEC3"] = 35672] = "BOOL_VEC3";
	GLEnum$1[GLEnum$1["BOOL_VEC4"] = 35673] = "BOOL_VEC4";
	GLEnum$1[GLEnum$1["FLOAT_MAT2"] = 35674] = "FLOAT_MAT2";
	GLEnum$1[GLEnum$1["FLOAT_MAT3"] = 35675] = "FLOAT_MAT3";
	GLEnum$1[GLEnum$1["FLOAT_MAT4"] = 35676] = "FLOAT_MAT4";
	GLEnum$1[GLEnum$1["SAMPLER_2D"] = 35678] = "SAMPLER_2D";
	GLEnum$1[GLEnum$1["SAMPLER_CUBE"] = 35680] = "SAMPLER_CUBE";
	GLEnum$1[GLEnum$1["LOW_FLOAT"] = 36336] = "LOW_FLOAT";
	GLEnum$1[GLEnum$1["MEDIUM_FLOAT"] = 36337] = "MEDIUM_FLOAT";
	GLEnum$1[GLEnum$1["HIGH_FLOAT"] = 36338] = "HIGH_FLOAT";
	GLEnum$1[GLEnum$1["LOW_INT"] = 36339] = "LOW_INT";
	GLEnum$1[GLEnum$1["MEDIUM_INT"] = 36340] = "MEDIUM_INT";
	GLEnum$1[GLEnum$1["HIGH_INT"] = 36341] = "HIGH_INT";
	GLEnum$1[GLEnum$1["FRAMEBUFFER"] = 36160] = "FRAMEBUFFER";
	GLEnum$1[GLEnum$1["RENDERBUFFER"] = 36161] = "RENDERBUFFER";
	GLEnum$1[GLEnum$1["RGBA4"] = 32854] = "RGBA4";
	GLEnum$1[GLEnum$1["RGB5_A1"] = 32855] = "RGB5_A1";
	GLEnum$1[GLEnum$1["RGB565"] = 36194] = "RGB565";
	GLEnum$1[GLEnum$1["DEPTH_COMPONENT16"] = 33189] = "DEPTH_COMPONENT16";
	GLEnum$1[GLEnum$1["STENCIL_INDEX"] = 6401] = "STENCIL_INDEX";
	GLEnum$1[GLEnum$1["STENCIL_INDEX8"] = 36168] = "STENCIL_INDEX8";
	GLEnum$1[GLEnum$1["DEPTH_STENCIL"] = 34041] = "DEPTH_STENCIL";
	GLEnum$1[GLEnum$1["RENDERBUFFER_WIDTH"] = 36162] = "RENDERBUFFER_WIDTH";
	GLEnum$1[GLEnum$1["RENDERBUFFER_HEIGHT"] = 36163] = "RENDERBUFFER_HEIGHT";
	GLEnum$1[GLEnum$1["RENDERBUFFER_INTERNAL_FORMAT"] = 36164] = "RENDERBUFFER_INTERNAL_FORMAT";
	GLEnum$1[GLEnum$1["RENDERBUFFER_RED_SIZE"] = 36176] = "RENDERBUFFER_RED_SIZE";
	GLEnum$1[GLEnum$1["RENDERBUFFER_GREEN_SIZE"] = 36177] = "RENDERBUFFER_GREEN_SIZE";
	GLEnum$1[GLEnum$1["RENDERBUFFER_BLUE_SIZE"] = 36178] = "RENDERBUFFER_BLUE_SIZE";
	GLEnum$1[GLEnum$1["RENDERBUFFER_ALPHA_SIZE"] = 36179] = "RENDERBUFFER_ALPHA_SIZE";
	GLEnum$1[GLEnum$1["RENDERBUFFER_DEPTH_SIZE"] = 36180] = "RENDERBUFFER_DEPTH_SIZE";
	GLEnum$1[GLEnum$1["RENDERBUFFER_STENCIL_SIZE"] = 36181] = "RENDERBUFFER_STENCIL_SIZE";
	GLEnum$1[GLEnum$1["FRAMEBUFFER_ATTACHMENT_OBJECT_TYPE"] = 36048] = "FRAMEBUFFER_ATTACHMENT_OBJECT_TYPE";
	GLEnum$1[GLEnum$1["FRAMEBUFFER_ATTACHMENT_OBJECT_NAME"] = 36049] = "FRAMEBUFFER_ATTACHMENT_OBJECT_NAME";
	GLEnum$1[GLEnum$1["FRAMEBUFFER_ATTACHMENT_TEXTURE_LEVEL"] = 36050] = "FRAMEBUFFER_ATTACHMENT_TEXTURE_LEVEL";
	GLEnum$1[GLEnum$1["FRAMEBUFFER_ATTACHMENT_TEXTURE_CUBE_MAP_FACE"] = 36051] = "FRAMEBUFFER_ATTACHMENT_TEXTURE_CUBE_MAP_FACE";
	GLEnum$1[GLEnum$1["COLOR_ATTACHMENT0"] = 36064] = "COLOR_ATTACHMENT0";
	GLEnum$1[GLEnum$1["DEPTH_ATTACHMENT"] = 36096] = "DEPTH_ATTACHMENT";
	GLEnum$1[GLEnum$1["STENCIL_ATTACHMENT"] = 36128] = "STENCIL_ATTACHMENT";
	GLEnum$1[GLEnum$1["DEPTH_STENCIL_ATTACHMENT"] = 33306] = "DEPTH_STENCIL_ATTACHMENT";
	GLEnum$1[GLEnum$1["NONE"] = 0] = "NONE";
	GLEnum$1[GLEnum$1["FRAMEBUFFER_COMPLETE"] = 36053] = "FRAMEBUFFER_COMPLETE";
	GLEnum$1[GLEnum$1["FRAMEBUFFER_INCOMPLETE_ATTACHMENT"] = 36054] = "FRAMEBUFFER_INCOMPLETE_ATTACHMENT";
	GLEnum$1[GLEnum$1["FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT"] = 36055] = "FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT";
	GLEnum$1[GLEnum$1["FRAMEBUFFER_INCOMPLETE_DIMENSIONS"] = 36057] = "FRAMEBUFFER_INCOMPLETE_DIMENSIONS";
	GLEnum$1[GLEnum$1["FRAMEBUFFER_UNSUPPORTED"] = 36061] = "FRAMEBUFFER_UNSUPPORTED";
	GLEnum$1[GLEnum$1["FRAMEBUFFER_BINDING"] = 36006] = "FRAMEBUFFER_BINDING";
	GLEnum$1[GLEnum$1["RENDERBUFFER_BINDING"] = 36007] = "RENDERBUFFER_BINDING";
	GLEnum$1[GLEnum$1["READ_FRAMEBUFFER"] = 36008] = "READ_FRAMEBUFFER";
	GLEnum$1[GLEnum$1["DRAW_FRAMEBUFFER"] = 36009] = "DRAW_FRAMEBUFFER";
	GLEnum$1[GLEnum$1["MAX_RENDERBUFFER_SIZE"] = 34024] = "MAX_RENDERBUFFER_SIZE";
	GLEnum$1[GLEnum$1["INVALID_FRAMEBUFFER_OPERATION"] = 1286] = "INVALID_FRAMEBUFFER_OPERATION";
	GLEnum$1[GLEnum$1["UNPACK_FLIP_Y_WEBGL"] = 37440] = "UNPACK_FLIP_Y_WEBGL";
	GLEnum$1[GLEnum$1["UNPACK_PREMULTIPLY_ALPHA_WEBGL"] = 37441] = "UNPACK_PREMULTIPLY_ALPHA_WEBGL";
	GLEnum$1[GLEnum$1["UNPACK_COLORSPACE_CONVERSION_WEBGL"] = 37443] = "UNPACK_COLORSPACE_CONVERSION_WEBGL";
	GLEnum$1[GLEnum$1["READ_BUFFER"] = 3074] = "READ_BUFFER";
	GLEnum$1[GLEnum$1["UNPACK_ROW_LENGTH"] = 3314] = "UNPACK_ROW_LENGTH";
	GLEnum$1[GLEnum$1["UNPACK_SKIP_ROWS"] = 3315] = "UNPACK_SKIP_ROWS";
	GLEnum$1[GLEnum$1["UNPACK_SKIP_PIXELS"] = 3316] = "UNPACK_SKIP_PIXELS";
	GLEnum$1[GLEnum$1["PACK_ROW_LENGTH"] = 3330] = "PACK_ROW_LENGTH";
	GLEnum$1[GLEnum$1["PACK_SKIP_ROWS"] = 3331] = "PACK_SKIP_ROWS";
	GLEnum$1[GLEnum$1["PACK_SKIP_PIXELS"] = 3332] = "PACK_SKIP_PIXELS";
	GLEnum$1[GLEnum$1["TEXTURE_BINDING_3D"] = 32874] = "TEXTURE_BINDING_3D";
	GLEnum$1[GLEnum$1["UNPACK_SKIP_IMAGES"] = 32877] = "UNPACK_SKIP_IMAGES";
	GLEnum$1[GLEnum$1["UNPACK_IMAGE_HEIGHT"] = 32878] = "UNPACK_IMAGE_HEIGHT";
	GLEnum$1[GLEnum$1["MAX_3D_TEXTURE_SIZE"] = 32883] = "MAX_3D_TEXTURE_SIZE";
	GLEnum$1[GLEnum$1["MAX_ELEMENTS_VERTICES"] = 33e3] = "MAX_ELEMENTS_VERTICES";
	GLEnum$1[GLEnum$1["MAX_ELEMENTS_INDICES"] = 33001] = "MAX_ELEMENTS_INDICES";
	GLEnum$1[GLEnum$1["MAX_TEXTURE_LOD_BIAS"] = 34045] = "MAX_TEXTURE_LOD_BIAS";
	GLEnum$1[GLEnum$1["MAX_FRAGMENT_UNIFORM_COMPONENTS"] = 35657] = "MAX_FRAGMENT_UNIFORM_COMPONENTS";
	GLEnum$1[GLEnum$1["MAX_VERTEX_UNIFORM_COMPONENTS"] = 35658] = "MAX_VERTEX_UNIFORM_COMPONENTS";
	GLEnum$1[GLEnum$1["MAX_ARRAY_TEXTURE_LAYERS"] = 35071] = "MAX_ARRAY_TEXTURE_LAYERS";
	GLEnum$1[GLEnum$1["MIN_PROGRAM_TEXEL_OFFSET"] = 35076] = "MIN_PROGRAM_TEXEL_OFFSET";
	GLEnum$1[GLEnum$1["MAX_PROGRAM_TEXEL_OFFSET"] = 35077] = "MAX_PROGRAM_TEXEL_OFFSET";
	GLEnum$1[GLEnum$1["MAX_VARYING_COMPONENTS"] = 35659] = "MAX_VARYING_COMPONENTS";
	GLEnum$1[GLEnum$1["FRAGMENT_SHADER_DERIVATIVE_HINT"] = 35723] = "FRAGMENT_SHADER_DERIVATIVE_HINT";
	GLEnum$1[GLEnum$1["RASTERIZER_DISCARD"] = 35977] = "RASTERIZER_DISCARD";
	GLEnum$1[GLEnum$1["VERTEX_ARRAY_BINDING"] = 34229] = "VERTEX_ARRAY_BINDING";
	GLEnum$1[GLEnum$1["MAX_VERTEX_OUTPUT_COMPONENTS"] = 37154] = "MAX_VERTEX_OUTPUT_COMPONENTS";
	GLEnum$1[GLEnum$1["MAX_FRAGMENT_INPUT_COMPONENTS"] = 37157] = "MAX_FRAGMENT_INPUT_COMPONENTS";
	GLEnum$1[GLEnum$1["MAX_SERVER_WAIT_TIMEOUT"] = 37137] = "MAX_SERVER_WAIT_TIMEOUT";
	GLEnum$1[GLEnum$1["MAX_ELEMENT_INDEX"] = 36203] = "MAX_ELEMENT_INDEX";
	GLEnum$1[GLEnum$1["RED"] = 6403] = "RED";
	GLEnum$1[GLEnum$1["RGB8"] = 32849] = "RGB8";
	GLEnum$1[GLEnum$1["RGBA8"] = 32856] = "RGBA8";
	GLEnum$1[GLEnum$1["RGB10_A2"] = 32857] = "RGB10_A2";
	GLEnum$1[GLEnum$1["TEXTURE_3D"] = 32879] = "TEXTURE_3D";
	/** Sets the wrap parameter for texture coordinate  to either GL_CLAMP_TO_EDGE, GL_MIRRORED_REPEAT, or GL_REPEAT. G */
	GLEnum$1[GLEnum$1["TEXTURE_WRAP_R"] = 32882] = "TEXTURE_WRAP_R";
	GLEnum$1[GLEnum$1["TEXTURE_MIN_LOD"] = 33082] = "TEXTURE_MIN_LOD";
	GLEnum$1[GLEnum$1["TEXTURE_MAX_LOD"] = 33083] = "TEXTURE_MAX_LOD";
	GLEnum$1[GLEnum$1["TEXTURE_BASE_LEVEL"] = 33084] = "TEXTURE_BASE_LEVEL";
	GLEnum$1[GLEnum$1["TEXTURE_MAX_LEVEL"] = 33085] = "TEXTURE_MAX_LEVEL";
	GLEnum$1[GLEnum$1["TEXTURE_COMPARE_MODE"] = 34892] = "TEXTURE_COMPARE_MODE";
	GLEnum$1[GLEnum$1["TEXTURE_COMPARE_FUNC"] = 34893] = "TEXTURE_COMPARE_FUNC";
	GLEnum$1[GLEnum$1["SRGB"] = 35904] = "SRGB";
	GLEnum$1[GLEnum$1["SRGB8"] = 35905] = "SRGB8";
	GLEnum$1[GLEnum$1["SRGB8_ALPHA8"] = 35907] = "SRGB8_ALPHA8";
	GLEnum$1[GLEnum$1["COMPARE_REF_TO_TEXTURE"] = 34894] = "COMPARE_REF_TO_TEXTURE";
	GLEnum$1[GLEnum$1["RGBA32F"] = 34836] = "RGBA32F";
	GLEnum$1[GLEnum$1["RGB32F"] = 34837] = "RGB32F";
	GLEnum$1[GLEnum$1["RGBA16F"] = 34842] = "RGBA16F";
	GLEnum$1[GLEnum$1["RGB16F"] = 34843] = "RGB16F";
	GLEnum$1[GLEnum$1["TEXTURE_2D_ARRAY"] = 35866] = "TEXTURE_2D_ARRAY";
	GLEnum$1[GLEnum$1["TEXTURE_BINDING_2D_ARRAY"] = 35869] = "TEXTURE_BINDING_2D_ARRAY";
	GLEnum$1[GLEnum$1["R11F_G11F_B10F"] = 35898] = "R11F_G11F_B10F";
	GLEnum$1[GLEnum$1["RGB9_E5"] = 35901] = "RGB9_E5";
	GLEnum$1[GLEnum$1["RGBA32UI"] = 36208] = "RGBA32UI";
	GLEnum$1[GLEnum$1["RGB32UI"] = 36209] = "RGB32UI";
	GLEnum$1[GLEnum$1["RGBA16UI"] = 36214] = "RGBA16UI";
	GLEnum$1[GLEnum$1["RGB16UI"] = 36215] = "RGB16UI";
	GLEnum$1[GLEnum$1["RGBA8UI"] = 36220] = "RGBA8UI";
	GLEnum$1[GLEnum$1["RGB8UI"] = 36221] = "RGB8UI";
	GLEnum$1[GLEnum$1["RGBA32I"] = 36226] = "RGBA32I";
	GLEnum$1[GLEnum$1["RGB32I"] = 36227] = "RGB32I";
	GLEnum$1[GLEnum$1["RGBA16I"] = 36232] = "RGBA16I";
	GLEnum$1[GLEnum$1["RGB16I"] = 36233] = "RGB16I";
	GLEnum$1[GLEnum$1["RGBA8I"] = 36238] = "RGBA8I";
	GLEnum$1[GLEnum$1["RGB8I"] = 36239] = "RGB8I";
	GLEnum$1[GLEnum$1["RED_INTEGER"] = 36244] = "RED_INTEGER";
	GLEnum$1[GLEnum$1["RGB_INTEGER"] = 36248] = "RGB_INTEGER";
	GLEnum$1[GLEnum$1["RGBA_INTEGER"] = 36249] = "RGBA_INTEGER";
	GLEnum$1[GLEnum$1["R8"] = 33321] = "R8";
	GLEnum$1[GLEnum$1["RG8"] = 33323] = "RG8";
	GLEnum$1[GLEnum$1["R16F"] = 33325] = "R16F";
	GLEnum$1[GLEnum$1["R32F"] = 33326] = "R32F";
	GLEnum$1[GLEnum$1["RG16F"] = 33327] = "RG16F";
	GLEnum$1[GLEnum$1["RG32F"] = 33328] = "RG32F";
	GLEnum$1[GLEnum$1["R8I"] = 33329] = "R8I";
	GLEnum$1[GLEnum$1["R8UI"] = 33330] = "R8UI";
	GLEnum$1[GLEnum$1["R16I"] = 33331] = "R16I";
	GLEnum$1[GLEnum$1["R16UI"] = 33332] = "R16UI";
	GLEnum$1[GLEnum$1["R32I"] = 33333] = "R32I";
	GLEnum$1[GLEnum$1["R32UI"] = 33334] = "R32UI";
	GLEnum$1[GLEnum$1["RG8I"] = 33335] = "RG8I";
	GLEnum$1[GLEnum$1["RG8UI"] = 33336] = "RG8UI";
	GLEnum$1[GLEnum$1["RG16I"] = 33337] = "RG16I";
	GLEnum$1[GLEnum$1["RG16UI"] = 33338] = "RG16UI";
	GLEnum$1[GLEnum$1["RG32I"] = 33339] = "RG32I";
	GLEnum$1[GLEnum$1["RG32UI"] = 33340] = "RG32UI";
	GLEnum$1[GLEnum$1["R8_SNORM"] = 36756] = "R8_SNORM";
	GLEnum$1[GLEnum$1["RG8_SNORM"] = 36757] = "RG8_SNORM";
	GLEnum$1[GLEnum$1["RGB8_SNORM"] = 36758] = "RGB8_SNORM";
	GLEnum$1[GLEnum$1["RGBA8_SNORM"] = 36759] = "RGBA8_SNORM";
	GLEnum$1[GLEnum$1["RGB10_A2UI"] = 36975] = "RGB10_A2UI";
	GLEnum$1[GLEnum$1["TEXTURE_IMMUTABLE_FORMAT"] = 37167] = "TEXTURE_IMMUTABLE_FORMAT";
	GLEnum$1[GLEnum$1["TEXTURE_IMMUTABLE_LEVELS"] = 33503] = "TEXTURE_IMMUTABLE_LEVELS";
	GLEnum$1[GLEnum$1["UNSIGNED_INT_2_10_10_10_REV"] = 33640] = "UNSIGNED_INT_2_10_10_10_REV";
	GLEnum$1[GLEnum$1["UNSIGNED_INT_10F_11F_11F_REV"] = 35899] = "UNSIGNED_INT_10F_11F_11F_REV";
	GLEnum$1[GLEnum$1["UNSIGNED_INT_5_9_9_9_REV"] = 35902] = "UNSIGNED_INT_5_9_9_9_REV";
	GLEnum$1[GLEnum$1["FLOAT_32_UNSIGNED_INT_24_8_REV"] = 36269] = "FLOAT_32_UNSIGNED_INT_24_8_REV";
	GLEnum$1[GLEnum$1["UNSIGNED_INT_24_8"] = 34042] = "UNSIGNED_INT_24_8";
	GLEnum$1[GLEnum$1["HALF_FLOAT"] = 5131] = "HALF_FLOAT";
	GLEnum$1[GLEnum$1["RG"] = 33319] = "RG";
	GLEnum$1[GLEnum$1["RG_INTEGER"] = 33320] = "RG_INTEGER";
	GLEnum$1[GLEnum$1["INT_2_10_10_10_REV"] = 36255] = "INT_2_10_10_10_REV";
	GLEnum$1[GLEnum$1["CURRENT_QUERY"] = 34917] = "CURRENT_QUERY";
	/** Returns a GLuint containing the query result. */
	GLEnum$1[GLEnum$1["QUERY_RESULT"] = 34918] = "QUERY_RESULT";
	/** Whether query result is available. */
	GLEnum$1[GLEnum$1["QUERY_RESULT_AVAILABLE"] = 34919] = "QUERY_RESULT_AVAILABLE";
	/** Occlusion query (if drawing passed depth test)  */
	GLEnum$1[GLEnum$1["ANY_SAMPLES_PASSED"] = 35887] = "ANY_SAMPLES_PASSED";
	/** Occlusion query less accurate/faster version */
	GLEnum$1[GLEnum$1["ANY_SAMPLES_PASSED_CONSERVATIVE"] = 36202] = "ANY_SAMPLES_PASSED_CONSERVATIVE";
	GLEnum$1[GLEnum$1["MAX_DRAW_BUFFERS"] = 34852] = "MAX_DRAW_BUFFERS";
	GLEnum$1[GLEnum$1["DRAW_BUFFER0"] = 34853] = "DRAW_BUFFER0";
	GLEnum$1[GLEnum$1["DRAW_BUFFER1"] = 34854] = "DRAW_BUFFER1";
	GLEnum$1[GLEnum$1["DRAW_BUFFER2"] = 34855] = "DRAW_BUFFER2";
	GLEnum$1[GLEnum$1["DRAW_BUFFER3"] = 34856] = "DRAW_BUFFER3";
	GLEnum$1[GLEnum$1["DRAW_BUFFER4"] = 34857] = "DRAW_BUFFER4";
	GLEnum$1[GLEnum$1["DRAW_BUFFER5"] = 34858] = "DRAW_BUFFER5";
	GLEnum$1[GLEnum$1["DRAW_BUFFER6"] = 34859] = "DRAW_BUFFER6";
	GLEnum$1[GLEnum$1["DRAW_BUFFER7"] = 34860] = "DRAW_BUFFER7";
	GLEnum$1[GLEnum$1["DRAW_BUFFER8"] = 34861] = "DRAW_BUFFER8";
	GLEnum$1[GLEnum$1["DRAW_BUFFER9"] = 34862] = "DRAW_BUFFER9";
	GLEnum$1[GLEnum$1["DRAW_BUFFER10"] = 34863] = "DRAW_BUFFER10";
	GLEnum$1[GLEnum$1["DRAW_BUFFER11"] = 34864] = "DRAW_BUFFER11";
	GLEnum$1[GLEnum$1["DRAW_BUFFER12"] = 34865] = "DRAW_BUFFER12";
	GLEnum$1[GLEnum$1["DRAW_BUFFER13"] = 34866] = "DRAW_BUFFER13";
	GLEnum$1[GLEnum$1["DRAW_BUFFER14"] = 34867] = "DRAW_BUFFER14";
	GLEnum$1[GLEnum$1["DRAW_BUFFER15"] = 34868] = "DRAW_BUFFER15";
	GLEnum$1[GLEnum$1["MAX_COLOR_ATTACHMENTS"] = 36063] = "MAX_COLOR_ATTACHMENTS";
	GLEnum$1[GLEnum$1["COLOR_ATTACHMENT1"] = 36065] = "COLOR_ATTACHMENT1";
	GLEnum$1[GLEnum$1["COLOR_ATTACHMENT2"] = 36066] = "COLOR_ATTACHMENT2";
	GLEnum$1[GLEnum$1["COLOR_ATTACHMENT3"] = 36067] = "COLOR_ATTACHMENT3";
	GLEnum$1[GLEnum$1["COLOR_ATTACHMENT4"] = 36068] = "COLOR_ATTACHMENT4";
	GLEnum$1[GLEnum$1["COLOR_ATTACHMENT5"] = 36069] = "COLOR_ATTACHMENT5";
	GLEnum$1[GLEnum$1["COLOR_ATTACHMENT6"] = 36070] = "COLOR_ATTACHMENT6";
	GLEnum$1[GLEnum$1["COLOR_ATTACHMENT7"] = 36071] = "COLOR_ATTACHMENT7";
	GLEnum$1[GLEnum$1["COLOR_ATTACHMENT8"] = 36072] = "COLOR_ATTACHMENT8";
	GLEnum$1[GLEnum$1["COLOR_ATTACHMENT9"] = 36073] = "COLOR_ATTACHMENT9";
	GLEnum$1[GLEnum$1["COLOR_ATTACHMENT10"] = 36074] = "COLOR_ATTACHMENT10";
	GLEnum$1[GLEnum$1["COLOR_ATTACHMENT11"] = 36075] = "COLOR_ATTACHMENT11";
	GLEnum$1[GLEnum$1["COLOR_ATTACHMENT12"] = 36076] = "COLOR_ATTACHMENT12";
	GLEnum$1[GLEnum$1["COLOR_ATTACHMENT13"] = 36077] = "COLOR_ATTACHMENT13";
	GLEnum$1[GLEnum$1["COLOR_ATTACHMENT14"] = 36078] = "COLOR_ATTACHMENT14";
	GLEnum$1[GLEnum$1["COLOR_ATTACHMENT15"] = 36079] = "COLOR_ATTACHMENT15";
	GLEnum$1[GLEnum$1["SAMPLER_3D"] = 35679] = "SAMPLER_3D";
	GLEnum$1[GLEnum$1["SAMPLER_2D_SHADOW"] = 35682] = "SAMPLER_2D_SHADOW";
	GLEnum$1[GLEnum$1["SAMPLER_2D_ARRAY"] = 36289] = "SAMPLER_2D_ARRAY";
	GLEnum$1[GLEnum$1["SAMPLER_2D_ARRAY_SHADOW"] = 36292] = "SAMPLER_2D_ARRAY_SHADOW";
	GLEnum$1[GLEnum$1["SAMPLER_CUBE_SHADOW"] = 36293] = "SAMPLER_CUBE_SHADOW";
	GLEnum$1[GLEnum$1["INT_SAMPLER_2D"] = 36298] = "INT_SAMPLER_2D";
	GLEnum$1[GLEnum$1["INT_SAMPLER_3D"] = 36299] = "INT_SAMPLER_3D";
	GLEnum$1[GLEnum$1["INT_SAMPLER_CUBE"] = 36300] = "INT_SAMPLER_CUBE";
	GLEnum$1[GLEnum$1["INT_SAMPLER_2D_ARRAY"] = 36303] = "INT_SAMPLER_2D_ARRAY";
	GLEnum$1[GLEnum$1["UNSIGNED_INT_SAMPLER_2D"] = 36306] = "UNSIGNED_INT_SAMPLER_2D";
	GLEnum$1[GLEnum$1["UNSIGNED_INT_SAMPLER_3D"] = 36307] = "UNSIGNED_INT_SAMPLER_3D";
	GLEnum$1[GLEnum$1["UNSIGNED_INT_SAMPLER_CUBE"] = 36308] = "UNSIGNED_INT_SAMPLER_CUBE";
	GLEnum$1[GLEnum$1["UNSIGNED_INT_SAMPLER_2D_ARRAY"] = 36311] = "UNSIGNED_INT_SAMPLER_2D_ARRAY";
	GLEnum$1[GLEnum$1["MAX_SAMPLES"] = 36183] = "MAX_SAMPLES";
	GLEnum$1[GLEnum$1["SAMPLER_BINDING"] = 35097] = "SAMPLER_BINDING";
	GLEnum$1[GLEnum$1["PIXEL_PACK_BUFFER"] = 35051] = "PIXEL_PACK_BUFFER";
	GLEnum$1[GLEnum$1["PIXEL_UNPACK_BUFFER"] = 35052] = "PIXEL_UNPACK_BUFFER";
	GLEnum$1[GLEnum$1["PIXEL_PACK_BUFFER_BINDING"] = 35053] = "PIXEL_PACK_BUFFER_BINDING";
	GLEnum$1[GLEnum$1["PIXEL_UNPACK_BUFFER_BINDING"] = 35055] = "PIXEL_UNPACK_BUFFER_BINDING";
	GLEnum$1[GLEnum$1["COPY_READ_BUFFER"] = 36662] = "COPY_READ_BUFFER";
	GLEnum$1[GLEnum$1["COPY_WRITE_BUFFER"] = 36663] = "COPY_WRITE_BUFFER";
	GLEnum$1[GLEnum$1["COPY_READ_BUFFER_BINDING"] = 36662] = "COPY_READ_BUFFER_BINDING";
	GLEnum$1[GLEnum$1["COPY_WRITE_BUFFER_BINDING"] = 36663] = "COPY_WRITE_BUFFER_BINDING";
	GLEnum$1[GLEnum$1["FLOAT_MAT2x3"] = 35685] = "FLOAT_MAT2x3";
	GLEnum$1[GLEnum$1["FLOAT_MAT2x4"] = 35686] = "FLOAT_MAT2x4";
	GLEnum$1[GLEnum$1["FLOAT_MAT3x2"] = 35687] = "FLOAT_MAT3x2";
	GLEnum$1[GLEnum$1["FLOAT_MAT3x4"] = 35688] = "FLOAT_MAT3x4";
	GLEnum$1[GLEnum$1["FLOAT_MAT4x2"] = 35689] = "FLOAT_MAT4x2";
	GLEnum$1[GLEnum$1["FLOAT_MAT4x3"] = 35690] = "FLOAT_MAT4x3";
	GLEnum$1[GLEnum$1["UNSIGNED_INT_VEC2"] = 36294] = "UNSIGNED_INT_VEC2";
	GLEnum$1[GLEnum$1["UNSIGNED_INT_VEC3"] = 36295] = "UNSIGNED_INT_VEC3";
	GLEnum$1[GLEnum$1["UNSIGNED_INT_VEC4"] = 36296] = "UNSIGNED_INT_VEC4";
	GLEnum$1[GLEnum$1["UNSIGNED_NORMALIZED"] = 35863] = "UNSIGNED_NORMALIZED";
	GLEnum$1[GLEnum$1["SIGNED_NORMALIZED"] = 36764] = "SIGNED_NORMALIZED";
	GLEnum$1[GLEnum$1["VERTEX_ATTRIB_ARRAY_INTEGER"] = 35069] = "VERTEX_ATTRIB_ARRAY_INTEGER";
	GLEnum$1[GLEnum$1["VERTEX_ATTRIB_ARRAY_DIVISOR"] = 35070] = "VERTEX_ATTRIB_ARRAY_DIVISOR";
	GLEnum$1[GLEnum$1["TRANSFORM_FEEDBACK_BUFFER_MODE"] = 35967] = "TRANSFORM_FEEDBACK_BUFFER_MODE";
	GLEnum$1[GLEnum$1["MAX_TRANSFORM_FEEDBACK_SEPARATE_COMPONENTS"] = 35968] = "MAX_TRANSFORM_FEEDBACK_SEPARATE_COMPONENTS";
	GLEnum$1[GLEnum$1["TRANSFORM_FEEDBACK_VARYINGS"] = 35971] = "TRANSFORM_FEEDBACK_VARYINGS";
	GLEnum$1[GLEnum$1["TRANSFORM_FEEDBACK_BUFFER_START"] = 35972] = "TRANSFORM_FEEDBACK_BUFFER_START";
	GLEnum$1[GLEnum$1["TRANSFORM_FEEDBACK_BUFFER_SIZE"] = 35973] = "TRANSFORM_FEEDBACK_BUFFER_SIZE";
	GLEnum$1[GLEnum$1["TRANSFORM_FEEDBACK_PRIMITIVES_WRITTEN"] = 35976] = "TRANSFORM_FEEDBACK_PRIMITIVES_WRITTEN";
	GLEnum$1[GLEnum$1["MAX_TRANSFORM_FEEDBACK_INTERLEAVED_COMPONENTS"] = 35978] = "MAX_TRANSFORM_FEEDBACK_INTERLEAVED_COMPONENTS";
	GLEnum$1[GLEnum$1["MAX_TRANSFORM_FEEDBACK_SEPARATE_ATTRIBS"] = 35979] = "MAX_TRANSFORM_FEEDBACK_SEPARATE_ATTRIBS";
	GLEnum$1[GLEnum$1["INTERLEAVED_ATTRIBS"] = 35980] = "INTERLEAVED_ATTRIBS";
	GLEnum$1[GLEnum$1["SEPARATE_ATTRIBS"] = 35981] = "SEPARATE_ATTRIBS";
	GLEnum$1[GLEnum$1["TRANSFORM_FEEDBACK_BUFFER"] = 35982] = "TRANSFORM_FEEDBACK_BUFFER";
	GLEnum$1[GLEnum$1["TRANSFORM_FEEDBACK_BUFFER_BINDING"] = 35983] = "TRANSFORM_FEEDBACK_BUFFER_BINDING";
	GLEnum$1[GLEnum$1["TRANSFORM_FEEDBACK"] = 36386] = "TRANSFORM_FEEDBACK";
	GLEnum$1[GLEnum$1["TRANSFORM_FEEDBACK_PAUSED"] = 36387] = "TRANSFORM_FEEDBACK_PAUSED";
	GLEnum$1[GLEnum$1["TRANSFORM_FEEDBACK_ACTIVE"] = 36388] = "TRANSFORM_FEEDBACK_ACTIVE";
	GLEnum$1[GLEnum$1["TRANSFORM_FEEDBACK_BINDING"] = 36389] = "TRANSFORM_FEEDBACK_BINDING";
	GLEnum$1[GLEnum$1["FRAMEBUFFER_ATTACHMENT_COLOR_ENCODING"] = 33296] = "FRAMEBUFFER_ATTACHMENT_COLOR_ENCODING";
	GLEnum$1[GLEnum$1["FRAMEBUFFER_ATTACHMENT_COMPONENT_TYPE"] = 33297] = "FRAMEBUFFER_ATTACHMENT_COMPONENT_TYPE";
	GLEnum$1[GLEnum$1["FRAMEBUFFER_ATTACHMENT_RED_SIZE"] = 33298] = "FRAMEBUFFER_ATTACHMENT_RED_SIZE";
	GLEnum$1[GLEnum$1["FRAMEBUFFER_ATTACHMENT_GREEN_SIZE"] = 33299] = "FRAMEBUFFER_ATTACHMENT_GREEN_SIZE";
	GLEnum$1[GLEnum$1["FRAMEBUFFER_ATTACHMENT_BLUE_SIZE"] = 33300] = "FRAMEBUFFER_ATTACHMENT_BLUE_SIZE";
	GLEnum$1[GLEnum$1["FRAMEBUFFER_ATTACHMENT_ALPHA_SIZE"] = 33301] = "FRAMEBUFFER_ATTACHMENT_ALPHA_SIZE";
	GLEnum$1[GLEnum$1["FRAMEBUFFER_ATTACHMENT_DEPTH_SIZE"] = 33302] = "FRAMEBUFFER_ATTACHMENT_DEPTH_SIZE";
	GLEnum$1[GLEnum$1["FRAMEBUFFER_ATTACHMENT_STENCIL_SIZE"] = 33303] = "FRAMEBUFFER_ATTACHMENT_STENCIL_SIZE";
	GLEnum$1[GLEnum$1["FRAMEBUFFER_DEFAULT"] = 33304] = "FRAMEBUFFER_DEFAULT";
	GLEnum$1[GLEnum$1["DEPTH24_STENCIL8"] = 35056] = "DEPTH24_STENCIL8";
	GLEnum$1[GLEnum$1["DRAW_FRAMEBUFFER_BINDING"] = 36006] = "DRAW_FRAMEBUFFER_BINDING";
	GLEnum$1[GLEnum$1["READ_FRAMEBUFFER_BINDING"] = 36010] = "READ_FRAMEBUFFER_BINDING";
	GLEnum$1[GLEnum$1["RENDERBUFFER_SAMPLES"] = 36011] = "RENDERBUFFER_SAMPLES";
	GLEnum$1[GLEnum$1["FRAMEBUFFER_ATTACHMENT_TEXTURE_LAYER"] = 36052] = "FRAMEBUFFER_ATTACHMENT_TEXTURE_LAYER";
	GLEnum$1[GLEnum$1["FRAMEBUFFER_INCOMPLETE_MULTISAMPLE"] = 36182] = "FRAMEBUFFER_INCOMPLETE_MULTISAMPLE";
	GLEnum$1[GLEnum$1["UNIFORM_BUFFER"] = 35345] = "UNIFORM_BUFFER";
	GLEnum$1[GLEnum$1["UNIFORM_BUFFER_BINDING"] = 35368] = "UNIFORM_BUFFER_BINDING";
	GLEnum$1[GLEnum$1["UNIFORM_BUFFER_START"] = 35369] = "UNIFORM_BUFFER_START";
	GLEnum$1[GLEnum$1["UNIFORM_BUFFER_SIZE"] = 35370] = "UNIFORM_BUFFER_SIZE";
	GLEnum$1[GLEnum$1["MAX_VERTEX_UNIFORM_BLOCKS"] = 35371] = "MAX_VERTEX_UNIFORM_BLOCKS";
	GLEnum$1[GLEnum$1["MAX_FRAGMENT_UNIFORM_BLOCKS"] = 35373] = "MAX_FRAGMENT_UNIFORM_BLOCKS";
	GLEnum$1[GLEnum$1["MAX_COMBINED_UNIFORM_BLOCKS"] = 35374] = "MAX_COMBINED_UNIFORM_BLOCKS";
	GLEnum$1[GLEnum$1["MAX_UNIFORM_BUFFER_BINDINGS"] = 35375] = "MAX_UNIFORM_BUFFER_BINDINGS";
	GLEnum$1[GLEnum$1["MAX_UNIFORM_BLOCK_SIZE"] = 35376] = "MAX_UNIFORM_BLOCK_SIZE";
	GLEnum$1[GLEnum$1["MAX_COMBINED_VERTEX_UNIFORM_COMPONENTS"] = 35377] = "MAX_COMBINED_VERTEX_UNIFORM_COMPONENTS";
	GLEnum$1[GLEnum$1["MAX_COMBINED_FRAGMENT_UNIFORM_COMPONENTS"] = 35379] = "MAX_COMBINED_FRAGMENT_UNIFORM_COMPONENTS";
	GLEnum$1[GLEnum$1["UNIFORM_BUFFER_OFFSET_ALIGNMENT"] = 35380] = "UNIFORM_BUFFER_OFFSET_ALIGNMENT";
	GLEnum$1[GLEnum$1["ACTIVE_UNIFORM_BLOCKS"] = 35382] = "ACTIVE_UNIFORM_BLOCKS";
	GLEnum$1[GLEnum$1["UNIFORM_TYPE"] = 35383] = "UNIFORM_TYPE";
	GLEnum$1[GLEnum$1["UNIFORM_SIZE"] = 35384] = "UNIFORM_SIZE";
	GLEnum$1[GLEnum$1["UNIFORM_BLOCK_INDEX"] = 35386] = "UNIFORM_BLOCK_INDEX";
	GLEnum$1[GLEnum$1["UNIFORM_OFFSET"] = 35387] = "UNIFORM_OFFSET";
	GLEnum$1[GLEnum$1["UNIFORM_ARRAY_STRIDE"] = 35388] = "UNIFORM_ARRAY_STRIDE";
	GLEnum$1[GLEnum$1["UNIFORM_MATRIX_STRIDE"] = 35389] = "UNIFORM_MATRIX_STRIDE";
	GLEnum$1[GLEnum$1["UNIFORM_IS_ROW_MAJOR"] = 35390] = "UNIFORM_IS_ROW_MAJOR";
	GLEnum$1[GLEnum$1["UNIFORM_BLOCK_BINDING"] = 35391] = "UNIFORM_BLOCK_BINDING";
	GLEnum$1[GLEnum$1["UNIFORM_BLOCK_DATA_SIZE"] = 35392] = "UNIFORM_BLOCK_DATA_SIZE";
	GLEnum$1[GLEnum$1["UNIFORM_BLOCK_ACTIVE_UNIFORMS"] = 35394] = "UNIFORM_BLOCK_ACTIVE_UNIFORMS";
	GLEnum$1[GLEnum$1["UNIFORM_BLOCK_ACTIVE_UNIFORM_INDICES"] = 35395] = "UNIFORM_BLOCK_ACTIVE_UNIFORM_INDICES";
	GLEnum$1[GLEnum$1["UNIFORM_BLOCK_REFERENCED_BY_VERTEX_SHADER"] = 35396] = "UNIFORM_BLOCK_REFERENCED_BY_VERTEX_SHADER";
	GLEnum$1[GLEnum$1["UNIFORM_BLOCK_REFERENCED_BY_FRAGMENT_SHADER"] = 35398] = "UNIFORM_BLOCK_REFERENCED_BY_FRAGMENT_SHADER";
	GLEnum$1[GLEnum$1["OBJECT_TYPE"] = 37138] = "OBJECT_TYPE";
	GLEnum$1[GLEnum$1["SYNC_CONDITION"] = 37139] = "SYNC_CONDITION";
	GLEnum$1[GLEnum$1["SYNC_STATUS"] = 37140] = "SYNC_STATUS";
	GLEnum$1[GLEnum$1["SYNC_FLAGS"] = 37141] = "SYNC_FLAGS";
	GLEnum$1[GLEnum$1["SYNC_FENCE"] = 37142] = "SYNC_FENCE";
	GLEnum$1[GLEnum$1["SYNC_GPU_COMMANDS_COMPLETE"] = 37143] = "SYNC_GPU_COMMANDS_COMPLETE";
	GLEnum$1[GLEnum$1["UNSIGNALED"] = 37144] = "UNSIGNALED";
	GLEnum$1[GLEnum$1["SIGNALED"] = 37145] = "SIGNALED";
	GLEnum$1[GLEnum$1["ALREADY_SIGNALED"] = 37146] = "ALREADY_SIGNALED";
	GLEnum$1[GLEnum$1["TIMEOUT_EXPIRED"] = 37147] = "TIMEOUT_EXPIRED";
	GLEnum$1[GLEnum$1["CONDITION_SATISFIED"] = 37148] = "CONDITION_SATISFIED";
	GLEnum$1[GLEnum$1["WAIT_FAILED"] = 37149] = "WAIT_FAILED";
	GLEnum$1[GLEnum$1["SYNC_FLUSH_COMMANDS_BIT"] = 1] = "SYNC_FLUSH_COMMANDS_BIT";
	GLEnum$1[GLEnum$1["COLOR"] = 6144] = "COLOR";
	GLEnum$1[GLEnum$1["DEPTH"] = 6145] = "DEPTH";
	GLEnum$1[GLEnum$1["STENCIL"] = 6146] = "STENCIL";
	GLEnum$1[GLEnum$1["MIN"] = 32775] = "MIN";
	GLEnum$1[GLEnum$1["MAX"] = 32776] = "MAX";
	GLEnum$1[GLEnum$1["DEPTH_COMPONENT24"] = 33190] = "DEPTH_COMPONENT24";
	GLEnum$1[GLEnum$1["STREAM_READ"] = 35041] = "STREAM_READ";
	GLEnum$1[GLEnum$1["STREAM_COPY"] = 35042] = "STREAM_COPY";
	GLEnum$1[GLEnum$1["STATIC_READ"] = 35045] = "STATIC_READ";
	GLEnum$1[GLEnum$1["STATIC_COPY"] = 35046] = "STATIC_COPY";
	GLEnum$1[GLEnum$1["DYNAMIC_READ"] = 35049] = "DYNAMIC_READ";
	GLEnum$1[GLEnum$1["DYNAMIC_COPY"] = 35050] = "DYNAMIC_COPY";
	GLEnum$1[GLEnum$1["DEPTH_COMPONENT32F"] = 36012] = "DEPTH_COMPONENT32F";
	GLEnum$1[GLEnum$1["DEPTH32F_STENCIL8"] = 36013] = "DEPTH32F_STENCIL8";
	GLEnum$1[GLEnum$1["INVALID_INDEX"] = 4294967295] = "INVALID_INDEX";
	GLEnum$1[GLEnum$1["TIMEOUT_IGNORED"] = -1] = "TIMEOUT_IGNORED";
	GLEnum$1[GLEnum$1["MAX_CLIENT_WAIT_TIMEOUT_WEBGL"] = 37447] = "MAX_CLIENT_WAIT_TIMEOUT_WEBGL";
	/** Passed to getParameter to get the vendor string of the graphics driver. */
	GLEnum$1[GLEnum$1["UNMASKED_VENDOR_WEBGL"] = 37445] = "UNMASKED_VENDOR_WEBGL";
	/** Passed to getParameter to get the renderer string of the graphics driver. */
	GLEnum$1[GLEnum$1["UNMASKED_RENDERER_WEBGL"] = 37446] = "UNMASKED_RENDERER_WEBGL";
	/** Returns the maximum available anisotropy. */
	GLEnum$1[GLEnum$1["MAX_TEXTURE_MAX_ANISOTROPY_EXT"] = 34047] = "MAX_TEXTURE_MAX_ANISOTROPY_EXT";
	/** Passed to texParameter to set the desired maximum anisotropy for a texture. */
	GLEnum$1[GLEnum$1["TEXTURE_MAX_ANISOTROPY_EXT"] = 34046] = "TEXTURE_MAX_ANISOTROPY_EXT";
	GLEnum$1[GLEnum$1["R16_EXT"] = 33322] = "R16_EXT";
	GLEnum$1[GLEnum$1["RG16_EXT"] = 33324] = "RG16_EXT";
	GLEnum$1[GLEnum$1["RGB16_EXT"] = 32852] = "RGB16_EXT";
	GLEnum$1[GLEnum$1["RGBA16_EXT"] = 32859] = "RGBA16_EXT";
	GLEnum$1[GLEnum$1["R16_SNORM_EXT"] = 36760] = "R16_SNORM_EXT";
	GLEnum$1[GLEnum$1["RG16_SNORM_EXT"] = 36761] = "RG16_SNORM_EXT";
	GLEnum$1[GLEnum$1["RGB16_SNORM_EXT"] = 36762] = "RGB16_SNORM_EXT";
	GLEnum$1[GLEnum$1["RGBA16_SNORM_EXT"] = 36763] = "RGBA16_SNORM_EXT";
	/** A DXT1-compressed image in an RGB image format. */
	GLEnum$1[GLEnum$1["COMPRESSED_RGB_S3TC_DXT1_EXT"] = 33776] = "COMPRESSED_RGB_S3TC_DXT1_EXT";
	/** A DXT1-compressed image in an RGB image format with a simple on/off alpha value. */
	GLEnum$1[GLEnum$1["COMPRESSED_RGBA_S3TC_DXT1_EXT"] = 33777] = "COMPRESSED_RGBA_S3TC_DXT1_EXT";
	/** A DXT3-compressed image in an RGBA image format. Compared to a 32-bit RGBA texture, it offers 4:1 compression. */
	GLEnum$1[GLEnum$1["COMPRESSED_RGBA_S3TC_DXT3_EXT"] = 33778] = "COMPRESSED_RGBA_S3TC_DXT3_EXT";
	/** A DXT5-compressed image in an RGBA image format. It also provides a 4:1 compression, but differs to the DXT3 compression in how the alpha compression is done. */
	GLEnum$1[GLEnum$1["COMPRESSED_RGBA_S3TC_DXT5_EXT"] = 33779] = "COMPRESSED_RGBA_S3TC_DXT5_EXT";
	GLEnum$1[GLEnum$1["COMPRESSED_SRGB_S3TC_DXT1_EXT"] = 35916] = "COMPRESSED_SRGB_S3TC_DXT1_EXT";
	GLEnum$1[GLEnum$1["COMPRESSED_SRGB_ALPHA_S3TC_DXT1_EXT"] = 35917] = "COMPRESSED_SRGB_ALPHA_S3TC_DXT1_EXT";
	GLEnum$1[GLEnum$1["COMPRESSED_SRGB_ALPHA_S3TC_DXT3_EXT"] = 35918] = "COMPRESSED_SRGB_ALPHA_S3TC_DXT3_EXT";
	GLEnum$1[GLEnum$1["COMPRESSED_SRGB_ALPHA_S3TC_DXT5_EXT"] = 35919] = "COMPRESSED_SRGB_ALPHA_S3TC_DXT5_EXT";
	GLEnum$1[GLEnum$1["COMPRESSED_RED_RGTC1_EXT"] = 36283] = "COMPRESSED_RED_RGTC1_EXT";
	GLEnum$1[GLEnum$1["COMPRESSED_SIGNED_RED_RGTC1_EXT"] = 36284] = "COMPRESSED_SIGNED_RED_RGTC1_EXT";
	GLEnum$1[GLEnum$1["COMPRESSED_RED_GREEN_RGTC2_EXT"] = 36285] = "COMPRESSED_RED_GREEN_RGTC2_EXT";
	GLEnum$1[GLEnum$1["COMPRESSED_SIGNED_RED_GREEN_RGTC2_EXT"] = 36286] = "COMPRESSED_SIGNED_RED_GREEN_RGTC2_EXT";
	GLEnum$1[GLEnum$1["COMPRESSED_RGBA_BPTC_UNORM_EXT"] = 36492] = "COMPRESSED_RGBA_BPTC_UNORM_EXT";
	GLEnum$1[GLEnum$1["COMPRESSED_SRGB_ALPHA_BPTC_UNORM_EXT"] = 36493] = "COMPRESSED_SRGB_ALPHA_BPTC_UNORM_EXT";
	GLEnum$1[GLEnum$1["COMPRESSED_RGB_BPTC_SIGNED_FLOAT_EXT"] = 36494] = "COMPRESSED_RGB_BPTC_SIGNED_FLOAT_EXT";
	GLEnum$1[GLEnum$1["COMPRESSED_RGB_BPTC_UNSIGNED_FLOAT_EXT"] = 36495] = "COMPRESSED_RGB_BPTC_UNSIGNED_FLOAT_EXT";
	/** One-channel (red) unsigned format compression. */
	GLEnum$1[GLEnum$1["COMPRESSED_R11_EAC"] = 37488] = "COMPRESSED_R11_EAC";
	/** One-channel (red) signed format compression. */
	GLEnum$1[GLEnum$1["COMPRESSED_SIGNED_R11_EAC"] = 37489] = "COMPRESSED_SIGNED_R11_EAC";
	/** Two-channel (red and green) unsigned format compression. */
	GLEnum$1[GLEnum$1["COMPRESSED_RG11_EAC"] = 37490] = "COMPRESSED_RG11_EAC";
	/** Two-channel (red and green) signed format compression. */
	GLEnum$1[GLEnum$1["COMPRESSED_SIGNED_RG11_EAC"] = 37491] = "COMPRESSED_SIGNED_RG11_EAC";
	/** Compresses RGB8 data with no alpha channel. */
	GLEnum$1[GLEnum$1["COMPRESSED_RGB8_ETC2"] = 37492] = "COMPRESSED_RGB8_ETC2";
	/** Compresses RGBA8 data. The RGB part is encoded the same as RGB_ETC2, but the alpha part is encoded separately. */
	GLEnum$1[GLEnum$1["COMPRESSED_RGBA8_ETC2_EAC"] = 37493] = "COMPRESSED_RGBA8_ETC2_EAC";
	/** Compresses sRGB8 data with no alpha channel. */
	GLEnum$1[GLEnum$1["COMPRESSED_SRGB8_ETC2"] = 37494] = "COMPRESSED_SRGB8_ETC2";
	/** Compresses sRGBA8 data. The sRGB part is encoded the same as SRGB_ETC2, but the alpha part is encoded separately. */
	GLEnum$1[GLEnum$1["COMPRESSED_SRGB8_ALPHA8_ETC2_EAC"] = 37495] = "COMPRESSED_SRGB8_ALPHA8_ETC2_EAC";
	/** Similar to RGB8_ETC, but with ability to punch through the alpha channel, which means to make it completely opaque or transparent. */
	GLEnum$1[GLEnum$1["COMPRESSED_RGB8_PUNCHTHROUGH_ALPHA1_ETC2"] = 37496] = "COMPRESSED_RGB8_PUNCHTHROUGH_ALPHA1_ETC2";
	/** Similar to SRGB8_ETC, but with ability to punch through the alpha channel, which means to make it completely opaque or transparent. */
	GLEnum$1[GLEnum$1["COMPRESSED_SRGB8_PUNCHTHROUGH_ALPHA1_ETC2"] = 37497] = "COMPRESSED_SRGB8_PUNCHTHROUGH_ALPHA1_ETC2";
	/** RGB compression in 4-bit mode. One block for each 44 pixels. */
	GLEnum$1[GLEnum$1["COMPRESSED_RGB_PVRTC_4BPPV1_IMG"] = 35840] = "COMPRESSED_RGB_PVRTC_4BPPV1_IMG";
	/** RGBA compression in 4-bit mode. One block for each 44 pixels. */
	GLEnum$1[GLEnum$1["COMPRESSED_RGBA_PVRTC_4BPPV1_IMG"] = 35842] = "COMPRESSED_RGBA_PVRTC_4BPPV1_IMG";
	/** RGB compression in 2-bit mode. One block for each 84 pixels. */
	GLEnum$1[GLEnum$1["COMPRESSED_RGB_PVRTC_2BPPV1_IMG"] = 35841] = "COMPRESSED_RGB_PVRTC_2BPPV1_IMG";
	/** RGBA compression in 2-bit mode. One block for each 84 pixels. */
	GLEnum$1[GLEnum$1["COMPRESSED_RGBA_PVRTC_2BPPV1_IMG"] = 35843] = "COMPRESSED_RGBA_PVRTC_2BPPV1_IMG";
	/** Compresses 24-bit RGB data with no alpha channel. */
	GLEnum$1[GLEnum$1["COMPRESSED_RGB_ETC1_WEBGL"] = 36196] = "COMPRESSED_RGB_ETC1_WEBGL";
	GLEnum$1[GLEnum$1["COMPRESSED_RGB_ATC_WEBGL"] = 35986] = "COMPRESSED_RGB_ATC_WEBGL";
	GLEnum$1[GLEnum$1["COMPRESSED_RGBA_ATC_EXPLICIT_ALPHA_WEBGL"] = 35986] = "COMPRESSED_RGBA_ATC_EXPLICIT_ALPHA_WEBGL";
	GLEnum$1[GLEnum$1["COMPRESSED_RGBA_ATC_INTERPOLATED_ALPHA_WEBGL"] = 34798] = "COMPRESSED_RGBA_ATC_INTERPOLATED_ALPHA_WEBGL";
	GLEnum$1[GLEnum$1["COMPRESSED_RGBA_ASTC_4x4_KHR"] = 37808] = "COMPRESSED_RGBA_ASTC_4x4_KHR";
	GLEnum$1[GLEnum$1["COMPRESSED_RGBA_ASTC_5x4_KHR"] = 37809] = "COMPRESSED_RGBA_ASTC_5x4_KHR";
	GLEnum$1[GLEnum$1["COMPRESSED_RGBA_ASTC_5x5_KHR"] = 37810] = "COMPRESSED_RGBA_ASTC_5x5_KHR";
	GLEnum$1[GLEnum$1["COMPRESSED_RGBA_ASTC_6x5_KHR"] = 37811] = "COMPRESSED_RGBA_ASTC_6x5_KHR";
	GLEnum$1[GLEnum$1["COMPRESSED_RGBA_ASTC_6x6_KHR"] = 37812] = "COMPRESSED_RGBA_ASTC_6x6_KHR";
	GLEnum$1[GLEnum$1["COMPRESSED_RGBA_ASTC_8x5_KHR"] = 37813] = "COMPRESSED_RGBA_ASTC_8x5_KHR";
	GLEnum$1[GLEnum$1["COMPRESSED_RGBA_ASTC_8x6_KHR"] = 37814] = "COMPRESSED_RGBA_ASTC_8x6_KHR";
	GLEnum$1[GLEnum$1["COMPRESSED_RGBA_ASTC_8x8_KHR"] = 37815] = "COMPRESSED_RGBA_ASTC_8x8_KHR";
	GLEnum$1[GLEnum$1["COMPRESSED_RGBA_ASTC_10x5_KHR"] = 37816] = "COMPRESSED_RGBA_ASTC_10x5_KHR";
	GLEnum$1[GLEnum$1["COMPRESSED_RGBA_ASTC_10x6_KHR"] = 37817] = "COMPRESSED_RGBA_ASTC_10x6_KHR";
	GLEnum$1[GLEnum$1["COMPRESSED_RGBA_ASTC_10x8_KHR"] = 37818] = "COMPRESSED_RGBA_ASTC_10x8_KHR";
	GLEnum$1[GLEnum$1["COMPRESSED_RGBA_ASTC_10x10_KHR"] = 37819] = "COMPRESSED_RGBA_ASTC_10x10_KHR";
	GLEnum$1[GLEnum$1["COMPRESSED_RGBA_ASTC_12x10_KHR"] = 37820] = "COMPRESSED_RGBA_ASTC_12x10_KHR";
	GLEnum$1[GLEnum$1["COMPRESSED_RGBA_ASTC_12x12_KHR"] = 37821] = "COMPRESSED_RGBA_ASTC_12x12_KHR";
	GLEnum$1[GLEnum$1["COMPRESSED_SRGB8_ALPHA8_ASTC_4x4_KHR"] = 37840] = "COMPRESSED_SRGB8_ALPHA8_ASTC_4x4_KHR";
	GLEnum$1[GLEnum$1["COMPRESSED_SRGB8_ALPHA8_ASTC_5x4_KHR"] = 37841] = "COMPRESSED_SRGB8_ALPHA8_ASTC_5x4_KHR";
	GLEnum$1[GLEnum$1["COMPRESSED_SRGB8_ALPHA8_ASTC_5x5_KHR"] = 37842] = "COMPRESSED_SRGB8_ALPHA8_ASTC_5x5_KHR";
	GLEnum$1[GLEnum$1["COMPRESSED_SRGB8_ALPHA8_ASTC_6x5_KHR"] = 37843] = "COMPRESSED_SRGB8_ALPHA8_ASTC_6x5_KHR";
	GLEnum$1[GLEnum$1["COMPRESSED_SRGB8_ALPHA8_ASTC_6x6_KHR"] = 37844] = "COMPRESSED_SRGB8_ALPHA8_ASTC_6x6_KHR";
	GLEnum$1[GLEnum$1["COMPRESSED_SRGB8_ALPHA8_ASTC_8x5_KHR"] = 37845] = "COMPRESSED_SRGB8_ALPHA8_ASTC_8x5_KHR";
	GLEnum$1[GLEnum$1["COMPRESSED_SRGB8_ALPHA8_ASTC_8x6_KHR"] = 37846] = "COMPRESSED_SRGB8_ALPHA8_ASTC_8x6_KHR";
	GLEnum$1[GLEnum$1["COMPRESSED_SRGB8_ALPHA8_ASTC_8x8_KHR"] = 37847] = "COMPRESSED_SRGB8_ALPHA8_ASTC_8x8_KHR";
	GLEnum$1[GLEnum$1["COMPRESSED_SRGB8_ALPHA8_ASTC_10x5_KHR"] = 37848] = "COMPRESSED_SRGB8_ALPHA8_ASTC_10x5_KHR";
	GLEnum$1[GLEnum$1["COMPRESSED_SRGB8_ALPHA8_ASTC_10x6_KHR"] = 37849] = "COMPRESSED_SRGB8_ALPHA8_ASTC_10x6_KHR";
	GLEnum$1[GLEnum$1["COMPRESSED_SRGB8_ALPHA8_ASTC_10x8_KHR"] = 37850] = "COMPRESSED_SRGB8_ALPHA8_ASTC_10x8_KHR";
	GLEnum$1[GLEnum$1["COMPRESSED_SRGB8_ALPHA8_ASTC_10x10_KHR"] = 37851] = "COMPRESSED_SRGB8_ALPHA8_ASTC_10x10_KHR";
	GLEnum$1[GLEnum$1["COMPRESSED_SRGB8_ALPHA8_ASTC_12x10_KHR"] = 37852] = "COMPRESSED_SRGB8_ALPHA8_ASTC_12x10_KHR";
	GLEnum$1[GLEnum$1["COMPRESSED_SRGB8_ALPHA8_ASTC_12x12_KHR"] = 37853] = "COMPRESSED_SRGB8_ALPHA8_ASTC_12x12_KHR";
	/** The number of bits used to hold the query result for the given target. */
	GLEnum$1[GLEnum$1["QUERY_COUNTER_BITS_EXT"] = 34916] = "QUERY_COUNTER_BITS_EXT";
	/** The currently active query. */
	GLEnum$1[GLEnum$1["CURRENT_QUERY_EXT"] = 34917] = "CURRENT_QUERY_EXT";
	/** The query result. */
	GLEnum$1[GLEnum$1["QUERY_RESULT_EXT"] = 34918] = "QUERY_RESULT_EXT";
	/** A Boolean indicating whether or not a query result is available. */
	GLEnum$1[GLEnum$1["QUERY_RESULT_AVAILABLE_EXT"] = 34919] = "QUERY_RESULT_AVAILABLE_EXT";
	/** Elapsed time (in nanoseconds). */
	GLEnum$1[GLEnum$1["TIME_ELAPSED_EXT"] = 35007] = "TIME_ELAPSED_EXT";
	/** The current time. */
	GLEnum$1[GLEnum$1["TIMESTAMP_EXT"] = 36392] = "TIMESTAMP_EXT";
	/** A Boolean indicating whether or not the GPU performed any disjoint operation (lost context) */
	GLEnum$1[GLEnum$1["GPU_DISJOINT_EXT"] = 36795] = "GPU_DISJOINT_EXT";
	/** a non-blocking poll operation, so that compile/link status availability can be queried without potentially incurring stalls */
	GLEnum$1[GLEnum$1["COMPLETION_STATUS_KHR"] = 37297] = "COMPLETION_STATUS_KHR";
	/** Disables depth clipping */
	GLEnum$1[GLEnum$1["DEPTH_CLAMP_EXT"] = 34383] = "DEPTH_CLAMP_EXT";
	/** Values of first vertex in primitive are used for flat shading */
	GLEnum$1[GLEnum$1["FIRST_VERTEX_CONVENTION_WEBGL"] = 36429] = "FIRST_VERTEX_CONVENTION_WEBGL";
	/** Values of first vertex in primitive are used for flat shading */
	GLEnum$1[GLEnum$1["LAST_VERTEX_CONVENTION_WEBGL"] = 36430] = "LAST_VERTEX_CONVENTION_WEBGL";
	/** Controls which vertex in primitive is used for flat shading */
	GLEnum$1[GLEnum$1["PROVOKING_VERTEX_WEBL"] = 36431] = "PROVOKING_VERTEX_WEBL";
	GLEnum$1[GLEnum$1["POLYGON_MODE_WEBGL"] = 2880] = "POLYGON_MODE_WEBGL";
	GLEnum$1[GLEnum$1["POLYGON_OFFSET_LINE_WEBGL"] = 10754] = "POLYGON_OFFSET_LINE_WEBGL";
	GLEnum$1[GLEnum$1["LINE_WEBGL"] = 6913] = "LINE_WEBGL";
	GLEnum$1[GLEnum$1["FILL_WEBGL"] = 6914] = "FILL_WEBGL";
	/** Max clip distances */
	GLEnum$1[GLEnum$1["MAX_CLIP_DISTANCES_WEBGL"] = 3378] = "MAX_CLIP_DISTANCES_WEBGL";
	/** Max cull distances */
	GLEnum$1[GLEnum$1["MAX_CULL_DISTANCES_WEBGL"] = 33529] = "MAX_CULL_DISTANCES_WEBGL";
	/** Max clip and cull distances */
	GLEnum$1[GLEnum$1["MAX_COMBINED_CLIP_AND_CULL_DISTANCES_WEBGL"] = 33530] = "MAX_COMBINED_CLIP_AND_CULL_DISTANCES_WEBGL";
	/** Enable gl_ClipDistance[0] and gl_CullDistance[0] */
	GLEnum$1[GLEnum$1["CLIP_DISTANCE0_WEBGL"] = 12288] = "CLIP_DISTANCE0_WEBGL";
	/** Enable gl_ClipDistance[1] and gl_CullDistance[1] */
	GLEnum$1[GLEnum$1["CLIP_DISTANCE1_WEBGL"] = 12289] = "CLIP_DISTANCE1_WEBGL";
	/** Enable gl_ClipDistance[2] and gl_CullDistance[2] */
	GLEnum$1[GLEnum$1["CLIP_DISTANCE2_WEBGL"] = 12290] = "CLIP_DISTANCE2_WEBGL";
	/** Enable gl_ClipDistance[3] and gl_CullDistance[3] */
	GLEnum$1[GLEnum$1["CLIP_DISTANCE3_WEBGL"] = 12291] = "CLIP_DISTANCE3_WEBGL";
	/** Enable gl_ClipDistance[4] and gl_CullDistance[4] */
	GLEnum$1[GLEnum$1["CLIP_DISTANCE4_WEBGL"] = 12292] = "CLIP_DISTANCE4_WEBGL";
	/** Enable gl_ClipDistance[5] and gl_CullDistance[5] */
	GLEnum$1[GLEnum$1["CLIP_DISTANCE5_WEBGL"] = 12293] = "CLIP_DISTANCE5_WEBGL";
	/** Enable gl_ClipDistance[6] and gl_CullDistance[6] */
	GLEnum$1[GLEnum$1["CLIP_DISTANCE6_WEBGL"] = 12294] = "CLIP_DISTANCE6_WEBGL";
	/** Enable gl_ClipDistance[7] and gl_CullDistance[7] */
	GLEnum$1[GLEnum$1["CLIP_DISTANCE7_WEBGL"] = 12295] = "CLIP_DISTANCE7_WEBGL";
	/** EXT_polygon_offset_clamp https://registry.khronos.org/webgl/extensions/EXT_polygon_offset_clamp/ */
	GLEnum$1[GLEnum$1["POLYGON_OFFSET_CLAMP_EXT"] = 36379] = "POLYGON_OFFSET_CLAMP_EXT";
	/** EXT_clip_control https://registry.khronos.org/webgl/extensions/EXT_clip_control/ */
	GLEnum$1[GLEnum$1["LOWER_LEFT_EXT"] = 36001] = "LOWER_LEFT_EXT";
	GLEnum$1[GLEnum$1["UPPER_LEFT_EXT"] = 36002] = "UPPER_LEFT_EXT";
	GLEnum$1[GLEnum$1["NEGATIVE_ONE_TO_ONE_EXT"] = 37726] = "NEGATIVE_ONE_TO_ONE_EXT";
	GLEnum$1[GLEnum$1["ZERO_TO_ONE_EXT"] = 37727] = "ZERO_TO_ONE_EXT";
	GLEnum$1[GLEnum$1["CLIP_ORIGIN_EXT"] = 37724] = "CLIP_ORIGIN_EXT";
	GLEnum$1[GLEnum$1["CLIP_DEPTH_MODE_EXT"] = 37725] = "CLIP_DEPTH_MODE_EXT";
	/** WEBGL_blend_func_extended https://registry.khronos.org/webgl/extensions/WEBGL_blend_func_extended/ */
	GLEnum$1[GLEnum$1["SRC1_COLOR_WEBGL"] = 35065] = "SRC1_COLOR_WEBGL";
	GLEnum$1[GLEnum$1["SRC1_ALPHA_WEBGL"] = 34185] = "SRC1_ALPHA_WEBGL";
	GLEnum$1[GLEnum$1["ONE_MINUS_SRC1_COLOR_WEBGL"] = 35066] = "ONE_MINUS_SRC1_COLOR_WEBGL";
	GLEnum$1[GLEnum$1["ONE_MINUS_SRC1_ALPHA_WEBGL"] = 35067] = "ONE_MINUS_SRC1_ALPHA_WEBGL";
	GLEnum$1[GLEnum$1["MAX_DUAL_SOURCE_DRAW_BUFFERS_WEBGL"] = 35068] = "MAX_DUAL_SOURCE_DRAW_BUFFERS_WEBGL";
	/** EXT_texture_mirror_clamp_to_edge https://registry.khronos.org/webgl/extensions/EXT_texture_mirror_clamp_to_edge/ */
	GLEnum$1[GLEnum$1["MIRROR_CLAMP_TO_EDGE_EXT"] = 34627] = "MIRROR_CLAMP_TO_EDGE_EXT";
})(GLEnum || (GLEnum = {}));

//#endregion
//#region node_modules/@luma.gl/webgl/dist/utils/load-script.js
/**
* Load a script (identified by an url). When the url returns, the
* content of this file is added into a new script element, attached to the DOM (body element)
* @param scriptUrl defines the url of the script to laod
* @param scriptId defines the id of the script element
*/
async function loadScript(scriptUrl, scriptId) {
	const head = document.getElementsByTagName("head")[0];
	if (!head) throw new Error("loadScript");
	const script = document.createElement("script");
	script.setAttribute("type", "text/javascript");
	script.setAttribute("src", scriptUrl);
	if (scriptId) script.id = scriptId;
	return new Promise((resolve, reject) => {
		script.onload = resolve;
		script.onerror = (error) => reject(/* @__PURE__ */ new Error(`Unable to load script '${scriptUrl}': ${error}`));
		head.appendChild(script);
	});
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/context/debug/spector.js
var LOG_LEVEL = 1;
var spector = null;
var initialized = false;
const DEFAULT_SPECTOR_PROPS = {
	debugSpectorJS: log.get("debug-spectorjs"),
	debugSpectorJSUrl: "https://cdn.jsdelivr.net/npm/spectorjs@0.9.30/dist/spector.bundle.js",
	gl: void 0
};
/** Loads spector from CDN if not already installed */
async function loadSpectorJS(props) {
	if (!globalThis.SPECTOR) try {
		await loadScript(props.debugSpectorJSUrl || DEFAULT_SPECTOR_PROPS.debugSpectorJSUrl);
	} catch (error) {
		log.warn(String(error));
	}
}
function initializeSpectorJS(props) {
	props = {
		...DEFAULT_SPECTOR_PROPS,
		...props
	};
	if (!props.debugSpectorJS) return null;
	if (!spector && globalThis.SPECTOR && !globalThis.luma?.spector) {
		log.probe(LOG_LEVEL, "SPECTOR found and initialized. Start with `luma.spector.displayUI()`")();
		const { Spector: SpectorJS } = globalThis.SPECTOR;
		spector = new SpectorJS();
		if (globalThis.luma) globalThis.luma.spector = spector;
	}
	if (!spector) return null;
	if (!initialized) {
		initialized = true;
		spector.spyCanvases();
		spector?.onCaptureStarted.add((capture) => log.info("Spector capture started:", capture)());
		spector?.onCapture.add((capture) => {
			log.info("Spector capture complete:", capture)();
			spector?.getResultUI();
			spector?.resultView.display();
			spector?.resultView.addCapture(capture);
		});
	}
	if (props.gl) {
		const gl = props.gl;
		const device = gl.device;
		spector?.startCapture(props.gl, 500);
		gl.device = device;
		new Promise((resolve) => setTimeout(resolve, 2e3)).then((_) => {
			log.info("Spector capture stopped after 2 seconds")();
			spector?.stopCapture();
		});
	}
	return spector;
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/context/debug/webgl-developer-tools.js
var WEBGL_DEBUG_CDN_URL = "https://unpkg.com/webgl-debug@2.0.1/index.js";
function getWebGLContextData(gl) {
	gl.luma = gl.luma || {};
	return gl.luma;
}
/**
* Loads Khronos WebGLDeveloperTools from CDN if not already installed
* const WebGLDebugUtils = require('webgl-debug');
* @see https://github.com/KhronosGroup/WebGLDeveloperTools
* @see https://github.com/vorg/webgl-debug
*/
async function loadWebGLDeveloperTools() {
	if (isBrowser() && !globalThis.WebGLDebugUtils) {
		globalThis.global = globalThis.global || globalThis;
		globalThis.global.module = {};
		await loadScript(WEBGL_DEBUG_CDN_URL);
	}
}
function makeDebugContext(gl, props = {}) {
	return props.debugWebGL || props.traceWebGL ? getDebugContext(gl, props) : getRealContext(gl);
}
function getRealContext(gl) {
	const data = getWebGLContextData(gl);
	return data.realContext ? data.realContext : gl;
}
function getDebugContext(gl, props) {
	if (!globalThis.WebGLDebugUtils) {
		log.warn("webgl-debug not loaded")();
		return gl;
	}
	const data = getWebGLContextData(gl);
	if (data.debugContext) return data.debugContext;
	globalThis.WebGLDebugUtils.init({
		...GLEnum,
		...gl
	});
	const glDebug = globalThis.WebGLDebugUtils.makeDebugContext(gl, onGLError.bind(null, props), onValidateGLFunc.bind(null, props));
	for (const key in GLEnum) if (!(key in glDebug) && typeof GLEnum[key] === "number") glDebug[key] = GLEnum[key];
	class WebGLDebugContext {}
	Object.setPrototypeOf(glDebug, Object.getPrototypeOf(gl));
	Object.setPrototypeOf(WebGLDebugContext, glDebug);
	const debugContext = Object.create(WebGLDebugContext);
	data.realContext = gl;
	data.debugContext = debugContext;
	debugContext.debug = true;
	return debugContext;
}
function getFunctionString(functionName, functionArgs) {
	functionArgs = Array.from(functionArgs).map((arg) => arg === void 0 ? "undefined" : arg);
	let args = globalThis.WebGLDebugUtils.glFunctionArgsToString(functionName, functionArgs);
	args = `${args.slice(0, 100)}${args.length > 100 ? "..." : ""}`;
	return `gl.${functionName}(${args})`;
}
function onGLError(props, err, functionName, args) {
	args = Array.from(args).map((arg) => arg === void 0 ? "undefined" : arg);
	const message$1 = `${globalThis.WebGLDebugUtils.glEnumToString(err)} in gl.${functionName}(${globalThis.WebGLDebugUtils.glFunctionArgsToString(functionName, args)})`;
	log.error(message$1)();
	debugger;
}
function onValidateGLFunc(props, functionName, functionArgs) {
	let functionString = "";
	if (log.level >= 1) {
		functionString = getFunctionString(functionName, functionArgs);
		if (props.traceWebGL) log.log(1, functionString)();
	}
	for (const arg of functionArgs) if (arg === void 0) {
		functionString = functionString || getFunctionString(functionName, functionArgs);
		debugger;
	}
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/context/parameters/webgl-parameter-tables.js
const GL_PARAMETER_DEFAULTS = {
	[3042]: false,
	[32773]: new Float32Array([
		0,
		0,
		0,
		0
	]),
	[32777]: 32774,
	[34877]: 32774,
	[32969]: 1,
	[32968]: 0,
	[32971]: 1,
	[32970]: 0,
	[3106]: new Float32Array([
		0,
		0,
		0,
		0
	]),
	[3107]: [
		true,
		true,
		true,
		true
	],
	[2884]: false,
	[2885]: 1029,
	[2929]: false,
	[2931]: 1,
	[2932]: 513,
	[2928]: new Float32Array([0, 1]),
	[2930]: true,
	[3024]: true,
	[35725]: null,
	[36006]: null,
	[36007]: null,
	[34229]: null,
	[34964]: null,
	[2886]: 2305,
	[33170]: 4352,
	[2849]: 1,
	[32823]: false,
	[32824]: 0,
	[10752]: 0,
	[32926]: false,
	[32928]: false,
	[32938]: 1,
	[32939]: false,
	[3089]: false,
	[3088]: new Int32Array([
		0,
		0,
		1024,
		1024
	]),
	[2960]: false,
	[2961]: 0,
	[2968]: 4294967295,
	[36005]: 4294967295,
	[2962]: 519,
	[2967]: 0,
	[2963]: 4294967295,
	[34816]: 519,
	[36003]: 0,
	[36004]: 4294967295,
	[2964]: 7680,
	[2965]: 7680,
	[2966]: 7680,
	[34817]: 7680,
	[34818]: 7680,
	[34819]: 7680,
	[2978]: [
		0,
		0,
		1024,
		1024
	],
	[36389]: null,
	[36662]: null,
	[36663]: null,
	[35053]: null,
	[35055]: null,
	[35723]: 4352,
	[36010]: null,
	[35977]: false,
	[3333]: 4,
	[3317]: 4,
	[37440]: false,
	[37441]: false,
	[37443]: 37444,
	[3330]: 0,
	[3332]: 0,
	[3331]: 0,
	[3314]: 0,
	[32878]: 0,
	[3316]: 0,
	[3315]: 0,
	[32877]: 0
};
var enable = (gl, value, key) => value ? gl.enable(key) : gl.disable(key);
var hint = (gl, value, key) => gl.hint(key, value);
var pixelStorei = (gl, value, key) => gl.pixelStorei(key, value);
var bindFramebuffer = (gl, value, key) => {
	const target$1 = key === 36006 ? 36009 : 36008;
	return gl.bindFramebuffer(target$1, value);
};
var bindBuffer = (gl, value, key) => {
	const glTarget = {
		[34964]: 34962,
		[36662]: 36662,
		[36663]: 36663,
		[35053]: 35051,
		[35055]: 35052
	}[key];
	gl.bindBuffer(glTarget, value);
};
function isArray$1(array) {
	return Array.isArray(array) || ArrayBuffer.isView(array) && !(array instanceof DataView);
}
const GL_PARAMETER_SETTERS = {
	[3042]: enable,
	[32773]: (gl, value) => gl.blendColor(...value),
	[32777]: "blendEquation",
	[34877]: "blendEquation",
	[32969]: "blendFunc",
	[32968]: "blendFunc",
	[32971]: "blendFunc",
	[32970]: "blendFunc",
	[3106]: (gl, value) => gl.clearColor(...value),
	[3107]: (gl, value) => gl.colorMask(...value),
	[2884]: enable,
	[2885]: (gl, value) => gl.cullFace(value),
	[2929]: enable,
	[2931]: (gl, value) => gl.clearDepth(value),
	[2932]: (gl, value) => gl.depthFunc(value),
	[2928]: (gl, value) => gl.depthRange(...value),
	[2930]: (gl, value) => gl.depthMask(value),
	[3024]: enable,
	[35723]: hint,
	[35725]: (gl, value) => gl.useProgram(value),
	[36007]: (gl, value) => gl.bindRenderbuffer(36161, value),
	[36389]: (gl, value) => gl.bindTransformFeedback?.(36386, value),
	[34229]: (gl, value) => gl.bindVertexArray(value),
	[36006]: bindFramebuffer,
	[36010]: bindFramebuffer,
	[34964]: bindBuffer,
	[36662]: bindBuffer,
	[36663]: bindBuffer,
	[35053]: bindBuffer,
	[35055]: bindBuffer,
	[2886]: (gl, value) => gl.frontFace(value),
	[33170]: hint,
	[2849]: (gl, value) => gl.lineWidth(value),
	[32823]: enable,
	[32824]: "polygonOffset",
	[10752]: "polygonOffset",
	[35977]: enable,
	[32926]: enable,
	[32928]: enable,
	[32938]: "sampleCoverage",
	[32939]: "sampleCoverage",
	[3089]: enable,
	[3088]: (gl, value) => gl.scissor(...value),
	[2960]: enable,
	[2961]: (gl, value) => gl.clearStencil(value),
	[2968]: (gl, value) => gl.stencilMaskSeparate(1028, value),
	[36005]: (gl, value) => gl.stencilMaskSeparate(1029, value),
	[2962]: "stencilFuncFront",
	[2967]: "stencilFuncFront",
	[2963]: "stencilFuncFront",
	[34816]: "stencilFuncBack",
	[36003]: "stencilFuncBack",
	[36004]: "stencilFuncBack",
	[2964]: "stencilOpFront",
	[2965]: "stencilOpFront",
	[2966]: "stencilOpFront",
	[34817]: "stencilOpBack",
	[34818]: "stencilOpBack",
	[34819]: "stencilOpBack",
	[2978]: (gl, value) => gl.viewport(...value),
	[34383]: enable,
	[10754]: enable,
	[12288]: enable,
	[12289]: enable,
	[12290]: enable,
	[12291]: enable,
	[12292]: enable,
	[12293]: enable,
	[12294]: enable,
	[12295]: enable,
	[3333]: pixelStorei,
	[3317]: pixelStorei,
	[37440]: pixelStorei,
	[37441]: pixelStorei,
	[37443]: pixelStorei,
	[3330]: pixelStorei,
	[3332]: pixelStorei,
	[3331]: pixelStorei,
	[3314]: pixelStorei,
	[32878]: pixelStorei,
	[3316]: pixelStorei,
	[3315]: pixelStorei,
	[32877]: pixelStorei,
	framebuffer: (gl, framebuffer) => {
		const handle = framebuffer && "handle" in framebuffer ? framebuffer.handle : framebuffer;
		return gl.bindFramebuffer(36160, handle);
	},
	blend: (gl, value) => value ? gl.enable(3042) : gl.disable(3042),
	blendColor: (gl, value) => gl.blendColor(...value),
	blendEquation: (gl, args) => {
		const separateModes = typeof args === "number" ? [args, args] : args;
		gl.blendEquationSeparate(...separateModes);
	},
	blendFunc: (gl, args) => {
		const separateFuncs = args?.length === 2 ? [...args, ...args] : args;
		gl.blendFuncSeparate(...separateFuncs);
	},
	clearColor: (gl, value) => gl.clearColor(...value),
	clearDepth: (gl, value) => gl.clearDepth(value),
	clearStencil: (gl, value) => gl.clearStencil(value),
	colorMask: (gl, value) => gl.colorMask(...value),
	cull: (gl, value) => value ? gl.enable(2884) : gl.disable(2884),
	cullFace: (gl, value) => gl.cullFace(value),
	depthTest: (gl, value) => value ? gl.enable(2929) : gl.disable(2929),
	depthFunc: (gl, value) => gl.depthFunc(value),
	depthMask: (gl, value) => gl.depthMask(value),
	depthRange: (gl, value) => gl.depthRange(...value),
	dither: (gl, value) => value ? gl.enable(3024) : gl.disable(3024),
	derivativeHint: (gl, value) => {
		gl.hint(35723, value);
	},
	frontFace: (gl, value) => gl.frontFace(value),
	mipmapHint: (gl, value) => gl.hint(33170, value),
	lineWidth: (gl, value) => gl.lineWidth(value),
	polygonOffsetFill: (gl, value) => value ? gl.enable(32823) : gl.disable(32823),
	polygonOffset: (gl, value) => gl.polygonOffset(...value),
	sampleCoverage: (gl, value) => gl.sampleCoverage(value[0], value[1] || false),
	scissorTest: (gl, value) => value ? gl.enable(3089) : gl.disable(3089),
	scissor: (gl, value) => gl.scissor(...value),
	stencilTest: (gl, value) => value ? gl.enable(2960) : gl.disable(2960),
	stencilMask: (gl, value) => {
		value = isArray$1(value) ? value : [value, value];
		const [mask, backMask] = value;
		gl.stencilMaskSeparate(1028, mask);
		gl.stencilMaskSeparate(1029, backMask);
	},
	stencilFunc: (gl, args) => {
		args = isArray$1(args) && args.length === 3 ? [...args, ...args] : args;
		const [func, ref, mask, backFunc, backRef, backMask] = args;
		gl.stencilFuncSeparate(1028, func, ref, mask);
		gl.stencilFuncSeparate(1029, backFunc, backRef, backMask);
	},
	stencilOp: (gl, args) => {
		args = isArray$1(args) && args.length === 3 ? [...args, ...args] : args;
		const [sfail, dpfail, dppass, backSfail, backDpfail, backDppass] = args;
		gl.stencilOpSeparate(1028, sfail, dpfail, dppass);
		gl.stencilOpSeparate(1029, backSfail, backDpfail, backDppass);
	},
	viewport: (gl, value) => gl.viewport(...value)
};
function getValue(glEnum, values, cache$1) {
	return values[glEnum] !== void 0 ? values[glEnum] : cache$1[glEnum];
}
const GL_COMPOSITE_PARAMETER_SETTERS = {
	blendEquation: (gl, values, cache$1) => gl.blendEquationSeparate(getValue(32777, values, cache$1), getValue(34877, values, cache$1)),
	blendFunc: (gl, values, cache$1) => gl.blendFuncSeparate(getValue(32969, values, cache$1), getValue(32968, values, cache$1), getValue(32971, values, cache$1), getValue(32970, values, cache$1)),
	polygonOffset: (gl, values, cache$1) => gl.polygonOffset(getValue(32824, values, cache$1), getValue(10752, values, cache$1)),
	sampleCoverage: (gl, values, cache$1) => gl.sampleCoverage(getValue(32938, values, cache$1), getValue(32939, values, cache$1)),
	stencilFuncFront: (gl, values, cache$1) => gl.stencilFuncSeparate(1028, getValue(2962, values, cache$1), getValue(2967, values, cache$1), getValue(2963, values, cache$1)),
	stencilFuncBack: (gl, values, cache$1) => gl.stencilFuncSeparate(1029, getValue(34816, values, cache$1), getValue(36003, values, cache$1), getValue(36004, values, cache$1)),
	stencilOpFront: (gl, values, cache$1) => gl.stencilOpSeparate(1028, getValue(2964, values, cache$1), getValue(2965, values, cache$1), getValue(2966, values, cache$1)),
	stencilOpBack: (gl, values, cache$1) => gl.stencilOpSeparate(1029, getValue(34817, values, cache$1), getValue(34818, values, cache$1), getValue(34819, values, cache$1))
};
const GL_HOOKED_SETTERS = {
	enable: (update, capability) => update({ [capability]: true }),
	disable: (update, capability) => update({ [capability]: false }),
	pixelStorei: (update, pname, value) => update({ [pname]: value }),
	hint: (update, pname, value) => update({ [pname]: value }),
	useProgram: (update, value) => update({ [35725]: value }),
	bindRenderbuffer: (update, target$1, value) => update({ [36007]: value }),
	bindTransformFeedback: (update, target$1, value) => update({ [36389]: value }),
	bindVertexArray: (update, value) => update({ [34229]: value }),
	bindFramebuffer: (update, target$1, framebuffer) => {
		switch (target$1) {
			case 36160: return update({
				[36006]: framebuffer,
				[36010]: framebuffer
			});
			case 36009: return update({ [36006]: framebuffer });
			case 36008: return update({ [36010]: framebuffer });
			default: return null;
		}
	},
	bindBuffer: (update, target$1, buffer) => {
		const pname = {
			[34962]: [34964],
			[36662]: [36662],
			[36663]: [36663],
			[35051]: [35053],
			[35052]: [35055]
		}[target$1];
		if (pname) return update({ [pname]: buffer });
		return { valueChanged: true };
	},
	blendColor: (update, r, g, b, a) => update({ [32773]: new Float32Array([
		r,
		g,
		b,
		a
	]) }),
	blendEquation: (update, mode) => update({
		[32777]: mode,
		[34877]: mode
	}),
	blendEquationSeparate: (update, modeRGB, modeAlpha) => update({
		[32777]: modeRGB,
		[34877]: modeAlpha
	}),
	blendFunc: (update, src, dst) => update({
		[32969]: src,
		[32968]: dst,
		[32971]: src,
		[32970]: dst
	}),
	blendFuncSeparate: (update, srcRGB, dstRGB, srcAlpha, dstAlpha) => update({
		[32969]: srcRGB,
		[32968]: dstRGB,
		[32971]: srcAlpha,
		[32970]: dstAlpha
	}),
	clearColor: (update, r, g, b, a) => update({ [3106]: new Float32Array([
		r,
		g,
		b,
		a
	]) }),
	clearDepth: (update, depth) => update({ [2931]: depth }),
	clearStencil: (update, s) => update({ [2961]: s }),
	colorMask: (update, r, g, b, a) => update({ [3107]: [
		r,
		g,
		b,
		a
	] }),
	cullFace: (update, mode) => update({ [2885]: mode }),
	depthFunc: (update, func) => update({ [2932]: func }),
	depthRange: (update, zNear, zFar) => update({ [2928]: new Float32Array([zNear, zFar]) }),
	depthMask: (update, mask) => update({ [2930]: mask }),
	frontFace: (update, face) => update({ [2886]: face }),
	lineWidth: (update, width) => update({ [2849]: width }),
	polygonOffset: (update, factor, units) => update({
		[32824]: factor,
		[10752]: units
	}),
	sampleCoverage: (update, value, invert) => update({
		[32938]: value,
		[32939]: invert
	}),
	scissor: (update, x, y, width, height) => update({ [3088]: new Int32Array([
		x,
		y,
		width,
		height
	]) }),
	stencilMask: (update, mask) => update({
		[2968]: mask,
		[36005]: mask
	}),
	stencilMaskSeparate: (update, face, mask) => update({ [face === 1028 ? 2968 : 36005]: mask }),
	stencilFunc: (update, func, ref, mask) => update({
		[2962]: func,
		[2967]: ref,
		[2963]: mask,
		[34816]: func,
		[36003]: ref,
		[36004]: mask
	}),
	stencilFuncSeparate: (update, face, func, ref, mask) => update({
		[face === 1028 ? 2962 : 34816]: func,
		[face === 1028 ? 2967 : 36003]: ref,
		[face === 1028 ? 2963 : 36004]: mask
	}),
	stencilOp: (update, fail, zfail, zpass) => update({
		[2964]: fail,
		[2965]: zfail,
		[2966]: zpass,
		[34817]: fail,
		[34818]: zfail,
		[34819]: zpass
	}),
	stencilOpSeparate: (update, face, fail, zfail, zpass) => update({
		[face === 1028 ? 2964 : 34817]: fail,
		[face === 1028 ? 2965 : 34818]: zfail,
		[face === 1028 ? 2966 : 34819]: zpass
	}),
	viewport: (update, x, y, width, height) => update({ [2978]: [
		x,
		y,
		width,
		height
	] })
};
var isEnabled = (gl, key) => gl.isEnabled(key);
const GL_PARAMETER_GETTERS = {
	[3042]: isEnabled,
	[2884]: isEnabled,
	[2929]: isEnabled,
	[3024]: isEnabled,
	[32823]: isEnabled,
	[32926]: isEnabled,
	[32928]: isEnabled,
	[3089]: isEnabled,
	[2960]: isEnabled,
	[35977]: isEnabled
};
const NON_CACHE_PARAMETERS = new Set([
	34016,
	36388,
	36387,
	35983,
	35368,
	34965,
	35739,
	35738,
	3074,
	34853,
	34854,
	34855,
	34856,
	34857,
	34858,
	34859,
	34860,
	34861,
	34862,
	34863,
	34864,
	34865,
	34866,
	34867,
	34868,
	35097,
	32873,
	35869,
	32874,
	34068
]);

//#endregion
//#region node_modules/@luma.gl/webgl/dist/context/parameters/unified-parameter-api.js
/**
* Sets any GL parameter regardless of function (gl.blendMode, ...)
*
* @note requires a `cache` object to be set on the context (gl.state.cache)
* This object is used to fill in any missing values for composite setter functions
*/
function setGLParameters(gl, parameters) {
	if (isObjectEmpty$2(parameters)) return;
	const compositeSetters = {};
	for (const key in parameters) {
		const glConstant = Number(key);
		const setter = GL_PARAMETER_SETTERS[key];
		if (setter) if (typeof setter === "string") compositeSetters[setter] = true;
		else setter(gl, parameters[key], glConstant);
	}
	const cache$1 = gl.state && gl.state.cache;
	if (cache$1) for (const key in compositeSetters) {
		const compositeSetter = GL_COMPOSITE_PARAMETER_SETTERS[key];
		compositeSetter(gl, parameters, cache$1);
	}
}
/**
* Reads the entire WebGL state from a context

// default to querying all parameters

* @returns - a newly created map, with values keyed by GL parameters
*
* @note Copies the state from a context (gl.getParameter should not be overriden)
* Reads the entire WebGL state from a context
*
* @note This can generates a huge amount of synchronous driver roundtrips and should be
* considered a very slow operation, to be used only if/when a context already manipulated
* by external code needs to be synchronized for the first time
*/
function getGLParameters(gl, parameters = GL_PARAMETER_DEFAULTS) {
	if (typeof parameters === "number") {
		const key = parameters;
		const getter = GL_PARAMETER_GETTERS[key];
		return getter ? getter(gl, key) : gl.getParameter(key);
	}
	const parameterKeys = Array.isArray(parameters) ? parameters : Object.keys(parameters);
	const state = {};
	for (const key of parameterKeys) {
		const getter = GL_PARAMETER_GETTERS[key];
		state[key] = getter ? getter(gl, Number(key)) : gl.getParameter(Number(key));
	}
	return state;
}
/**
* Reset all parameters to a (almost) pure context state
* @note viewport and scissor will be set to the values in GL_PARAMETER_DEFAULTS,
* NOT the canvas size dimensions, so they will have to be properly set after
* calling this function.
*/
function resetGLParameters(gl) {
	setGLParameters(gl, GL_PARAMETER_DEFAULTS);
}
function isObjectEmpty$2(object) {
	for (const key in object) return false;
	return true;
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/context/state-tracker/deep-array-equal.js
/** deeply compare two arrays */
function deepArrayEqual(x, y) {
	if (x === y) return true;
	if (isArray(x) && isArray(y) && x.length === y.length) {
		for (let i = 0; i < x.length; ++i) if (x[i] !== y[i]) return false;
		return true;
	}
	return false;
}
function isArray(x) {
	return Array.isArray(x) || ArrayBuffer.isView(x);
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/context/state-tracker/webgl-state-tracker.js
/**
* Support for listening to context state changes and intercepting state queries
* NOTE: this system does not handle buffer bindings
*/
var WebGLStateTracker = class {
	static get(gl) {
		return gl.state;
	}
	gl;
	program = null;
	stateStack = [];
	enable = true;
	cache = null;
	log;
	initialized = false;
	constructor(gl, props) {
		this.gl = gl;
		this.log = props?.log || (() => {});
		this._updateCache = this._updateCache.bind(this);
		Object.seal(this);
	}
	push(values = {}) {
		this.stateStack.push({});
	}
	pop() {
		const oldValues = this.stateStack[this.stateStack.length - 1];
		setGLParameters(this.gl, oldValues);
		this.stateStack.pop();
	}
	/**
	* Initialize WebGL state caching on a context
	* can be called multiple times to enable/disable
	*
	* @note After calling this function, context state will be cached
	* .push() and .pop() will be available for saving,
	* temporarily modifying, and then restoring state.
	*/
	trackState(gl, options) {
		this.cache = options?.copyState ? getGLParameters(gl) : Object.assign({}, GL_PARAMETER_DEFAULTS);
		if (this.initialized) throw new Error("WebGLStateTracker");
		this.initialized = true;
		this.gl.state = this;
		installProgramSpy(gl);
		for (const key in GL_HOOKED_SETTERS) {
			const setter = GL_HOOKED_SETTERS[key];
			installSetterSpy(gl, key, setter);
		}
		installGetterOverride(gl, "getParameter");
		installGetterOverride(gl, "isEnabled");
	}
	/**
	// interceptor for context set functions - update our cache and our stack
	// values (Object) - the key values for this setter
	* @param values
	* @returns
	*/
	_updateCache(values) {
		let valueChanged = false;
		let oldValue;
		const oldValues = this.stateStack.length > 0 ? this.stateStack[this.stateStack.length - 1] : null;
		for (const key in values) {
			const value = values[key];
			const cached = this.cache[key];
			if (!deepArrayEqual(value, cached)) {
				valueChanged = true;
				oldValue = cached;
				if (oldValues && !(key in oldValues)) oldValues[key] = cached;
				this.cache[key] = value;
			}
		}
		return {
			valueChanged,
			oldValue
		};
	}
};
/**
// Overrides a WebGL2RenderingContext state "getter" function
// to return values directly from cache
* @param gl
* @param functionName
*/
function installGetterOverride(gl, functionName) {
	const originalGetterFunc = gl[functionName].bind(gl);
	gl[functionName] = function get(pname) {
		if (pname === void 0 || NON_CACHE_PARAMETERS.has(pname)) return originalGetterFunc(pname);
		const glState = WebGLStateTracker.get(gl);
		if (!(pname in glState.cache)) glState.cache[pname] = originalGetterFunc(pname);
		return glState.enable ? glState.cache[pname] : originalGetterFunc(pname);
	};
	Object.defineProperty(gl[functionName], "name", {
		value: `${functionName}-from-cache`,
		configurable: false
	});
}
/**
// Overrides a WebGL2RenderingContext state "setter" function
// to call a setter spy before the actual setter. Allows us to keep a cache
// updated with a copy of the WebGL context state.
* @param gl
* @param functionName
* @param setter
* @returns
*/
function installSetterSpy(gl, functionName, setter) {
	if (!gl[functionName]) return;
	const originalSetterFunc = gl[functionName].bind(gl);
	gl[functionName] = function set(...params) {
		const { valueChanged, oldValue } = setter(WebGLStateTracker.get(gl)._updateCache, ...params);
		if (valueChanged) originalSetterFunc(...params);
		return oldValue;
	};
	Object.defineProperty(gl[functionName], "name", {
		value: `${functionName}-to-cache`,
		configurable: false
	});
}
function installProgramSpy(gl) {
	const originalUseProgram = gl.useProgram.bind(gl);
	gl.useProgram = function useProgramLuma(handle) {
		const glState = WebGLStateTracker.get(gl);
		if (glState.program !== handle) {
			originalUseProgram(handle);
			glState.program = handle;
		}
	};
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/context/helpers/create-browser-context.js
/**
* Create a WebGL context for a canvas
* Note calling this multiple time on the same canvas does return the same context
* @param canvas A canvas element or offscreen canvas
*/
function createBrowserContext(canvas, props, webglContextAttributes) {
	let errorMessage = "";
	const webglProps = {
		preserveDrawingBuffer: true,
		...webglContextAttributes
	};
	let gl = null;
	gl ||= canvas.getContext("webgl2", webglProps);
	if (webglProps.failIfMajorPerformanceCaveat) errorMessage ||= "Only software GPU is available. Set `failIfMajorPerformanceCaveat: false` to allow.";
	if (!gl && !webglContextAttributes.failIfMajorPerformanceCaveat) {
		webglProps.failIfMajorPerformanceCaveat = false;
		gl = canvas.getContext("webgl2", webglProps);
		gl.luma ||= {};
		gl.luma.softwareRenderer = true;
	}
	if (!gl) {
		gl = canvas.getContext("webgl", {});
		if (gl) {
			gl = null;
			errorMessage ||= "Your browser only supports WebGL1";
		}
	}
	if (!gl) {
		errorMessage ||= "Your browser does not support WebGL";
		throw new Error(`Failed to create WebGL context: ${errorMessage}`);
	}
	const { onContextLost, onContextRestored } = props;
	canvas.addEventListener("webglcontextlost", (event) => onContextLost(event), false);
	canvas.addEventListener("webglcontextrestored", (event) => onContextRestored(event), false);
	gl.luma ||= {};
	return gl;
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/context/helpers/webgl-extensions.js
/** Ensure extensions are only requested once */
function getWebGLExtension(gl, name$1, extensions) {
	if (extensions[name$1] === void 0) extensions[name$1] = gl.getExtension(name$1) || null;
	return extensions[name$1];
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/device-helpers/webgl-device-info.js
/** @returns strings identifying the GPU vendor and driver. */
function getDeviceInfo(gl, extensions) {
	const vendorMasked = gl.getParameter(7936);
	const rendererMasked = gl.getParameter(7937);
	getWebGLExtension(gl, "WEBGL_debug_renderer_info", extensions);
	const ext = extensions.WEBGL_debug_renderer_info;
	const vendorUnmasked = gl.getParameter(ext ? ext.UNMASKED_VENDOR_WEBGL : 7936);
	const rendererUnmasked = gl.getParameter(ext ? ext.UNMASKED_RENDERER_WEBGL : 7937);
	const vendor = vendorUnmasked || vendorMasked;
	const renderer = rendererUnmasked || rendererMasked;
	const version = gl.getParameter(7938);
	const gpu = identifyGPUVendor(vendor, renderer);
	const gpuBackend = identifyGPUBackend(vendor, renderer);
	return {
		type: "webgl",
		gpu,
		gpuType: identifyGPUType(vendor, renderer),
		gpuBackend,
		vendor,
		renderer,
		version,
		shadingLanguage: "glsl",
		shadingLanguageVersion: 300
	};
}
/** "Sniff" the GPU type from the info. This works best if unmasked info is available. */
function identifyGPUVendor(vendor, renderer) {
	if (/NVIDIA/i.exec(vendor) || /NVIDIA/i.exec(renderer)) return "nvidia";
	if (/INTEL/i.exec(vendor) || /INTEL/i.exec(renderer)) return "intel";
	if (/Apple/i.exec(vendor) || /Apple/i.exec(renderer)) return "apple";
	if (/AMD/i.exec(vendor) || /AMD/i.exec(renderer) || /ATI/i.exec(vendor) || /ATI/i.exec(renderer)) return "amd";
	if (/SwiftShader/i.exec(vendor) || /SwiftShader/i.exec(renderer)) return "software";
	return "unknown";
}
/** "Sniff" the GPU backend from the info. This works best if unmasked info is available. */
function identifyGPUBackend(vendor, renderer) {
	if (/Metal/i.exec(vendor) || /Metal/i.exec(renderer)) return "metal";
	if (/ANGLE/i.exec(vendor) || /ANGLE/i.exec(renderer)) return "opengl";
	return "unknown";
}
function identifyGPUType(vendor, renderer) {
	if (/SwiftShader/i.exec(vendor) || /SwiftShader/i.exec(renderer)) return "cpu";
	switch (identifyGPUVendor(vendor, renderer)) {
		case "intel": return "integrated";
		case "software": return "cpu";
		case "unknown": return "unknown";
		default: return "discrete";
	}
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/converters/webgl-vertex-formats.js
function getGLFromVertexType(dataType) {
	switch (dataType) {
		case "uint8": return 5121;
		case "sint8": return 5120;
		case "unorm8": return 5121;
		case "snorm8": return 5120;
		case "uint16": return 5123;
		case "sint16": return 5122;
		case "unorm16": return 5123;
		case "snorm16": return 5122;
		case "uint32": return 5125;
		case "sint32": return 5124;
		case "float16": return 5131;
		case "float32": return 5126;
	}
	throw new Error(String(dataType));
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/converters/webgl-texture-table.js
var X_S3TC = "WEBGL_compressed_texture_s3tc";
var X_S3TC_SRGB = "WEBGL_compressed_texture_s3tc_srgb";
var X_RGTC = "EXT_texture_compression_rgtc";
var X_BPTC = "EXT_texture_compression_bptc";
var X_ETC2 = "WEBGL_compressed_texture_etc";
var X_ASTC = "WEBGL_compressed_texture_astc";
var X_ETC1 = "WEBGL_compressed_texture_etc1";
var X_PVRTC = "WEBGL_compressed_texture_pvrtc";
var X_ATC = "WEBGL_compressed_texture_atc";
var EXT_texture_norm16 = "EXT_texture_norm16";
var EXT_render_snorm = "EXT_render_snorm";
var EXT_color_buffer_float = "EXT_color_buffer_float";
const TEXTURE_FEATURES = {
	"float32-renderable-webgl": ["EXT_color_buffer_float"],
	"float16-renderable-webgl": ["EXT_color_buffer_half_float"],
	"rgb9e5ufloat-renderable-webgl": ["WEBGL_render_shared_exponent"],
	"snorm8-renderable-webgl": [EXT_render_snorm],
	"norm16-renderable-webgl": [EXT_texture_norm16],
	"snorm16-renderable-webgl": [EXT_texture_norm16, EXT_render_snorm],
	"float32-filterable": ["OES_texture_float_linear"],
	"float16-filterable-webgl": ["OES_texture_half_float_linear"],
	"texture-filterable-anisotropic-webgl": ["EXT_texture_filter_anisotropic"],
	"texture-blend-float-webgl": ["EXT_float_blend"],
	"texture-compression-bc": [
		X_S3TC,
		X_S3TC_SRGB,
		X_RGTC,
		X_BPTC
	],
	"texture-compression-bc5-webgl": [X_RGTC],
	"texture-compression-bc7-webgl": [X_BPTC],
	"texture-compression-etc2": [X_ETC2],
	"texture-compression-astc": [X_ASTC],
	"texture-compression-etc1-webgl": [X_ETC1],
	"texture-compression-pvrtc-webgl": [X_PVRTC],
	"texture-compression-atc-webgl": [X_ATC]
};
function isTextureFeature(feature) {
	return feature in TEXTURE_FEATURES;
}
/** Checks a texture feature (for Device.features). Mainly compressed texture support */
function checkTextureFeature(gl, feature, extensions) {
	return (TEXTURE_FEATURES[feature] || []).every((extension) => getWebGLExtension(gl, extension, extensions));
}
/**
* Texture format data -
* Exported but can change without notice
*/
const WEBGL_TEXTURE_FORMATS = {
	"r8unorm": {
		gl: 33321,
		rb: true
	},
	"r8snorm": { gl: 36756 },
	"r8uint": {
		gl: 33330,
		rb: true
	},
	"r8sint": {
		gl: 33329,
		rb: true
	},
	"rg8unorm": {
		gl: 33323,
		rb: true
	},
	"rg8snorm": { gl: 36757 },
	"rg8uint": {
		gl: 33336,
		rb: true
	},
	"rg8sint": {
		gl: 33335,
		rb: true
	},
	"r16uint": {
		gl: 33332,
		rb: true
	},
	"r16sint": {
		gl: 33331,
		rb: true
	},
	"r16float": {
		gl: 33325,
		rb: true
	},
	"r16unorm": {
		gl: 33322,
		rb: true
	},
	"r16snorm": { gl: 36760 },
	"rgba4unorm-webgl": {
		gl: 32854,
		rb: true
	},
	"rgb565unorm-webgl": {
		gl: 36194,
		rb: true
	},
	"rgb5a1unorm-webgl": {
		gl: 32855,
		rb: true
	},
	"rgb8unorm-webgl": { gl: 32849 },
	"rgb8snorm-webgl": { gl: 36758 },
	"rgba8unorm": { gl: 32856 },
	"rgba8unorm-srgb": { gl: 35907 },
	"rgba8snorm": { gl: 36759 },
	"rgba8uint": { gl: 36220 },
	"rgba8sint": { gl: 36238 },
	"bgra8unorm": {},
	"bgra8unorm-srgb": {},
	"rg16uint": { gl: 33338 },
	"rg16sint": { gl: 33337 },
	"rg16float": {
		gl: 33327,
		rb: true
	},
	"rg16unorm": { gl: 33324 },
	"rg16snorm": { gl: 36761 },
	"r32uint": {
		gl: 33334,
		rb: true
	},
	"r32sint": {
		gl: 33333,
		rb: true
	},
	"r32float": { gl: 33326 },
	"rgb9e5ufloat": { gl: 35901 },
	"rg11b10ufloat": {
		gl: 35898,
		rb: true
	},
	"rgb10a2unorm": {
		gl: 32857,
		rb: true
	},
	"rgb10a2uint": {
		gl: 36975,
		rb: true
	},
	"rgb16unorm-webgl": { gl: 32852 },
	"rgb16snorm-webgl": { gl: 36762 },
	"rg32uint": {
		gl: 33340,
		rb: true
	},
	"rg32sint": {
		gl: 33339,
		rb: true
	},
	"rg32float": {
		gl: 33328,
		rb: true
	},
	"rgba16uint": {
		gl: 36214,
		rb: true
	},
	"rgba16sint": {
		gl: 36232,
		rb: true
	},
	"rgba16float": { gl: 34842 },
	"rgba16unorm": {
		gl: 32859,
		rb: true
	},
	"rgba16snorm": { gl: 36763 },
	"rgb32float-webgl": {
		gl: 34837,
		x: EXT_color_buffer_float,
		dataFormat: 6407,
		types: [5126]
	},
	"rgba32uint": {
		gl: 36208,
		rb: true
	},
	"rgba32sint": {
		gl: 36226,
		rb: true
	},
	"rgba32float": {
		gl: 34836,
		rb: true
	},
	"stencil8": {
		gl: 36168,
		rb: true
	},
	"depth16unorm": {
		gl: 33189,
		dataFormat: 6402,
		types: [5123],
		rb: true
	},
	"depth24plus": {
		gl: 33190,
		dataFormat: 6402,
		types: [5125]
	},
	"depth32float": {
		gl: 36012,
		dataFormat: 6402,
		types: [5126],
		rb: true
	},
	"depth24plus-stencil8": {
		gl: 35056,
		rb: true,
		depthTexture: true,
		dataFormat: 34041,
		types: [34042]
	},
	"depth32float-stencil8": {
		gl: 36013,
		dataFormat: 34041,
		types: [36269],
		rb: true
	},
	"bc1-rgb-unorm-webgl": {
		gl: 33776,
		x: X_S3TC
	},
	"bc1-rgb-unorm-srgb-webgl": {
		gl: 35916,
		x: X_S3TC_SRGB
	},
	"bc1-rgba-unorm": {
		gl: 33777,
		x: X_S3TC
	},
	"bc1-rgba-unorm-srgb": {
		gl: 35916,
		x: X_S3TC_SRGB
	},
	"bc2-rgba-unorm": {
		gl: 33778,
		x: X_S3TC
	},
	"bc2-rgba-unorm-srgb": {
		gl: 35918,
		x: X_S3TC_SRGB
	},
	"bc3-rgba-unorm": {
		gl: 33779,
		x: X_S3TC
	},
	"bc3-rgba-unorm-srgb": {
		gl: 35919,
		x: X_S3TC_SRGB
	},
	"bc4-r-unorm": {
		gl: 36283,
		x: X_RGTC
	},
	"bc4-r-snorm": {
		gl: 36284,
		x: X_RGTC
	},
	"bc5-rg-unorm": {
		gl: 36285,
		x: X_RGTC
	},
	"bc5-rg-snorm": {
		gl: 36286,
		x: X_RGTC
	},
	"bc6h-rgb-ufloat": {
		gl: 36495,
		x: X_BPTC
	},
	"bc6h-rgb-float": {
		gl: 36494,
		x: X_BPTC
	},
	"bc7-rgba-unorm": {
		gl: 36492,
		x: X_BPTC
	},
	"bc7-rgba-unorm-srgb": {
		gl: 36493,
		x: X_BPTC
	},
	"etc2-rgb8unorm": { gl: 37492 },
	"etc2-rgb8unorm-srgb": { gl: 37494 },
	"etc2-rgb8a1unorm": { gl: 37496 },
	"etc2-rgb8a1unorm-srgb": { gl: 37497 },
	"etc2-rgba8unorm": { gl: 37493 },
	"etc2-rgba8unorm-srgb": { gl: 37495 },
	"eac-r11unorm": { gl: 37488 },
	"eac-r11snorm": { gl: 37489 },
	"eac-rg11unorm": { gl: 37490 },
	"eac-rg11snorm": { gl: 37491 },
	"astc-4x4-unorm": { gl: 37808 },
	"astc-4x4-unorm-srgb": { gl: 37840 },
	"astc-5x4-unorm": { gl: 37809 },
	"astc-5x4-unorm-srgb": { gl: 37841 },
	"astc-5x5-unorm": { gl: 37810 },
	"astc-5x5-unorm-srgb": { gl: 37842 },
	"astc-6x5-unorm": { gl: 37811 },
	"astc-6x5-unorm-srgb": { gl: 37843 },
	"astc-6x6-unorm": { gl: 37812 },
	"astc-6x6-unorm-srgb": { gl: 37844 },
	"astc-8x5-unorm": { gl: 37813 },
	"astc-8x5-unorm-srgb": { gl: 37845 },
	"astc-8x6-unorm": { gl: 37814 },
	"astc-8x6-unorm-srgb": { gl: 37846 },
	"astc-8x8-unorm": { gl: 37815 },
	"astc-8x8-unorm-srgb": { gl: 37847 },
	"astc-10x5-unorm": { gl: 37819 },
	"astc-10x5-unorm-srgb": { gl: 37851 },
	"astc-10x6-unorm": { gl: 37817 },
	"astc-10x6-unorm-srgb": { gl: 37849 },
	"astc-10x8-unorm": { gl: 37818 },
	"astc-10x8-unorm-srgb": { gl: 37850 },
	"astc-10x10-unorm": { gl: 37819 },
	"astc-10x10-unorm-srgb": { gl: 37851 },
	"astc-12x10-unorm": { gl: 37820 },
	"astc-12x10-unorm-srgb": { gl: 37852 },
	"astc-12x12-unorm": { gl: 37821 },
	"astc-12x12-unorm-srgb": { gl: 37853 },
	"pvrtc-rgb4unorm-webgl": { gl: 35840 },
	"pvrtc-rgba4unorm-webgl": { gl: 35842 },
	"pvrtc-rbg2unorm-webgl": { gl: 35841 },
	"pvrtc-rgba2unorm-webgl": { gl: 35843 },
	"etc1-rbg-unorm-webgl": { gl: 36196 },
	"atc-rgb-unorm-webgl": { gl: 35986 },
	"atc-rgba-unorm-webgl": { gl: 35986 },
	"atc-rgbai-unorm-webgl": { gl: 34798 }
};
/** Checks if a texture format is supported, renderable, filterable etc */
function getTextureFormatCapabilitiesWebGL(gl, formatSupport, extensions) {
	let supported = formatSupport.create;
	const webglFormatInfo = WEBGL_TEXTURE_FORMATS[formatSupport.format];
	if (webglFormatInfo?.gl === void 0) supported = false;
	if (webglFormatInfo?.x) supported = supported && Boolean(getWebGLExtension(gl, webglFormatInfo.x, extensions));
	return {
		format: formatSupport.format,
		create: supported && formatSupport.create,
		render: supported && formatSupport.render,
		filter: supported && formatSupport.filter,
		blend: supported && formatSupport.blend,
		store: supported && formatSupport.store
	};
}
/** Get parameters necessary to work with format in WebGL: internalFormat, dataFormat, type, compressed, */
function getTextureFormatWebGL(format) {
	const formatData = WEBGL_TEXTURE_FORMATS[format];
	const webglFormat = convertTextureFormatToGL(format);
	const decoded = textureFormatDecoder.getInfo(format);
	if (decoded.compressed) formatData.dataFormat = webglFormat;
	return {
		internalFormat: webglFormat,
		format: formatData?.dataFormat || getWebGLPixelDataFormat(decoded.channels, decoded.integer, decoded.normalized, webglFormat),
		type: decoded.dataType ? getGLFromVertexType(decoded.dataType) : formatData?.types?.[0] || 5121,
		compressed: decoded.compressed || false
	};
}
function getDepthStencilAttachmentWebGL(format) {
	switch (textureFormatDecoder.getInfo(format).attachment) {
		case "depth": return 36096;
		case "stencil": return 36128;
		case "depth-stencil": return 33306;
		default: throw new Error(`Not a depth stencil format: ${format}`);
	}
}
function getWebGLPixelDataFormat(channels, integer, normalized, format) {
	if (format === 6408 || format === 6407) return format;
	switch (channels) {
		case "r": return integer && !normalized ? 36244 : 6403;
		case "rg": return integer && !normalized ? 33320 : 33319;
		case "rgb": return integer && !normalized ? 36248 : 6407;
		case "rgba": return integer && !normalized ? 36249 : 6408;
		case "bgra": throw new Error("bgra pixels not supported by WebGL");
		default: return 6408;
	}
}
/**
* Map WebGPU style texture format strings to GL constants
*/
function convertTextureFormatToGL(format) {
	const webglFormat = WEBGL_TEXTURE_FORMATS[format]?.gl;
	if (webglFormat === void 0) throw new Error(`Unsupported texture format ${format}`);
	return webglFormat;
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/device-helpers/webgl-device-features.js
/**
* Defines luma.gl "feature" names and semantics
* when value is 'string' it is the name of the extension that enables this feature
*/
var WEBGL_FEATURES = {
	"depth-clip-control": "EXT_depth_clamp",
	"timer-query-webgl": "EXT_disjoint_timer_query_webgl2",
	"compilation-status-async-webgl": "KHR_parallel_shader_compile",
	"polygon-mode-webgl": "WEBGL_polygon_mode",
	"provoking-vertex-webgl": "WEBGL_provoking_vertex",
	"shader-clip-cull-distance-webgl": "WEBGL_clip_cull_distance",
	"shader-noperspective-interpolation-webgl": "NV_shader_noperspective_interpolation",
	"shader-conservative-depth-webgl": "EXT_conservative_depth"
};
/**
* WebGL extensions exposed as luma.gl features
* To minimize GL log noise and improve performance, this class ensures that
* - WebGL extensions are not queried until the corresponding feature is checked.
* - WebGL extensions are only queried once.
*/
var WebGLDeviceFeatures = class extends DeviceFeatures {
	gl;
	extensions;
	testedFeatures = /* @__PURE__ */ new Set();
	constructor(gl, extensions, disabledFeatures) {
		super([], disabledFeatures);
		this.gl = gl;
		this.extensions = extensions;
		getWebGLExtension(gl, "EXT_color_buffer_float", extensions);
	}
	*[Symbol.iterator]() {
		const features = this.getFeatures();
		for (const feature of features) if (this.has(feature)) yield feature;
		return [];
	}
	has(feature) {
		if (this.disabledFeatures?.[feature]) return false;
		if (!this.testedFeatures.has(feature)) {
			this.testedFeatures.add(feature);
			if (isTextureFeature(feature) && checkTextureFeature(this.gl, feature, this.extensions)) this.features.add(feature);
			if (this.getWebGLFeature(feature)) this.features.add(feature);
		}
		return this.features.has(feature);
	}
	initializeFeatures() {
		const features = this.getFeatures().filter((feature) => feature !== "polygon-mode-webgl");
		for (const feature of features) this.has(feature);
	}
	getFeatures() {
		return [...Object.keys(WEBGL_FEATURES), ...Object.keys(TEXTURE_FEATURES)];
	}
	/** Extract all WebGL features */
	getWebGLFeature(feature) {
		const featureInfo = WEBGL_FEATURES[feature];
		return typeof featureInfo === "string" ? Boolean(getWebGLExtension(this.gl, featureInfo, this.extensions)) : Boolean(featureInfo);
	}
};

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/device-helpers/webgl-device-limits.js
var WebGLDeviceLimits = class extends DeviceLimits {
	get maxTextureDimension1D() {
		return 0;
	}
	get maxTextureDimension2D() {
		return this.getParameter(3379);
	}
	get maxTextureDimension3D() {
		return this.getParameter(32883);
	}
	get maxTextureArrayLayers() {
		return this.getParameter(35071);
	}
	get maxBindGroups() {
		return 0;
	}
	get maxDynamicUniformBuffersPerPipelineLayout() {
		return 0;
	}
	get maxDynamicStorageBuffersPerPipelineLayout() {
		return 0;
	}
	get maxSampledTexturesPerShaderStage() {
		return this.getParameter(35660);
	}
	get maxSamplersPerShaderStage() {
		return this.getParameter(35661);
	}
	get maxStorageBuffersPerShaderStage() {
		return 0;
	}
	get maxStorageTexturesPerShaderStage() {
		return 0;
	}
	get maxUniformBuffersPerShaderStage() {
		return this.getParameter(35375);
	}
	get maxUniformBufferBindingSize() {
		return this.getParameter(35376);
	}
	get maxStorageBufferBindingSize() {
		return 0;
	}
	get minUniformBufferOffsetAlignment() {
		return this.getParameter(35380);
	}
	get minStorageBufferOffsetAlignment() {
		return 0;
	}
	get maxVertexBuffers() {
		return 16;
	}
	get maxVertexAttributes() {
		return this.getParameter(34921);
	}
	get maxVertexBufferArrayStride() {
		return 2048;
	}
	get maxInterStageShaderVariables() {
		return this.getParameter(35659);
	}
	get maxComputeWorkgroupStorageSize() {
		return 0;
	}
	get maxComputeInvocationsPerWorkgroup() {
		return 0;
	}
	get maxComputeWorkgroupSizeX() {
		return 0;
	}
	get maxComputeWorkgroupSizeY() {
		return 0;
	}
	get maxComputeWorkgroupSizeZ() {
		return 0;
	}
	get maxComputeWorkgroupsPerDimension() {
		return 0;
	}
	gl;
	limits = {};
	constructor(gl) {
		super();
		this.gl = gl;
	}
	getParameter(parameter) {
		if (this.limits[parameter] === void 0) this.limits[parameter] = this.gl.getParameter(parameter);
		return this.limits[parameter] || 0;
	}
};

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/resources/webgl-framebuffer.js
/** luma.gl Framebuffer, WebGL implementation  */
var WEBGLFramebuffer = class extends Framebuffer {
	device;
	gl;
	handle;
	colorAttachments = [];
	depthStencilAttachment = null;
	constructor(device, props) {
		super(device, props);
		const isDefaultFramebuffer = props.handle === null;
		this.device = device;
		this.gl = device.gl;
		this.handle = this.props.handle || isDefaultFramebuffer ? this.props.handle : this.gl.createFramebuffer();
		if (!isDefaultFramebuffer) {
			device._setWebGLDebugMetadata(this.handle, this, { spector: this.props });
			this.autoCreateAttachmentTextures();
			this.updateAttachments();
		}
	}
	/** destroys any auto created resources etc. */
	destroy() {
		super.destroy();
		if (!this.destroyed && this.handle !== null) this.gl.deleteFramebuffer(this.handle);
	}
	updateAttachments() {
		/** Attach from a map of attachments */
		const prevHandle = this.gl.bindFramebuffer(36160, this.handle);
		for (let i = 0; i < this.colorAttachments.length; ++i) {
			const attachment = this.colorAttachments[i];
			if (attachment) {
				const attachmentPoint = 36064 + i;
				this._attachTextureView(attachmentPoint, attachment);
			}
		}
		if (this.depthStencilAttachment) {
			const attachmentPoint = getDepthStencilAttachmentWebGL(this.depthStencilAttachment.props.format);
			this._attachTextureView(attachmentPoint, this.depthStencilAttachment);
		}
		/** Check the status */
		if (this.device.props.debug) {
			const status = this.gl.checkFramebufferStatus(36160);
			if (status !== 36053) throw new Error(`Framebuffer ${_getFrameBufferStatus(status)}`);
		}
		this.gl.bindFramebuffer(36160, prevHandle);
	}
	/** In WebGL we must use renderbuffers for depth/stencil attachments (unless we have extensions) */
	/**
	* @param attachment
	* @param texture
	* @param layer = 0 - index into WEBGLTextureArray and Texture3D or face for `TextureCubeMap`
	* @param level = 0 - mipmapLevel
	*/
	_attachTextureView(attachment, textureView) {
		const { gl } = this.device;
		const { texture } = textureView;
		const level = textureView.props.baseMipLevel;
		const layer = textureView.props.baseArrayLayer;
		gl.bindTexture(texture.glTarget, texture.handle);
		switch (texture.glTarget) {
			case 35866:
			case 32879:
				gl.framebufferTextureLayer(36160, attachment, texture.handle, level, layer);
				break;
			case 34067:
				const face = mapIndexToCubeMapFace(layer);
				gl.framebufferTexture2D(36160, attachment, face, texture.handle, level);
				break;
			case 3553:
				gl.framebufferTexture2D(36160, attachment, 3553, texture.handle, level);
				break;
			default: throw new Error("Illegal texture type");
		}
		gl.bindTexture(texture.glTarget, null);
	}
};
function mapIndexToCubeMapFace(layer) {
	return layer < 34069 ? layer + 34069 : layer;
}
function _getFrameBufferStatus(status) {
	switch (status) {
		case 36053: return "success";
		case 36054: return "Mismatched attachments";
		case 36055: return "No attachments";
		case 36057: return "Height/width mismatch";
		case 36061: return "Unsupported or split attachments";
		case 36182: return "Samples mismatch";
		default: return `${status}`;
	}
}
/**
* Attachment resize is expected to be a noop if size is same
*
protected override resizeAttachments(width: number, height: number): this {
// for default framebuffer, just update the stored size
if (this.handle === null) {
// assert(width === undefined && height === undefined);
this.width = this.gl.drawingBufferWidth;
this.height = this.gl.drawingBufferHeight;
return this;
}

if (width === undefined) {
width = this.gl.drawingBufferWidth;
}
if (height === undefined) {
height = this.gl.drawingBufferHeight;
}

// TODO Not clear that this is better than default destroy/create implementation

for (const colorAttachment of this.colorAttachments) {
colorAttachment.texture.clone({width, height});
}
if (this.depthStencilAttachment) {
this.depthStencilAttachment.texture.resize({width, height});
}
return this;
}
*/

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/webgl-canvas-context.js
/**
* A WebGL Canvas Context which manages the canvas and handles drawing buffer resizing etc
*/
var WebGLCanvasContext = class extends CanvasContext {
	device;
	handle = null;
	_framebuffer = null;
	get [Symbol.toStringTag]() {
		return "WebGLCanvasContext";
	}
	constructor(device, props) {
		super(props);
		this.device = device;
		this._setAutoCreatedCanvasId(`${this.device.id}-canvas`);
		this._updateDevice();
	}
	getCurrentFramebuffer() {
		this._framebuffer = this._framebuffer || new WEBGLFramebuffer(this.device, { handle: null });
		return this._framebuffer;
	}
	_updateDevice() {}
};

//#endregion
//#region node_modules/@luma.gl/webgl/dist/utils/uid.js
var uidCounters = {};
/**
* Returns a UID.
* @param id= - Identifier base name
* @return uid
**/
function uid(id = "id") {
	uidCounters[id] = uidCounters[id] || 1;
	return `${id}-${uidCounters[id]++}`;
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/resources/webgl-buffer.js
/** WebGL Buffer interface */
var WEBGLBuffer = class extends Buffer {
	device;
	gl;
	handle;
	/** Target in OpenGL defines the type of buffer */
	glTarget;
	/** Usage is a hint on how frequently the buffer will be updates */
	glUsage;
	/** Index type is needed when issuing draw calls, so we pre-compute it */
	glIndexType = 5123;
	/** Number of bytes allocated on the GPU for this buffer */
	byteLength = 0;
	/** Number of bytes used */
	bytesUsed = 0;
	constructor(device, props = {}) {
		super(device, props);
		this.device = device;
		this.gl = this.device.gl;
		this.handle = (typeof props === "object" ? props.handle : void 0) || this.gl.createBuffer();
		device._setWebGLDebugMetadata(this.handle, this, { spector: {
			...this.props,
			data: typeof this.props.data
		} });
		this.glTarget = getWebGLTarget(this.props.usage);
		this.glUsage = getWebGLUsage(this.props.usage);
		this.glIndexType = this.props.indexType === "uint32" ? 5125 : 5123;
		if (props.data) this._initWithData(props.data, props.byteOffset, props.byteLength);
		else this._initWithByteLength(props.byteLength || 0);
	}
	destroy() {
		if (!this.destroyed && this.handle) {
			this.removeStats();
			this.trackDeallocatedMemory();
			this.gl.deleteBuffer(this.handle);
			this.destroyed = true;
			this.handle = null;
		}
	}
	/** Allocate a new buffer and initialize to contents of typed array */
	_initWithData(data, byteOffset = 0, byteLength = data.byteLength + byteOffset) {
		const glTarget = this.glTarget;
		this.gl.bindBuffer(glTarget, this.handle);
		this.gl.bufferData(glTarget, byteLength, this.glUsage);
		this.gl.bufferSubData(glTarget, byteOffset, data);
		this.gl.bindBuffer(glTarget, null);
		this.bytesUsed = byteLength;
		this.byteLength = byteLength;
		this._setDebugData(data, byteOffset, byteLength);
		this.trackAllocatedMemory(byteLength);
	}
	_initWithByteLength(byteLength) {
		let data = byteLength;
		if (byteLength === 0) data = new Float32Array(0);
		const glTarget = this.glTarget;
		this.gl.bindBuffer(glTarget, this.handle);
		this.gl.bufferData(glTarget, data, this.glUsage);
		this.gl.bindBuffer(glTarget, null);
		this.bytesUsed = byteLength;
		this.byteLength = byteLength;
		this._setDebugData(null, 0, byteLength);
		this.trackAllocatedMemory(byteLength);
		return this;
	}
	write(data, byteOffset = 0) {
		const dataView = ArrayBuffer.isView(data) ? data : new Uint8Array(data);
		const srcOffset = 0;
		const byteLength = void 0;
		const glTarget = 36663;
		this.gl.bindBuffer(glTarget, this.handle);
		if (srcOffset !== 0 || byteLength !== void 0) this.gl.bufferSubData(glTarget, byteOffset, dataView, srcOffset, byteLength);
		else this.gl.bufferSubData(glTarget, byteOffset, dataView);
		this.gl.bindBuffer(glTarget, null);
		this._setDebugData(data, byteOffset, data.byteLength);
	}
	async mapAndWriteAsync(callback, byteOffset = 0, byteLength = this.byteLength - byteOffset) {
		const arrayBuffer$1 = new ArrayBuffer(byteLength);
		await callback(arrayBuffer$1, "copied");
		this.write(arrayBuffer$1, byteOffset);
	}
	async readAsync(byteOffset = 0, byteLength) {
		return this.readSyncWebGL(byteOffset, byteLength);
	}
	async mapAndReadAsync(callback, byteOffset = 0, byteLength) {
		return await callback((await this.readAsync(byteOffset, byteLength)).buffer, "copied");
	}
	readSyncWebGL(byteOffset = 0, byteLength) {
		byteLength = byteLength ?? this.byteLength - byteOffset;
		const data = new Uint8Array(byteLength);
		const dstOffset = 0;
		this.gl.bindBuffer(36662, this.handle);
		this.gl.getBufferSubData(36662, byteOffset, data, dstOffset, byteLength);
		this.gl.bindBuffer(36662, null);
		this._setDebugData(data, byteOffset, byteLength);
		return data;
	}
};
/**
* Returns a WebGL buffer target
*
* @param usage
* static MAP_READ = 0x01;
* static MAP_WRITE = 0x02;
* static COPY_SRC = 0x0004;
* static COPY_DST = 0x0008;
* static INDEX = 0x0010;
* static VERTEX = 0x0020;
* static UNIFORM = 0x0040;
* static STORAGE = 0x0080;
* static INDIRECT = 0x0100;
* static QUERY_RESOLVE = 0x0200;
*
* @returns WebGL buffer targe
*
* Buffer bind points in WebGL2
* gl.COPY_READ_BUFFER: Buffer for copying from one buffer object to another.
* gl.COPY_WRITE_BUFFER: Buffer for copying from one buffer object to another.
* gl.TRANSFORM_FEEDBACK_BUFFER: Buffer for transform feedback operations.
* gl.PIXEL_PACK_BUFFER: Buffer used for pixel transfer operations.
* gl.PIXEL_UNPACK_BUFFER: Buffer used for pixel transfer operations.
*/
function getWebGLTarget(usage) {
	if (usage & Buffer.INDEX) return 34963;
	if (usage & Buffer.VERTEX) return 34962;
	if (usage & Buffer.UNIFORM) return 35345;
	return 34962;
}
/** @todo usage is not passed correctly */
function getWebGLUsage(usage) {
	if (usage & Buffer.INDEX) return 35044;
	if (usage & Buffer.VERTEX) return 35044;
	if (usage & Buffer.UNIFORM) return 35048;
	return 35044;
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/helpers/parse-shader-compiler-log.js
/**
* Parse a WebGL-format GLSL compilation log into an array of WebGPU style message records.
* This follows documented WebGL conventions for compilation logs.
* Based on https://github.com/wwwtyro/gl-format-compiler-error (public domain)
*/
function parseShaderCompilerLog(errLog) {
	const lines = errLog.split(/\r?\n/);
	const messages = [];
	for (const line of lines) {
		if (line.length <= 1) continue;
		const segments = line.split(":");
		if (segments.length === 2) {
			const [messageType$1, message$1] = segments;
			messages.push({
				message: message$1.trim(),
				type: getMessageType(messageType$1),
				lineNum: 0,
				linePos: 0
			});
			continue;
		}
		const [messageType, linePosition, lineNumber, ...rest] = segments;
		let lineNum = parseInt(lineNumber, 10);
		if (isNaN(lineNum)) lineNum = 0;
		let linePos = parseInt(linePosition, 10);
		if (isNaN(linePos)) linePos = 0;
		messages.push({
			message: rest.join(":").trim(),
			type: getMessageType(messageType),
			lineNum,
			linePos
		});
	}
	return messages;
}
/** Ensure supported type */
function getMessageType(messageType) {
	const MESSAGE_TYPES = [
		"warning",
		"error",
		"info"
	];
	const lowerCaseType = messageType.toLowerCase();
	return MESSAGE_TYPES.includes(lowerCaseType) ? lowerCaseType : "info";
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/resources/webgl-shader.js
/**
* An immutable compiled shader program that execute portions of the GPU Pipeline
*/
var WEBGLShader = class extends Shader {
	device;
	handle;
	constructor(device, props) {
		super(device, props);
		this.device = device;
		switch (this.props.stage) {
			case "vertex":
				this.handle = this.props.handle || this.device.gl.createShader(35633);
				break;
			case "fragment":
				this.handle = this.props.handle || this.device.gl.createShader(35632);
				break;
			default: throw new Error(this.props.stage);
		}
		device._setWebGLDebugMetadata(this.handle, this, { spector: this.props });
		this._compile(this.source);
	}
	destroy() {
		if (this.handle) {
			this.removeStats();
			this.device.gl.deleteShader(this.handle);
			this.destroyed = true;
			this.handle.destroyed = true;
		}
	}
	get asyncCompilationStatus() {
		return this._waitForCompilationComplete().then(() => {
			this._getCompilationStatus();
			return this.compilationStatus;
		});
	}
	async getCompilationInfo() {
		await this._waitForCompilationComplete();
		return this.getCompilationInfoSync();
	}
	getCompilationInfoSync() {
		const shaderLog = this.device.gl.getShaderInfoLog(this.handle);
		return shaderLog ? parseShaderCompilerLog(shaderLog) : [];
	}
	getTranslatedSource() {
		return this.device.getExtension("WEBGL_debug_shaders").WEBGL_debug_shaders?.getTranslatedShaderSource(this.handle) || null;
	}
	/** Compile a shader and get compilation status */
	async _compile(source) {
		source = source.startsWith("#version ") ? source : `#version 300 es\n${source}`;
		const { gl } = this.device;
		gl.shaderSource(this.handle, source);
		gl.compileShader(this.handle);
		if (!this.device.props.debug) {
			this.compilationStatus = "pending";
			return;
		}
		if (!this.device.features.has("compilation-status-async-webgl")) {
			this._getCompilationStatus();
			this.debugShader();
			if (this.compilationStatus === "error") throw new Error(`GLSL compilation errors in ${this.props.stage} shader ${this.props.id}`);
			return;
		}
		log.once(1, "Shader compilation is asynchronous")();
		await this._waitForCompilationComplete();
		log.info(2, `Shader ${this.id} - async compilation complete: ${this.compilationStatus}`)();
		this._getCompilationStatus();
		this.debugShader();
	}
	/** Use KHR_parallel_shader_compile extension if available */
	async _waitForCompilationComplete() {
		const waitMs = async (ms) => await new Promise((resolve) => setTimeout(resolve, ms));
		const DELAY_MS = 10;
		if (!this.device.features.has("compilation-status-async-webgl")) {
			await waitMs(DELAY_MS);
			return;
		}
		const { gl } = this.device;
		for (;;) {
			if (gl.getShaderParameter(this.handle, 37297)) return;
			await waitMs(DELAY_MS);
		}
	}
	/**
	* Get the shader compilation status
	* TODO - Load log even when no error reported, to catch warnings?
	* https://gamedev.stackexchange.com/questions/30429/how-to-detect-glsl-warnings
	*/
	_getCompilationStatus() {
		this.compilationStatus = this.device.gl.getShaderParameter(this.handle, 35713) ? "success" : "error";
	}
};

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/converters/device-parameters.js
/**
* Execute a function with a set of temporary WebGL parameter overrides
* - Saves current "global" WebGL context settings
* - Sets the supplies WebGL context parameters,
* - Executes supplied function
* - Restores parameters
* - Returns the return value of the supplied function
*/
function withDeviceAndGLParameters(device, parameters, glParameters, func) {
	if (isObjectEmpty$1(parameters)) return func(device);
	const webglDevice = device;
	webglDevice.pushState();
	try {
		setDeviceParameters(device, parameters);
		setGLParameters(webglDevice.gl, glParameters);
		return func(device);
	} finally {
		webglDevice.popState();
	}
}
/** Set WebGPU Style Parameters */
function setDeviceParameters(device, parameters) {
	const webglDevice = device;
	const { gl } = webglDevice;
	if (parameters.cullMode) switch (parameters.cullMode) {
		case "none":
			gl.disable(2884);
			break;
		case "front":
			gl.enable(2884);
			gl.cullFace(1028);
			break;
		case "back":
			gl.enable(2884);
			gl.cullFace(1029);
			break;
	}
	if (parameters.frontFace) gl.frontFace(map("frontFace", parameters.frontFace, {
		ccw: 2305,
		cw: 2304
	}));
	if (parameters.unclippedDepth) {
		if (device.features.has("depth-clip-control")) gl.enable(34383);
	}
	if (parameters.depthBias !== void 0) {
		gl.enable(32823);
		gl.polygonOffset(parameters.depthBias, parameters.depthBiasSlopeScale || 0);
	}
	if (parameters.provokingVertex) {
		if (device.features.has("provoking-vertex-webgl")) {
			const ext = webglDevice.getExtension("WEBGL_provoking_vertex").WEBGL_provoking_vertex;
			const vertex = map("provokingVertex", parameters.provokingVertex, {
				first: 36429,
				last: 36430
			});
			ext?.provokingVertexWEBGL(vertex);
		}
	}
	if (parameters.polygonMode || parameters.polygonOffsetLine) {
		if (device.features.has("polygon-mode-webgl")) {
			if (parameters.polygonMode) {
				const ext = webglDevice.getExtension("WEBGL_polygon_mode").WEBGL_polygon_mode;
				const mode = map("polygonMode", parameters.polygonMode, {
					fill: 6914,
					line: 6913
				});
				ext?.polygonModeWEBGL(1028, mode);
				ext?.polygonModeWEBGL(1029, mode);
			}
			if (parameters.polygonOffsetLine) gl.enable(10754);
		}
	}
	if (device.features.has("shader-clip-cull-distance-webgl")) {
		if (parameters.clipDistance0) gl.enable(12288);
		if (parameters.clipDistance1) gl.enable(12289);
		if (parameters.clipDistance2) gl.enable(12290);
		if (parameters.clipDistance3) gl.enable(12291);
		if (parameters.clipDistance4) gl.enable(12292);
		if (parameters.clipDistance5) gl.enable(12293);
		if (parameters.clipDistance6) gl.enable(12294);
		if (parameters.clipDistance7) gl.enable(12295);
	}
	if (parameters.depthWriteEnabled !== void 0) gl.depthMask(mapBoolean("depthWriteEnabled", parameters.depthWriteEnabled));
	if (parameters.depthCompare) {
		parameters.depthCompare !== "always" ? gl.enable(2929) : gl.disable(2929);
		gl.depthFunc(convertCompareFunction("depthCompare", parameters.depthCompare));
	}
	if (parameters.stencilWriteMask) {
		const mask = parameters.stencilWriteMask;
		gl.stencilMaskSeparate(1028, mask);
		gl.stencilMaskSeparate(1029, mask);
	}
	if (parameters.stencilReadMask) log.warn("stencilReadMask not supported under WebGL");
	if (parameters.stencilCompare) {
		const mask = parameters.stencilReadMask || 4294967295;
		const glValue = convertCompareFunction("depthCompare", parameters.stencilCompare);
		parameters.stencilCompare !== "always" ? gl.enable(2960) : gl.disable(2960);
		gl.stencilFuncSeparate(1028, glValue, 0, mask);
		gl.stencilFuncSeparate(1029, glValue, 0, mask);
	}
	if (parameters.stencilPassOperation && parameters.stencilFailOperation && parameters.stencilDepthFailOperation) {
		const dppass = convertStencilOperation("stencilPassOperation", parameters.stencilPassOperation);
		const sfail = convertStencilOperation("stencilFailOperation", parameters.stencilFailOperation);
		const dpfail = convertStencilOperation("stencilDepthFailOperation", parameters.stencilDepthFailOperation);
		gl.stencilOpSeparate(1028, sfail, dpfail, dppass);
		gl.stencilOpSeparate(1029, sfail, dpfail, dppass);
	}
	switch (parameters.blend) {
		case true:
			gl.enable(3042);
			break;
		case false:
			gl.disable(3042);
			break;
		default:
	}
	if (parameters.blendColorOperation || parameters.blendAlphaOperation) {
		const colorEquation = convertBlendOperationToEquation("blendColorOperation", parameters.blendColorOperation || "add");
		const alphaEquation = convertBlendOperationToEquation("blendAlphaOperation", parameters.blendAlphaOperation || "add");
		gl.blendEquationSeparate(colorEquation, alphaEquation);
		const colorSrcFactor = convertBlendFactorToFunction("blendColorSrcFactor", parameters.blendColorSrcFactor || "one");
		const colorDstFactor = convertBlendFactorToFunction("blendColorDstFactor", parameters.blendColorDstFactor || "zero");
		const alphaSrcFactor = convertBlendFactorToFunction("blendAlphaSrcFactor", parameters.blendAlphaSrcFactor || "one");
		const alphaDstFactor = convertBlendFactorToFunction("blendAlphaDstFactor", parameters.blendAlphaDstFactor || "zero");
		gl.blendFuncSeparate(colorSrcFactor, colorDstFactor, alphaSrcFactor, alphaDstFactor);
	}
}
function convertCompareFunction(parameter, value) {
	return map(parameter, value, {
		never: 512,
		less: 513,
		equal: 514,
		"less-equal": 515,
		greater: 516,
		"not-equal": 517,
		"greater-equal": 518,
		always: 519
	});
}
function convertStencilOperation(parameter, value) {
	return map(parameter, value, {
		keep: 7680,
		zero: 0,
		replace: 7681,
		invert: 5386,
		"increment-clamp": 7682,
		"decrement-clamp": 7683,
		"increment-wrap": 34055,
		"decrement-wrap": 34056
	});
}
function convertBlendOperationToEquation(parameter, value) {
	return map(parameter, value, {
		add: 32774,
		subtract: 32778,
		"reverse-subtract": 32779,
		min: 32775,
		max: 32776
	});
}
function convertBlendFactorToFunction(parameter, value, type = "color") {
	return map(parameter, value, {
		one: 1,
		zero: 0,
		src: 768,
		"one-minus-src": 769,
		dst: 774,
		"one-minus-dst": 775,
		"src-alpha": 770,
		"one-minus-src-alpha": 771,
		"dst-alpha": 772,
		"one-minus-dst-alpha": 773,
		"src-alpha-saturated": 776,
		constant: type === "color" ? 32769 : 32771,
		"one-minus-constant": type === "color" ? 32770 : 32772,
		src1: 768,
		"one-minus-src1": 769,
		"src1-alpha": 770,
		"one-minus-src1-alpha": 771
	});
}
function message(parameter, value) {
	return `Illegal parameter ${value} for ${parameter}`;
}
function map(parameter, value, valueMap) {
	if (!(value in valueMap)) throw new Error(message(parameter, value));
	return valueMap[value];
}
function mapBoolean(parameter, value) {
	return value;
}
/** Returns true if given object is empty, false otherwise. */
function isObjectEmpty$1(obj) {
	let isEmpty = true;
	for (const key in obj) {
		isEmpty = false;
		break;
	}
	return isEmpty;
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/converters/sampler-parameters.js
/**
* Convert WebGPU-style sampler props to WebGL
* @param props
* @returns
*/
function convertSamplerParametersToWebGL(props) {
	const params = {};
	if (props.addressModeU) params[10242] = convertAddressMode(props.addressModeU);
	if (props.addressModeV) params[10243] = convertAddressMode(props.addressModeV);
	if (props.addressModeW) params[32882] = convertAddressMode(props.addressModeW);
	if (props.magFilter) params[10240] = convertMaxFilterMode(props.magFilter);
	if (props.minFilter || props.mipmapFilter) params[10241] = convertMinFilterMode(props.minFilter || "linear", props.mipmapFilter);
	if (props.lodMinClamp !== void 0) params[33082] = props.lodMinClamp;
	if (props.lodMaxClamp !== void 0) params[33083] = props.lodMaxClamp;
	if (props.type === "comparison-sampler") params[34892] = 34894;
	if (props.compare) params[34893] = convertCompareFunction("compare", props.compare);
	if (props.maxAnisotropy) params[34046] = props.maxAnisotropy;
	return params;
}
/** Convert address more */
function convertAddressMode(addressMode) {
	switch (addressMode) {
		case "clamp-to-edge": return 33071;
		case "repeat": return 10497;
		case "mirror-repeat": return 33648;
	}
}
function convertMaxFilterMode(maxFilter) {
	switch (maxFilter) {
		case "nearest": return 9728;
		case "linear": return 9729;
	}
}
/**
* WebGPU has separate min filter and mipmap filter,
* WebGL is combined and effectively offers 6 options
*/
function convertMinFilterMode(minFilter, mipmapFilter = "none") {
	if (!mipmapFilter) return convertMaxFilterMode(minFilter);
	switch (mipmapFilter) {
		case "none": return convertMaxFilterMode(minFilter);
		case "nearest":
			switch (minFilter) {
				case "nearest": return 9984;
				case "linear": return 9985;
			}
			break;
		case "linear": switch (minFilter) {
			case "nearest": return 9986;
			case "linear": return 9987;
		}
	}
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/resources/webgl-sampler.js
/**
* Sampler object -
* so that they can be set directly on the texture
* https://github.com/WebGLSamples/WebGL2Samples/blob/master/samples/sampler_object.html
*/
var WEBGLSampler = class extends Sampler {
	device;
	handle;
	parameters;
	constructor(device, props) {
		super(device, props);
		this.device = device;
		this.parameters = convertSamplerParametersToWebGL(props);
		this.handle = props.handle || this.device.gl.createSampler();
		this._setSamplerParameters(this.parameters);
	}
	destroy() {
		if (this.handle) {
			this.device.gl.deleteSampler(this.handle);
			this.handle = void 0;
		}
	}
	toString() {
		return `Sampler(${this.id},${JSON.stringify(this.props)})`;
	}
	/** Set sampler parameters on the sampler */
	_setSamplerParameters(parameters) {
		for (const [pname, value] of Object.entries(parameters)) {
			const param = Number(pname);
			switch (param) {
				case 33082:
				case 33083:
					this.device.gl.samplerParameterf(this.handle, param, value);
					break;
				default:
					this.device.gl.samplerParameteri(this.handle, param, value);
					break;
			}
		}
	}
};

//#endregion
//#region node_modules/@luma.gl/webgl/dist/context/state-tracker/with-parameters.js
/**
* Execute a function with a set of temporary WebGL parameter overrides
* - Saves current "global" WebGL context settings
* - Sets the supplies WebGL context parameters,
* - Executes supplied function
* - Restores parameters
* - Returns the return value of the supplied function
*/
function withGLParameters(gl, parameters, func) {
	if (isObjectEmpty(parameters)) return func(gl);
	const { nocatch = true } = parameters;
	const webglState = WebGLStateTracker.get(gl);
	webglState.push();
	setGLParameters(gl, parameters);
	let value;
	if (nocatch) {
		value = func(gl);
		webglState.pop();
	} else try {
		value = func(gl);
	} finally {
		webglState.pop();
	}
	return value;
}
function isObjectEmpty(object) {
	for (const key in object) return false;
	return true;
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/resources/webgl-texture-view.js
var WEBGLTextureView = class extends TextureView {
	device;
	gl;
	handle;
	texture;
	constructor(device, props) {
		super(device, {
			...Texture.defaultProps,
			...props
		});
		this.device = device;
		this.gl = this.device.gl;
		this.handle = null;
		this.texture = props.texture;
	}
};

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/resources/webgl-texture.js
/**
* WebGL... the texture API from hell... hopefully made simpler
*/
var WEBGLTexture = class extends Texture {
	device;
	gl;
	handle;
	sampler = void 0;
	view;
	/**
	* The WebGL target corresponding to the texture type
	* @note `target` cannot be modified by bind:
	* textures are special because when you first bind them to a target,
	* When you first bind a texture as a GL_TEXTURE_2D, you are saying that this texture is a 2D texture.
	* And it will always be a 2D texture; this state cannot be changed ever.
	* A texture that was first bound as a GL_TEXTURE_2D, must always be bound as a GL_TEXTURE_2D;
	* attempting to bind it as GL_TEXTURE_3D will give rise to a run-time error
	*/
	glTarget;
	/** The WebGL format - essentially channel structure */
	glFormat;
	/** The WebGL data format - the type of each channel */
	glType;
	/** The WebGL constant corresponding to the WebGPU style constant in format */
	glInternalFormat;
	/** Whether the internal format is compressed */
	compressed;
	/** Texture binding slot - TODO - move to texture view? */
	_textureUnit = 0;
	constructor(device, props) {
		super(device, props);
		this.device = device;
		this.gl = this.device.gl;
		const formatInfo = getTextureFormatWebGL(this.props.format);
		this.glTarget = getWebGLTextureTarget(this.props.dimension);
		this.glInternalFormat = formatInfo.internalFormat;
		this.glFormat = formatInfo.format;
		this.glType = formatInfo.type;
		this.compressed = formatInfo.compressed;
		this.handle = this.props.handle || this.gl.createTexture();
		this.device._setWebGLDebugMetadata(this.handle, this, { spector: this.props });
		/**
		* Use WebGL immutable texture storage to allocate and clear texture memory.
		* - texStorage2D should be considered a preferred alternative to texImage2D. It may have lower memory costs than texImage2D in some implementations.
		* - Once texStorage*D has been called, the texture is immutable and can only be updated with texSubImage*(), not texImage()
		* @see https://registry.khronos.org/webgl/specs/latest/2.0/ WebGL 2 spec section 3.7.6
		*/
		this.gl.bindTexture(this.glTarget, this.handle);
		const { dimension, width, height, depth, mipLevels, glTarget, glInternalFormat } = this;
		switch (dimension) {
			case "2d":
			case "cube":
				this.gl.texStorage2D(glTarget, mipLevels, glInternalFormat, width, height);
				break;
			case "2d-array":
			case "3d":
				this.gl.texStorage3D(glTarget, mipLevels, glInternalFormat, width, height, depth);
				break;
			default: throw new Error(dimension);
		}
		this.gl.bindTexture(this.glTarget, null);
		this._initializeData(props.data);
		this.setSampler(this.props.sampler);
		this.view = new WEBGLTextureView(this.device, {
			...this.props,
			texture: this
		});
		Object.seal(this);
	}
	destroy() {
		if (this.handle) {
			this.gl.deleteTexture(this.handle);
			this.removeStats();
			this.trackDeallocatedMemory("Texture");
			this.destroyed = true;
		}
	}
	createView(props) {
		return new WEBGLTextureView(this.device, {
			...props,
			texture: this
		});
	}
	setSampler(sampler = {}) {
		super.setSampler(sampler);
		const parameters = convertSamplerParametersToWebGL(this.sampler.props);
		this._setSamplerParameters(parameters);
	}
	copyImageData(options_) {
		const options = this._normalizeCopyImageDataOptions(options_);
		const typedArray = options.data;
		const { width, height, depth } = this;
		const { mipLevel = 0, byteOffset = 0, x = 0, y = 0, z = 0 } = options;
		const { glFormat, glType, compressed } = this;
		const glTarget = getWebGLCubeFaceTarget(this.glTarget, this.dimension, z);
		let unpackRowLength;
		if (!this.compressed) {
			const { bytesPerPixel } = this.device.getTextureFormatInfo(this.format);
			if (bytesPerPixel) {
				if (options.bytesPerRow % bytesPerPixel !== 0) throw new Error(`bytesPerRow (${options.bytesPerRow}) must be a multiple of bytesPerPixel (${bytesPerPixel}) for ${this.format}`);
				unpackRowLength = options.bytesPerRow / bytesPerPixel;
			}
		}
		const glParameters = !this.compressed ? {
			...unpackRowLength !== void 0 ? { [3314]: unpackRowLength } : {},
			[32878]: options.rowsPerImage
		} : {};
		this.gl.bindTexture(glTarget, this.handle);
		withGLParameters(this.gl, glParameters, () => {
			switch (this.dimension) {
				case "2d":
				case "cube":
					if (compressed) this.gl.compressedTexSubImage2D(glTarget, mipLevel, x, y, width, height, glFormat, typedArray, byteOffset);
					else this.gl.texSubImage2D(glTarget, mipLevel, x, y, width, height, glFormat, glType, typedArray, byteOffset);
					break;
				case "2d-array":
				case "3d":
					if (compressed) this.gl.compressedTexSubImage3D(glTarget, mipLevel, x, y, z, width, height, depth, glFormat, typedArray, byteOffset);
					else this.gl.texSubImage3D(glTarget, mipLevel, x, y, z, width, height, depth, glFormat, glType, typedArray, byteOffset);
					break;
				default:
			}
		});
		this.gl.bindTexture(glTarget, null);
	}
	copyExternalImage(options_) {
		const options = this._normalizeCopyExternalImageOptions(options_);
		if (options.sourceX || options.sourceY) throw new Error("WebGL does not support sourceX/sourceY)");
		const { glFormat, glType } = this;
		const { image, depth, mipLevel, x, y, z, width, height } = options;
		const glTarget = getWebGLCubeFaceTarget(this.glTarget, this.dimension, depth);
		const glParameters = options.flipY ? { [37440]: true } : {};
		this.gl.bindTexture(this.glTarget, this.handle);
		withGLParameters(this.gl, glParameters, () => {
			switch (this.dimension) {
				case "2d":
				case "cube":
					this.gl.texSubImage2D(glTarget, mipLevel, x, y, width, height, glFormat, glType, image);
					break;
				case "2d-array":
				case "3d":
					this.gl.texSubImage3D(glTarget, mipLevel, x, y, z, width, height, depth, glFormat, glType, image);
					break;
				default:
			}
		});
		this.gl.bindTexture(this.glTarget, null);
		return {
			width: options.width,
			height: options.height
		};
	}
	generateMipmapsWebGL(options) {
		if (!(this.device.isTextureFormatRenderable(this.props.format) && this.device.isTextureFormatFilterable(this.props.format))) {
			log.warn(`${this} is not renderable or filterable, may not be able to generate mipmaps`)();
			if (!options?.force) return;
		}
		try {
			this.gl.bindTexture(this.glTarget, this.handle);
			this.gl.generateMipmap(this.glTarget);
		} catch (error) {
			log.warn(`Error generating mipmap for ${this}: ${error.message}`)();
		} finally {
			this.gl.bindTexture(this.glTarget, null);
		}
	}
	/**
	* Sets sampler parameters on texture
	*/
	_setSamplerParameters(parameters) {
		log.log(2, `${this.id} sampler parameters`, this.device.getGLKeys(parameters))();
		this.gl.bindTexture(this.glTarget, this.handle);
		for (const [pname, pvalue] of Object.entries(parameters)) {
			const param = Number(pname);
			const value = pvalue;
			switch (param) {
				case 33082:
				case 33083:
					this.gl.texParameterf(this.glTarget, param, value);
					break;
				case 10240:
				case 10241:
					this.gl.texParameteri(this.glTarget, param, value);
					break;
				case 10242:
				case 10243:
				case 32882:
					this.gl.texParameteri(this.glTarget, param, value);
					break;
				case 34046:
					if (this.device.features.has("texture-filterable-anisotropic-webgl")) this.gl.texParameteri(this.glTarget, param, value);
					break;
				case 34892:
				case 34893:
					this.gl.texParameteri(this.glTarget, param, value);
					break;
			}
		}
		this.gl.bindTexture(this.glTarget, null);
	}
	_getActiveUnit() {
		return this.gl.getParameter(34016) - 33984;
	}
	_bind(_textureUnit) {
		const { gl } = this;
		if (_textureUnit !== void 0) {
			this._textureUnit = _textureUnit;
			gl.activeTexture(33984 + _textureUnit);
		}
		gl.bindTexture(this.glTarget, this.handle);
		return _textureUnit;
	}
	_unbind(_textureUnit) {
		const { gl } = this;
		if (_textureUnit !== void 0) {
			this._textureUnit = _textureUnit;
			gl.activeTexture(33984 + _textureUnit);
		}
		gl.bindTexture(this.glTarget, null);
		return _textureUnit;
	}
};
/** Convert a WebGPU style texture constant to a WebGL style texture constant */
function getWebGLTextureTarget(dimension) {
	switch (dimension) {
		case "1d": break;
		case "2d": return 3553;
		case "3d": return 32879;
		case "cube": return 34067;
		case "2d-array": return 35866;
		case "cube-array": break;
	}
	throw new Error(dimension);
}
/**
* In WebGL, cube maps specify faces by overriding target instead of using the depth parameter.
* @note We still bind the texture using GL.TEXTURE_CUBE_MAP, but we need to use the face-specific target when setting mip levels.
* @returns glTarget unchanged, if dimension !== 'cube'.
*/
function getWebGLCubeFaceTarget(glTarget, dimension, level) {
	return dimension === "cube" ? 34069 + level : glTarget;
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/converters/webgl-shadertypes.js
/** Converts to a luma shadertype to a GL data type (GL.BYTE, GL.FLOAT32 etc)  */
function convertDataTypeToGLDataType(normalizedType) {
	return NORMALIZED_SHADER_TYPE_TO_WEBGL[normalizedType];
}
/** Convert a WebGL "compisite type (e.g. GL.VEC3) into the corresponding luma shader uniform type */
function convertGLUniformTypeToShaderVariableType(glUniformType) {
	return WEBGL_SHADER_TYPES[glUniformType];
}
/** Check if a WebGL "uniform:" is a texture binding */
function isGLSamplerType(type) {
	return Boolean(WEBGL_SAMPLER_TO_TEXTURE_BINDINGS[type]);
}
function getTextureBindingFromGLSamplerType(glSamplerType) {
	return WEBGL_SAMPLER_TO_TEXTURE_BINDINGS[glSamplerType];
}
var WEBGL_SHADER_TYPES = {
	[5126]: "f32",
	[35664]: "vec2<f32>",
	[35665]: "vec3<f32>",
	[35666]: "vec4<f32>",
	[5124]: "i32",
	[35667]: "vec2<i32>",
	[35668]: "vec3<i32>",
	[35669]: "vec4<i32>",
	[5125]: "u32",
	[36294]: "vec2<u32>",
	[36295]: "vec3<u32>",
	[36296]: "vec4<u32>",
	[35670]: "f32",
	[35671]: "vec2<f32>",
	[35672]: "vec3<f32>",
	[35673]: "vec4<f32>",
	[35674]: "mat2x2<f32>",
	[35685]: "mat2x3<f32>",
	[35686]: "mat2x4<f32>",
	[35687]: "mat3x2<f32>",
	[35675]: "mat3x3<f32>",
	[35688]: "mat3x4<f32>",
	[35689]: "mat4x2<f32>",
	[35690]: "mat4x3<f32>",
	[35676]: "mat4x4<f32>"
};
var WEBGL_SAMPLER_TO_TEXTURE_BINDINGS = {
	[35678]: {
		viewDimension: "2d",
		sampleType: "float"
	},
	[35680]: {
		viewDimension: "cube",
		sampleType: "float"
	},
	[35679]: {
		viewDimension: "3d",
		sampleType: "float"
	},
	[35682]: {
		viewDimension: "3d",
		sampleType: "depth"
	},
	[36289]: {
		viewDimension: "2d-array",
		sampleType: "float"
	},
	[36292]: {
		viewDimension: "2d-array",
		sampleType: "depth"
	},
	[36293]: {
		viewDimension: "cube",
		sampleType: "float"
	},
	[36298]: {
		viewDimension: "2d",
		sampleType: "sint"
	},
	[36299]: {
		viewDimension: "3d",
		sampleType: "sint"
	},
	[36300]: {
		viewDimension: "cube",
		sampleType: "sint"
	},
	[36303]: {
		viewDimension: "2d-array",
		sampleType: "uint"
	},
	[36306]: {
		viewDimension: "2d",
		sampleType: "uint"
	},
	[36307]: {
		viewDimension: "3d",
		sampleType: "uint"
	},
	[36308]: {
		viewDimension: "cube",
		sampleType: "uint"
	},
	[36311]: {
		viewDimension: "2d-array",
		sampleType: "uint"
	}
};
/** Map from WebGL normalized types to WebGL */
var NORMALIZED_SHADER_TYPE_TO_WEBGL = {
	uint8: 5121,
	sint8: 5120,
	unorm8: 5121,
	snorm8: 5120,
	uint16: 5123,
	sint16: 5122,
	unorm16: 5123,
	snorm16: 5122,
	uint32: 5125,
	sint32: 5124,
	float16: 5131,
	float32: 5126
};

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/helpers/get-shader-layout-from-glsl.js
/**
* Extract metadata describing binding information for a program's shaders
* Note: `linkProgram()` needs to have been called
* (although linking does not need to have been successful).
*/
function getShaderLayoutFromGLSL(gl, program) {
	const shaderLayout = {
		attributes: [],
		bindings: []
	};
	shaderLayout.attributes = readAttributeDeclarations(gl, program);
	const uniformBlocks = readUniformBlocks(gl, program);
	for (const uniformBlock of uniformBlocks) {
		const uniforms$1 = uniformBlock.uniforms.map((uniform) => ({
			name: uniform.name,
			format: uniform.format,
			byteOffset: uniform.byteOffset,
			byteStride: uniform.byteStride,
			arrayLength: uniform.arrayLength
		}));
		shaderLayout.bindings.push({
			type: "uniform",
			name: uniformBlock.name,
			group: 0,
			location: uniformBlock.location,
			visibility: (uniformBlock.vertex ? 1 : 0) & (uniformBlock.fragment ? 2 : 0),
			minBindingSize: uniformBlock.byteLength,
			uniforms: uniforms$1
		});
	}
	const uniforms = readUniformBindings(gl, program);
	let textureUnit = 0;
	for (const uniform of uniforms) if (isGLSamplerType(uniform.type)) {
		const { viewDimension, sampleType } = getTextureBindingFromGLSamplerType(uniform.type);
		shaderLayout.bindings.push({
			type: "texture",
			name: uniform.name,
			group: 0,
			location: textureUnit,
			viewDimension,
			sampleType
		});
		uniform.textureUnit = textureUnit;
		textureUnit += 1;
	}
	if (uniforms.length) shaderLayout.uniforms = uniforms;
	const varyings = readVaryings(gl, program);
	if (varyings?.length) shaderLayout.varyings = varyings;
	return shaderLayout;
}
/**
* Extract info about all transform feedback varyings
*
* linkProgram needs to have been called, although linking does not need to have been successful
*/
function readAttributeDeclarations(gl, program) {
	const attributes = [];
	const count = gl.getProgramParameter(program, 35721);
	for (let index = 0; index < count; index++) {
		const activeInfo = gl.getActiveAttrib(program, index);
		if (!activeInfo) throw new Error("activeInfo");
		const { name: name$1, type: compositeType } = activeInfo;
		const location = gl.getAttribLocation(program, name$1);
		if (location >= 0) {
			const attributeType = convertGLUniformTypeToShaderVariableType(compositeType);
			const stepMode = /instance/i.test(name$1) ? "instance" : "vertex";
			attributes.push({
				name: name$1,
				location,
				stepMode,
				type: attributeType
			});
		}
	}
	attributes.sort((a, b) => a.location - b.location);
	return attributes;
}
/**
* Extract info about all transform feedback varyings
*
* linkProgram needs to have been called, although linking does not need to have been successful
*/
function readVaryings(gl, program) {
	const varyings = [];
	const count = gl.getProgramParameter(program, 35971);
	for (let location = 0; location < count; location++) {
		const activeInfo = gl.getTransformFeedbackVarying(program, location);
		if (!activeInfo) throw new Error("activeInfo");
		const { name: name$1, type: glUniformType, size } = activeInfo;
		const { type, components } = getVariableShaderTypeInfo(convertGLUniformTypeToShaderVariableType(glUniformType));
		varyings.push({
			location,
			name: name$1,
			type,
			size: size * components
		});
	}
	varyings.sort((a, b) => a.location - b.location);
	return varyings;
}
/**
* Extract info about all uniforms
*
* Query uniform locations and build name to setter map.
*/
function readUniformBindings(gl, program) {
	const uniforms = [];
	const uniformCount = gl.getProgramParameter(program, 35718);
	for (let i = 0; i < uniformCount; i++) {
		const activeInfo = gl.getActiveUniform(program, i);
		if (!activeInfo) throw new Error("activeInfo");
		const { name: rawName, size, type } = activeInfo;
		const { name: name$1, isArray: isArray$2 } = parseUniformName(rawName);
		let webglLocation = gl.getUniformLocation(program, name$1);
		const uniformInfo = {
			location: webglLocation,
			name: name$1,
			size,
			type,
			isArray: isArray$2
		};
		uniforms.push(uniformInfo);
		if (uniformInfo.size > 1) for (let j = 0; j < uniformInfo.size; j++) {
			const elementName = `${name$1}[${j}]`;
			webglLocation = gl.getUniformLocation(program, elementName);
			const arrayElementUniformInfo = {
				...uniformInfo,
				name: elementName,
				location: webglLocation
			};
			uniforms.push(arrayElementUniformInfo);
		}
	}
	return uniforms;
}
/**
* Extract info about all "active" uniform blocks
* @note In WebGL, "active" just means that unused (inactive) blocks may have been optimized away during linking)
*/
function readUniformBlocks(gl, program) {
	const getBlockParameter = (blockIndex, pname) => gl.getActiveUniformBlockParameter(program, blockIndex, pname);
	const uniformBlocks = [];
	const blockCount = gl.getProgramParameter(program, 35382);
	for (let blockIndex = 0; blockIndex < blockCount; blockIndex++) {
		const blockInfo = {
			name: gl.getActiveUniformBlockName(program, blockIndex) || "",
			location: getBlockParameter(blockIndex, 35391),
			byteLength: getBlockParameter(blockIndex, 35392),
			vertex: getBlockParameter(blockIndex, 35396),
			fragment: getBlockParameter(blockIndex, 35398),
			uniformCount: getBlockParameter(blockIndex, 35394),
			uniforms: []
		};
		const uniformIndices = getBlockParameter(blockIndex, 35395) || [];
		const uniformType = gl.getActiveUniforms(program, uniformIndices, 35383);
		const uniformArrayLength = gl.getActiveUniforms(program, uniformIndices, 35384);
		const uniformOffset = gl.getActiveUniforms(program, uniformIndices, 35387);
		const uniformStride = gl.getActiveUniforms(program, uniformIndices, 35388);
		for (let i = 0; i < blockInfo.uniformCount; ++i) {
			const activeInfo = gl.getActiveUniform(program, uniformIndices[i]);
			if (!activeInfo) throw new Error("activeInfo");
			const format = convertGLUniformTypeToShaderVariableType(uniformType[i]);
			blockInfo.uniforms.push({
				name: activeInfo.name,
				format,
				type: uniformType[i],
				arrayLength: uniformArrayLength[i],
				byteOffset: uniformOffset[i],
				byteStride: uniformStride[i]
			});
		}
		uniformBlocks.push(blockInfo);
	}
	uniformBlocks.sort((a, b) => a.location - b.location);
	return uniformBlocks;
}
/**
* TOOD - compare with a above, confirm copy, then delete
const bindings: Binding[] = [];
const count = gl.getProgramParameter(program, gl.ACTIVE_UNIFORM_BLOCKS);
for (let blockIndex = 0; blockIndex < count; blockIndex++) {
const vertex = gl.getActiveUniformBlockParameter(program, blockIndex, gl.UNIFORM_BLOCK_REFERENCED_BY_VERTEX_SHADER),
const fragment = gl.getActiveUniformBlockParameter(program, blockIndex, gl.UNIFORM_BLOCK_REFERENCED_BY_FRAGMENT_SHADER),
const visibility = (vertex) + (fragment);
const binding: BufferBinding = {
location: gl.getActiveUniformBlockParameter(program, blockIndex, gl.UNIFORM_BLOCK_BINDING),
// name: gl.getActiveUniformBlockName(program, blockIndex),
type: 'uniform',
visibility,
minBindingSize: gl.getActiveUniformBlockParameter(program, blockIndex, gl.UNIFORM_BLOCK_DATA_SIZE),
// uniformCount: gl.getActiveUniformBlockParameter(program, blockIndex, gl.UNIFORM_BLOCK_ACTIVE_UNIFORMS),
// uniformIndices: gl.getActiveUniformBlockParameter(program, blockIndex, gl.UNIFORM_BLOCK_ACTIVE_UNIFORM_INDICES),
}
bindings.push(binding);
}
*/
function parseUniformName(name$1) {
	if (name$1[name$1.length - 1] !== "]") return {
		name: name$1,
		length: 1,
		isArray: false
	};
	const matches = /([^[]*)(\[[0-9]+\])?/.exec(name$1);
	if (!matches || matches.length < 2) throw new Error(`Failed to parse GLSL uniform name ${name$1}`);
	return {
		name: matches[1],
		length: matches[2] ? 1 : 0,
		isArray: Boolean(matches[2])
	};
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/helpers/set-uniform.js
/** Set a raw uniform (without type conversion and caching) */
function setUniform(gl, location, type, value) {
	const gl2 = gl;
	let uniformValue = value;
	if (uniformValue === true) uniformValue = 1;
	if (uniformValue === false) uniformValue = 0;
	const arrayValue = typeof uniformValue === "number" ? [uniformValue] : uniformValue;
	switch (type) {
		case 35678:
		case 35680:
		case 35679:
		case 35682:
		case 36289:
		case 36292:
		case 36293:
		case 36298:
		case 36299:
		case 36300:
		case 36303:
		case 36306:
		case 36307:
		case 36308:
		case 36311:
			if (typeof value !== "number") throw new Error("samplers must be set to integers");
			return gl.uniform1i(location, value);
		case 5126: return gl.uniform1fv(location, arrayValue);
		case 35664: return gl.uniform2fv(location, arrayValue);
		case 35665: return gl.uniform3fv(location, arrayValue);
		case 35666: return gl.uniform4fv(location, arrayValue);
		case 5124: return gl.uniform1iv(location, arrayValue);
		case 35667: return gl.uniform2iv(location, arrayValue);
		case 35668: return gl.uniform3iv(location, arrayValue);
		case 35669: return gl.uniform4iv(location, arrayValue);
		case 35670: return gl.uniform1iv(location, arrayValue);
		case 35671: return gl.uniform2iv(location, arrayValue);
		case 35672: return gl.uniform3iv(location, arrayValue);
		case 35673: return gl.uniform4iv(location, arrayValue);
		case 5125: return gl2.uniform1uiv(location, arrayValue, 1);
		case 36294: return gl2.uniform2uiv(location, arrayValue, 2);
		case 36295: return gl2.uniform3uiv(location, arrayValue, 3);
		case 36296: return gl2.uniform4uiv(location, arrayValue, 4);
		case 35674: return gl.uniformMatrix2fv(location, false, arrayValue);
		case 35675: return gl.uniformMatrix3fv(location, false, arrayValue);
		case 35676: return gl.uniformMatrix4fv(location, false, arrayValue);
		case 35685: return gl2.uniformMatrix2x3fv(location, false, arrayValue);
		case 35686: return gl2.uniformMatrix2x4fv(location, false, arrayValue);
		case 35687: return gl2.uniformMatrix3x2fv(location, false, arrayValue);
		case 35688: return gl2.uniformMatrix3x4fv(location, false, arrayValue);
		case 35689: return gl2.uniformMatrix4x2fv(location, false, arrayValue);
		case 35690: return gl2.uniformMatrix4x3fv(location, false, arrayValue);
	}
	throw new Error("Illegal uniform");
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/helpers/webgl-topology-utils.js
/** Get the primitive type for draw */
function getGLDrawMode(topology) {
	switch (topology) {
		case "point-list": return 0;
		case "line-list": return 1;
		case "line-strip": return 3;
		case "triangle-list": return 4;
		case "triangle-strip": return 5;
		default: throw new Error(topology);
	}
}
/** Get the primitive type for transform feedback */
function getGLPrimitive(topology) {
	switch (topology) {
		case "point-list": return 0;
		case "line-list": return 1;
		case "line-strip": return 1;
		case "triangle-list": return 4;
		case "triangle-strip": return 4;
		default: throw new Error(topology);
	}
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/resources/webgl-render-pipeline.js
var LOG_PROGRAM_PERF_PRIORITY = 4;
/** Creates a new render pipeline */
var WEBGLRenderPipeline = class extends RenderPipeline {
	/** The WebGL device that created this render pipeline */
	device;
	/** Handle to underlying WebGL program */
	handle;
	/** vertex shader */
	vs;
	/** fragment shader */
	fs;
	/** The layout extracted from shader by WebGL introspection APIs */
	introspectedLayout;
	/** Uniforms set on this model */
	uniforms = {};
	/** Bindings set on this model */
	bindings = {};
	/** WebGL varyings */
	varyings = null;
	_uniformCount = 0;
	_uniformSetters = {};
	get [Symbol.toStringTag]() {
		return "WEBGLRenderPipeline";
	}
	constructor(device, props) {
		super(device, props);
		this.device = device;
		this.handle = this.props.handle || this.device.gl.createProgram();
		this.device._setWebGLDebugMetadata(this.handle, this, { spector: { id: this.props.id } });
		this.vs = props.vs;
		this.fs = props.fs;
		const { varyings, bufferMode = 35981 } = props;
		if (varyings && varyings.length > 0) {
			this.varyings = varyings;
			this.device.gl.transformFeedbackVaryings(this.handle, varyings, bufferMode);
		}
		this._linkShaders();
		log.time(3, `RenderPipeline ${this.id} - shaderLayout introspection`)();
		this.introspectedLayout = getShaderLayoutFromGLSL(this.device.gl, this.handle);
		log.timeEnd(3, `RenderPipeline ${this.id} - shaderLayout introspection`)();
		this.shaderLayout = props.shaderLayout ? mergeShaderLayout(this.introspectedLayout, props.shaderLayout) : this.introspectedLayout;
	}
	destroy() {
		if (this.handle) {
			this.device.gl.useProgram(null);
			this.device.gl.deleteProgram(this.handle);
			this.destroyed = true;
			this.handle.destroyed = true;
			this.handle = null;
		}
	}
	/**
	* Bindings include: textures, samplers and uniform buffers
	* @todo needed for portable model
	*/
	setBindings(bindings, options) {
		for (const [name$1, value] of Object.entries(bindings)) {
			const binding = this.shaderLayout.bindings.find((binding_) => binding_.name === name$1) || this.shaderLayout.bindings.find((binding_) => binding_.name === `${name$1}Uniforms`);
			if (!binding) {
				const validBindings = this.shaderLayout.bindings.map((binding_) => `"${binding_.name}"`).join(", ");
				if (!options?.disableWarnings) log.warn(`No binding "${name$1}" in render pipeline "${this.id}", expected one of ${validBindings}`, value)();
				continue;
			}
			if (!value) log.warn(`Unsetting binding "${name$1}" in render pipeline "${this.id}"`)();
			switch (binding.type) {
				case "uniform":
					if (!(value instanceof WEBGLBuffer) && !(value.buffer instanceof WEBGLBuffer)) throw new Error("buffer value");
					break;
				case "texture":
					if (!(value instanceof WEBGLTextureView || value instanceof WEBGLTexture || value instanceof WEBGLFramebuffer)) throw new Error(`${this} Bad texture binding for ${name$1}`);
					break;
				case "sampler":
					log.warn(`Ignoring sampler ${name$1}`)();
					break;
				default: throw new Error(binding.type);
			}
			this.bindings[name$1] = value;
		}
	}
	/** @todo needed for portable model
	* @note The WebGL API is offers many ways to draw things
	* This function unifies those ways into a single call using common parameters with sane defaults
	*/
	draw(options) {
		const { renderPass, parameters = this.props.parameters, topology = this.props.topology, vertexArray, vertexCount, instanceCount, isInstanced = false, firstVertex = 0, transformFeedback } = options;
		const glDrawMode = getGLDrawMode(topology);
		const isIndexed = Boolean(vertexArray.indexBuffer);
		const glIndexType = vertexArray.indexBuffer?.glIndexType;
		if (this.linkStatus !== "success") {
			log.info(2, `RenderPipeline:${this.id}.draw() aborted - waiting for shader linking`)();
			return false;
		}
		if (!this._areTexturesRenderable()) {
			log.info(2, `RenderPipeline:${this.id}.draw() aborted - textures not yet loaded`)();
			return false;
		}
		this.device.gl.useProgram(this.handle);
		vertexArray.bindBeforeRender(renderPass);
		if (transformFeedback) transformFeedback.begin(this.props.topology);
		this._applyBindings();
		this._applyUniforms();
		const webglRenderPass = renderPass;
		withDeviceAndGLParameters(this.device, parameters, webglRenderPass.glParameters, () => {
			if (isIndexed && isInstanced) this.device.gl.drawElementsInstanced(glDrawMode, vertexCount || 0, glIndexType, firstVertex, instanceCount || 0);
			else if (isIndexed) this.device.gl.drawElements(glDrawMode, vertexCount || 0, glIndexType, firstVertex);
			else if (isInstanced) this.device.gl.drawArraysInstanced(glDrawMode, firstVertex, vertexCount || 0, instanceCount || 0);
			else this.device.gl.drawArrays(glDrawMode, firstVertex, vertexCount || 0);
			if (transformFeedback) transformFeedback.end();
		});
		vertexArray.unbindAfterRender(renderPass);
		return true;
	}
	async _linkShaders() {
		const { gl } = this.device;
		gl.attachShader(this.handle, this.vs.handle);
		gl.attachShader(this.handle, this.fs.handle);
		log.time(LOG_PROGRAM_PERF_PRIORITY, `linkProgram for ${this.id}`)();
		gl.linkProgram(this.handle);
		log.timeEnd(LOG_PROGRAM_PERF_PRIORITY, `linkProgram for ${this.id}`)();
		if (log.level === 0) {}
		if (!this.device.features.has("compilation-status-async-webgl")) {
			const status$1 = this._getLinkStatus();
			this._reportLinkStatus(status$1);
			return;
		}
		log.once(1, "RenderPipeline linking is asynchronous")();
		await this._waitForLinkComplete();
		log.info(2, `RenderPipeline ${this.id} - async linking complete: ${this.linkStatus}`)();
		const status = this._getLinkStatus();
		this._reportLinkStatus(status);
	}
	/** Report link status. First, check for shader compilation failures if linking fails */
	async _reportLinkStatus(status) {
		switch (status) {
			case "success": return;
			default:
				const errorType = status === "link-error" ? "Link error" : "Validation error";
				switch (this.vs.compilationStatus) {
					case "error":
						this.vs.debugShader();
						throw new Error(`${this} ${errorType} during compilation of ${this.vs}`);
					case "pending":
						await this.vs.asyncCompilationStatus;
						this.vs.debugShader();
						break;
					case "success": break;
				}
				switch (this.fs?.compilationStatus) {
					case "error":
						this.fs.debugShader();
						throw new Error(`${this} ${errorType} during compilation of ${this.fs}`);
					case "pending":
						await this.fs.asyncCompilationStatus;
						this.fs.debugShader();
						break;
					case "success": break;
				}
				const linkErrorLog = this.device.gl.getProgramInfoLog(this.handle);
				this.device.reportError(/* @__PURE__ */ new Error(`${errorType} during ${status}: ${linkErrorLog}`), this)();
				this.device.debug();
		}
	}
	/**
	* Get the shader compilation status
	* TODO - Load log even when no error reported, to catch warnings?
	* https://gamedev.stackexchange.com/questions/30429/how-to-detect-glsl-warnings
	*/
	_getLinkStatus() {
		const { gl } = this.device;
		if (!gl.getProgramParameter(this.handle, 35714)) {
			this.linkStatus = "error";
			return "link-error";
		}
		gl.validateProgram(this.handle);
		if (!gl.getProgramParameter(this.handle, 35715)) {
			this.linkStatus = "error";
			return "validation-error";
		}
		this.linkStatus = "success";
		return "success";
	}
	/** Use KHR_parallel_shader_compile extension if available */
	async _waitForLinkComplete() {
		const waitMs = async (ms) => await new Promise((resolve) => setTimeout(resolve, ms));
		const DELAY_MS = 10;
		if (!this.device.features.has("compilation-status-async-webgl")) {
			await waitMs(DELAY_MS);
			return;
		}
		const { gl } = this.device;
		for (;;) {
			if (gl.getProgramParameter(this.handle, 37297)) return;
			await waitMs(DELAY_MS);
		}
	}
	/**
	* Checks if all texture-values uniforms are renderable (i.e. loaded)
	* Update a texture if needed (e.g. from video)
	* Note: This is currently done before every draw call
	*/
	_areTexturesRenderable() {
		let texturesRenderable = true;
		for (const bindingInfo of this.shaderLayout.bindings) if (!this.bindings[bindingInfo.name] && !this.bindings[bindingInfo.name.replace(/Uniforms$/, "")]) {
			log.warn(`Binding ${bindingInfo.name} not found in ${this.id}`)();
			texturesRenderable = false;
		}
		return texturesRenderable;
	}
	/** Apply any bindings (before each draw call) */
	_applyBindings() {
		if (this.linkStatus !== "success") return;
		const { gl } = this.device;
		gl.useProgram(this.handle);
		let textureUnit = 0;
		let uniformBufferIndex = 0;
		for (const binding of this.shaderLayout.bindings) {
			const value = this.bindings[binding.name] || this.bindings[binding.name.replace(/Uniforms$/, "")];
			if (!value) throw new Error(`No value for binding ${binding.name} in ${this.id}`);
			switch (binding.type) {
				case "uniform":
					const { name: name$1 } = binding;
					const location = gl.getUniformBlockIndex(this.handle, name$1);
					if (location === 4294967295) throw new Error(`Invalid uniform block name ${name$1}`);
					gl.uniformBlockBinding(this.handle, uniformBufferIndex, location);
					if (value instanceof WEBGLBuffer) gl.bindBufferBase(35345, uniformBufferIndex, value.handle);
					else gl.bindBufferRange(35345, uniformBufferIndex, value.buffer.handle, value.offset || 0, value.size || value.buffer.byteLength - value.offset);
					uniformBufferIndex += 1;
					break;
				case "texture":
					if (!(value instanceof WEBGLTextureView || value instanceof WEBGLTexture || value instanceof WEBGLFramebuffer)) throw new Error("texture");
					let texture;
					if (value instanceof WEBGLTextureView) texture = value.texture;
					else if (value instanceof WEBGLTexture) texture = value;
					else if (value instanceof WEBGLFramebuffer && value.colorAttachments[0] instanceof WEBGLTextureView) {
						log.warn("Passing framebuffer in texture binding may be deprecated. Use fbo.colorAttachments[0] instead")();
						texture = value.colorAttachments[0].texture;
					} else throw new Error("No texture");
					gl.activeTexture(33984 + textureUnit);
					gl.bindTexture(texture.glTarget, texture.handle);
					textureUnit += 1;
					break;
				case "sampler": break;
				case "storage":
				case "read-only-storage": throw new Error(`binding type '${binding.type}' not supported in WebGL`);
			}
		}
	}
	/**
	* Due to program sharing, uniforms need to be reset before every draw call
	* (though caching will avoid redundant WebGL calls)
	*/
	_applyUniforms() {
		for (const uniformLayout of this.shaderLayout.uniforms || []) {
			const { name: name$1, location, type, textureUnit } = uniformLayout;
			const value = this.uniforms[name$1] ?? textureUnit;
			if (value !== void 0) setUniform(this.device.gl, location, type, value);
		}
	}
};
/**
* Merges an provided shader layout into a base shader layout
* In WebGL, this allows the auto generated shader layout to be overridden by the application
* Typically to change the format of the vertex attributes (from float32x4 to uint8x4 etc).
* @todo Drop this? Aren't all use cases covered by mergeBufferLayout()?
*/
function mergeShaderLayout(baseLayout, overrideLayout) {
	const mergedLayout = {
		...baseLayout,
		attributes: baseLayout.attributes.map((attribute) => ({ ...attribute }))
	};
	for (const attribute of overrideLayout?.attributes || []) {
		const baseAttribute = mergedLayout.attributes.find((attr) => attr.name === attribute.name);
		if (!baseAttribute) log.warn(`shader layout attribute ${attribute.name} not present in shader`);
		else {
			baseAttribute.type = attribute.type || baseAttribute.type;
			baseAttribute.stepMode = attribute.stepMode || baseAttribute.stepMode;
		}
	}
	return mergedLayout;
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/resources/webgl-command-buffer.js
var WEBGLCommandBuffer = class extends CommandBuffer {
	device;
	handle = null;
	commands = [];
	constructor(device) {
		super(device, {});
		this.device = device;
	}
	_executeCommands(commands = this.commands) {
		for (const command of commands) switch (command.name) {
			case "copy-buffer-to-buffer":
				_copyBufferToBuffer(this.device, command.options);
				break;
			case "copy-buffer-to-texture":
				_copyBufferToTexture(this.device, command.options);
				break;
			case "copy-texture-to-buffer":
				_copyTextureToBuffer(this.device, command.options);
				break;
			case "copy-texture-to-texture":
				_copyTextureToTexture(this.device, command.options);
				break;
			default: throw new Error(command.name);
		}
	}
};
function _copyBufferToBuffer(device, options) {
	const source = options.sourceBuffer;
	const destination = options.destinationBuffer;
	device.gl.bindBuffer(36662, source.handle);
	device.gl.bindBuffer(36663, destination.handle);
	device.gl.copyBufferSubData(36662, 36663, options.sourceOffset ?? 0, options.destinationOffset ?? 0, options.size);
	device.gl.bindBuffer(36662, null);
	device.gl.bindBuffer(36663, null);
}
/**
* Copies data from a Buffer object into a Texture object
* NOTE: doesn't wait for copy to be complete
*/
function _copyBufferToTexture(device, options) {
	throw new Error("Not implemented");
}
/**
* Copies data from a Texture object into a Buffer object.
* NOTE: doesn't wait for copy to be complete
*/
function _copyTextureToBuffer(device, options) {
	const { sourceTexture, mipLevel = 0, aspect = "all", width = options.sourceTexture.width, height = options.sourceTexture.height, depthOrArrayLayers = 0, origin = [0, 0], destinationBuffer, byteOffset = 0, bytesPerRow, rowsPerImage } = options;
	if (aspect !== "all") throw new Error("aspect not supported in WebGL");
	if (mipLevel !== 0 || depthOrArrayLayers !== 0 || bytesPerRow || rowsPerImage) throw new Error("not implemented");
	const { framebuffer, destroyFramebuffer } = getFramebuffer$1(sourceTexture);
	let prevHandle;
	try {
		const webglBuffer = destinationBuffer;
		const sourceWidth = width || framebuffer.width;
		const sourceHeight = height || framebuffer.height;
		const sourceParams = getTextureFormatWebGL(framebuffer.colorAttachments[0].texture.props.format);
		const sourceFormat = sourceParams.format;
		const sourceType = sourceParams.type;
		device.gl.bindBuffer(35051, webglBuffer.handle);
		prevHandle = device.gl.bindFramebuffer(36160, framebuffer.handle);
		device.gl.readPixels(origin[0], origin[1], sourceWidth, sourceHeight, sourceFormat, sourceType, byteOffset);
	} finally {
		device.gl.bindBuffer(35051, null);
		if (prevHandle !== void 0) device.gl.bindFramebuffer(36160, prevHandle);
		if (destroyFramebuffer) framebuffer.destroy();
	}
}
/**
* Copies data from a Framebuffer or a Texture object into a Buffer object.
* NOTE: doesn't wait for copy to be complete, it programs GPU to perform a DMA transfer.
export function readPixelsToBuffer(
source: Framebuffer | Texture,
options?: {
sourceX?: number;
sourceY?: number;
sourceFormat?: number;
target?: Buffer; // A new Buffer object is created when not provided.
targetByteOffset?: number; // byte offset in buffer object
// following parameters are auto deduced if not provided
sourceWidth?: number;
sourceHeight?: number;
sourceType?: number;
}
): Buffer
*/
/**
* Copy a rectangle from a Framebuffer or Texture object into a texture (at an offset)
*/
function _copyTextureToTexture(device, options) {
	const { sourceTexture, destinationMipLevel = 0, origin = [0, 0], destinationOrigin = [0, 0], destinationTexture } = options;
	let { width = options.destinationTexture.width, height = options.destinationTexture.height } = options;
	const { framebuffer, destroyFramebuffer } = getFramebuffer$1(sourceTexture);
	const [sourceX, sourceY] = origin;
	const [destinationX, destinationY, destinationZ] = destinationOrigin;
	const prevHandle = device.gl.bindFramebuffer(36160, framebuffer.handle);
	let texture;
	let textureTarget;
	if (destinationTexture instanceof WEBGLTexture) {
		texture = destinationTexture;
		width = Number.isFinite(width) ? width : texture.width;
		height = Number.isFinite(height) ? height : texture.height;
		texture._bind(0);
		textureTarget = texture.glTarget;
	} else throw new Error("invalid destination");
	switch (textureTarget) {
		case 3553:
		case 34067:
			device.gl.copyTexSubImage2D(textureTarget, destinationMipLevel, destinationX, destinationY, sourceX, sourceY, width, height);
			break;
		case 35866:
		case 32879:
			device.gl.copyTexSubImage3D(textureTarget, destinationMipLevel, destinationX, destinationY, destinationZ, sourceX, sourceY, width, height);
			break;
		default:
	}
	if (texture) texture._unbind();
	device.gl.bindFramebuffer(36160, prevHandle);
	if (destroyFramebuffer) framebuffer.destroy();
}
/** Wrap a texture in a framebuffer so that we can use WebGL APIs that work on framebuffers */
function getFramebuffer$1(source) {
	if (source instanceof Texture) {
		const { width, height, id } = source;
		return {
			framebuffer: source.device.createFramebuffer({
				id: `framebuffer-for-${id}`,
				width,
				height,
				colorAttachments: [source]
			}),
			destroyFramebuffer: true
		};
	}
	return {
		framebuffer: source,
		destroyFramebuffer: false
	};
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/resources/webgl-render-pass.js
var COLOR_CHANNELS = [
	1,
	2,
	4,
	8
];
var WEBGLRenderPass = class extends RenderPass {
	device;
	handle = null;
	/** Parameters that should be applied before each draw call */
	glParameters = {};
	constructor(device, props) {
		super(device, props);
		this.device = device;
		let viewport;
		if (!props?.parameters?.viewport) if (props?.framebuffer) {
			const { width, height } = props.framebuffer;
			viewport = [
				0,
				0,
				width,
				height
			];
		} else {
			const [width, height] = device.getDefaultCanvasContext().getDrawingBufferSize();
			viewport = [
				0,
				0,
				width,
				height
			];
		}
		this.device.pushState();
		this.setParameters({
			viewport,
			...this.props.parameters
		});
		const webglFramebuffer = this.props.framebuffer;
		if (this.props.framebuffer && webglFramebuffer?.handle) {
			const drawBuffers = this.props.framebuffer.colorAttachments.map((_, i) => 36064 + i);
			this.device.gl.drawBuffers(drawBuffers);
		} else this.device.gl.drawBuffers([1029]);
		this.clear();
	}
	end() {
		this.device.popState();
	}
	pushDebugGroup(groupLabel) {}
	popDebugGroup() {}
	insertDebugMarker(markerLabel) {}
	/**
	* Maps RenderPass parameters to GL parameters
	*/
	setParameters(parameters = {}) {
		const glParameters = { ...this.glParameters };
		glParameters.framebuffer = this.props.framebuffer || null;
		if (this.props.depthReadOnly) glParameters.depthMask = !this.props.depthReadOnly;
		glParameters.stencilMask = this.props.stencilReadOnly ? 0 : 1;
		glParameters[35977] = this.props.discard;
		if (parameters.viewport) if (parameters.viewport.length >= 6) {
			glParameters.viewport = parameters.viewport.slice(0, 4);
			glParameters.depthRange = [parameters.viewport[4], parameters.viewport[5]];
		} else glParameters.viewport = parameters.viewport;
		if (parameters.scissorRect) {
			glParameters.scissorTest = true;
			glParameters.scissor = parameters.scissorRect;
		}
		if (parameters.blendConstant) glParameters.blendColor = parameters.blendConstant;
		if (parameters.stencilReference) {
			console.warn("RenderPassParameters.stencilReference not yet implemented in WebGL");
			glParameters[2967] = parameters.stencilReference;
		}
		if ("colorMask" in parameters) glParameters.colorMask = COLOR_CHANNELS.map((channel) => Boolean(channel & parameters.colorMask));
		this.glParameters = glParameters;
		setGLParameters(this.device.gl, glParameters);
	}
	beginOcclusionQuery(queryIndex) {
		this.props.occlusionQuerySet?.beginOcclusionQuery();
	}
	endOcclusionQuery() {
		this.props.occlusionQuerySet?.endOcclusionQuery();
	}
	/**
	* Optionally clears depth, color and stencil buffers based on parameters
	*/
	clear() {
		const glParameters = { ...this.glParameters };
		let clearMask = 0;
		if (this.props.clearColors) this.props.clearColors.forEach((color, drawBufferIndex) => {
			if (color) this.clearColorBuffer(drawBufferIndex, color);
		});
		if (this.props.clearColor !== false && this.props.clearColors === void 0) {
			clearMask |= 16384;
			glParameters.clearColor = this.props.clearColor;
		}
		if (this.props.clearDepth !== false) {
			clearMask |= 256;
			glParameters.clearDepth = this.props.clearDepth;
		}
		if (this.props.clearStencil !== false) {
			clearMask |= 1024;
			glParameters.clearStencil = this.props.clearStencil;
		}
		if (clearMask !== 0) withGLParameters(this.device.gl, glParameters, () => {
			this.device.gl.clear(clearMask);
		});
	}
	/**
	* WebGL2 - clear a specific color buffer
	*/
	clearColorBuffer(drawBuffer = 0, value = [
		0,
		0,
		0,
		0
	]) {
		withGLParameters(this.device.gl, { framebuffer: this.props.framebuffer }, () => {
			switch (value.constructor) {
				case Int8Array:
				case Int16Array:
				case Int32Array:
					this.device.gl.clearBufferiv(6144, drawBuffer, value);
					break;
				case Uint8Array:
				case Uint8ClampedArray:
				case Uint16Array:
				case Uint32Array:
					this.device.gl.clearBufferuiv(6144, drawBuffer, value);
					break;
				case Float32Array:
					this.device.gl.clearBufferfv(6144, drawBuffer, value);
					break;
				default: throw new Error("clearColorBuffer: color must be typed array");
			}
		});
	}
};

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/resources/webgl-command-encoder.js
var WEBGLCommandEncoder = class extends CommandEncoder {
	device;
	handle = null;
	commandBuffer;
	constructor(device, props) {
		super(device, props);
		this.device = device;
		this.commandBuffer = new WEBGLCommandBuffer(device);
	}
	destroy() {}
	finish() {
		return this.commandBuffer;
	}
	beginRenderPass(props) {
		return new WEBGLRenderPass(this.device, props);
	}
	beginComputePass(props) {
		throw new Error("ComputePass not supported in WebGL");
	}
	copyBufferToBuffer(options) {
		this.commandBuffer.commands.push({
			name: "copy-buffer-to-buffer",
			options
		});
	}
	copyBufferToTexture(options) {
		this.commandBuffer.commands.push({
			name: "copy-buffer-to-texture",
			options
		});
	}
	copyTextureToBuffer(options) {
		this.commandBuffer.commands.push({
			name: "copy-texture-to-buffer",
			options
		});
	}
	copyTextureToTexture(options) {
		this.commandBuffer.commands.push({
			name: "copy-texture-to-texture",
			options
		});
	}
	pushDebugGroup(groupLabel) {}
	popDebugGroup() {}
	insertDebugMarker(markerLabel) {}
	resolveQuerySet(querySet, destination, options) {}
};

//#endregion
//#region node_modules/@luma.gl/webgl/dist/utils/fill-array.js
function fillArray(options) {
	const { target: target$1, source, start = 0, count = 1 } = options;
	const length = source.length;
	const total = count * length;
	let copied = 0;
	for (let i = start; copied < length; copied++) target$1[i++] = source[copied];
	while (copied < total) if (copied < total - copied) {
		target$1.copyWithin(start + copied, start, start + copied);
		copied *= 2;
	} else {
		target$1.copyWithin(start + copied, start, start + total - copied);
		copied = total;
	}
	return options.target;
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/resources/webgl-vertex-array.js
/** VertexArrayObject wrapper */
var WEBGLVertexArray = class WEBGLVertexArray extends VertexArray {
	get [Symbol.toStringTag]() {
		return "VertexArray";
	}
	device;
	handle;
	/** Attribute 0 buffer constant */
	buffer = null;
	bufferValue = null;
	/** * Attribute 0 can not be disable on most desktop OpenGL based browsers */
	static isConstantAttributeZeroSupported(device) {
		return getBrowser() === "Chrome";
	}
	constructor(device, props) {
		super(device, props);
		this.device = device;
		this.handle = this.device.gl.createVertexArray();
	}
	destroy() {
		super.destroy();
		if (this.buffer) this.buffer?.destroy();
		if (this.handle) {
			this.device.gl.deleteVertexArray(this.handle);
			this.handle = void 0;
		}
	}
	/**
	// Set (bind/unbind) an elements buffer, for indexed rendering.
	// Must be a Buffer bound to GL.ELEMENT_ARRAY_BUFFER or null. Constants not supported
	*
	* @param elementBuffer
	*/
	setIndexBuffer(indexBuffer) {
		const buffer = indexBuffer;
		if (buffer && buffer.glTarget !== 34963) throw new Error("Use .setBuffer()");
		this.device.gl.bindVertexArray(this.handle);
		this.device.gl.bindBuffer(34963, buffer ? buffer.handle : null);
		this.indexBuffer = buffer;
		this.device.gl.bindVertexArray(null);
	}
	/** Set a location in vertex attributes array to a buffer, enables the location, sets divisor */
	setBuffer(location, attributeBuffer) {
		const buffer = attributeBuffer;
		if (buffer.glTarget === 34963) throw new Error("Use .setIndexBuffer()");
		const { size, type, stride, offset, normalized, integer, divisor } = this._getAccessor(location);
		this.device.gl.bindVertexArray(this.handle);
		this.device.gl.bindBuffer(34962, buffer.handle);
		if (integer) this.device.gl.vertexAttribIPointer(location, size, type, stride, offset);
		else this.device.gl.vertexAttribPointer(location, size, type, normalized, stride, offset);
		this.device.gl.bindBuffer(34962, null);
		this.device.gl.enableVertexAttribArray(location);
		this.device.gl.vertexAttribDivisor(location, divisor || 0);
		this.attributes[location] = buffer;
		this.device.gl.bindVertexArray(null);
	}
	/** Set a location in vertex attributes array to a constant value, disables the location */
	setConstantWebGL(location, value) {
		this._enable(location, false);
		this.attributes[location] = value;
	}
	bindBeforeRender() {
		this.device.gl.bindVertexArray(this.handle);
		this._applyConstantAttributes();
	}
	unbindAfterRender() {
		this.device.gl.bindVertexArray(null);
	}
	/**
	* Constant attributes need to be reset before every draw call
	* Any attribute that is disabled in the current vertex array object
	* is read from the context's global constant value for that attribute location.
	* @note Constant attributes are only supported in WebGL, not in WebGPU
	*/
	_applyConstantAttributes() {
		for (let location = 0; location < this.maxVertexAttributes; ++location) {
			const constant = this.attributes[location];
			if (ArrayBuffer.isView(constant)) this.device.setConstantAttributeWebGL(location, constant);
		}
	}
	/**
	* Set a location in vertex attributes array to a buffer, enables the location, sets divisor
	* @note requires vertex array to be bound
	*/
	/** Get an accessor from the  */
	_getAccessor(location) {
		const attributeInfo = this.attributeInfos[location];
		if (!attributeInfo) throw new Error(`Unknown attribute location ${location}`);
		const glType = getGLFromVertexType(attributeInfo.bufferDataType);
		return {
			size: attributeInfo.bufferComponents,
			type: glType,
			stride: attributeInfo.byteStride,
			offset: attributeInfo.byteOffset,
			normalized: attributeInfo.normalized,
			integer: attributeInfo.integer,
			divisor: attributeInfo.stepMode === "instance" ? 1 : 0
		};
	}
	/**
	* Enabling an attribute location makes it reference the currently bound buffer
	* Disabling an attribute location makes it reference the global constant value
	* TODO - handle single values for size 1 attributes?
	* TODO - convert classic arrays based on known type?
	*/
	_enable(location, enable$1 = true) {
		const canDisableAttribute = WEBGLVertexArray.isConstantAttributeZeroSupported(this.device) || location !== 0;
		if (enable$1 || canDisableAttribute) {
			location = Number(location);
			this.device.gl.bindVertexArray(this.handle);
			if (enable$1) this.device.gl.enableVertexAttribArray(location);
			else this.device.gl.disableVertexAttribArray(location);
			this.device.gl.bindVertexArray(null);
		}
	}
	/**
	* Provide a means to create a buffer that is equivalent to a constant.
	* NOTE: Desktop OpenGL cannot disable attribute 0.
	* https://stackoverflow.com/questions/20305231/webgl-warning-attribute-0-is-disabled-
	* this-has-significant-performance-penalty
	*/
	getConstantBuffer(elementCount, value) {
		const constantValue = normalizeConstantArrayValue(value);
		const byteLength = constantValue.byteLength * elementCount;
		const length = constantValue.length * elementCount;
		if (this.buffer && byteLength !== this.buffer.byteLength) throw new Error(`Buffer size is immutable, byte length ${byteLength} !== ${this.buffer.byteLength}.`);
		let updateNeeded = !this.buffer;
		this.buffer = this.buffer || this.device.createBuffer({ byteLength });
		updateNeeded ||= !compareConstantArrayValues$1(constantValue, this.bufferValue);
		if (updateNeeded) {
			const typedArray = getScratchArray(value.constructor, length);
			fillArray({
				target: typedArray,
				source: constantValue,
				start: 0,
				count: length
			});
			this.buffer.write(typedArray);
			this.bufferValue = value;
		}
		return this.buffer;
	}
};
/**
* TODO - convert Arrays based on known type? (read type from accessor, don't assume Float32Array)
* TODO - handle single values for size 1 attributes?
*/
function normalizeConstantArrayValue(arrayValue) {
	if (Array.isArray(arrayValue)) return new Float32Array(arrayValue);
	return arrayValue;
}
/**
*
*/
function compareConstantArrayValues$1(v1, v2) {
	if (!v1 || !v2 || v1.length !== v2.length || v1.constructor !== v2.constructor) return false;
	for (let i = 0; i < v1.length; ++i) if (v1[i] !== v2[i]) return false;
	return true;
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/resources/webgl-transform-feedback.js
var WEBGLTransformFeedback = class extends TransformFeedback {
	device;
	gl;
	handle;
	/**
	* NOTE: The Model already has this information while drawing, but
	* TransformFeedback currently needs it internally, to look up
	* varying information outside of a draw() call.
	*/
	layout;
	buffers = {};
	unusedBuffers = {};
	/**
	* Allows us to avoid a Chrome bug where a buffer that is already bound to a
	* different target cannot be bound to 'TRANSFORM_FEEDBACK_BUFFER' target.
	* This a major workaround, see: https://github.com/KhronosGroup/WebGL/issues/2346
	*/
	bindOnUse = true;
	_bound = false;
	constructor(device, props) {
		super(device, props);
		this.device = device;
		this.gl = device.gl;
		this.handle = this.props.handle || this.gl.createTransformFeedback();
		this.layout = this.props.layout;
		if (props.buffers) this.setBuffers(props.buffers);
		Object.seal(this);
	}
	destroy() {
		this.gl.deleteTransformFeedback(this.handle);
		super.destroy();
	}
	begin(topology = "point-list") {
		this.gl.bindTransformFeedback(36386, this.handle);
		if (this.bindOnUse) this._bindBuffers();
		this.gl.beginTransformFeedback(getGLPrimitive(topology));
	}
	end() {
		this.gl.endTransformFeedback();
		if (this.bindOnUse) this._unbindBuffers();
		this.gl.bindTransformFeedback(36386, null);
	}
	setBuffers(buffers) {
		this.buffers = {};
		this.unusedBuffers = {};
		this.bind(() => {
			for (const bufferName in buffers) this.setBuffer(bufferName, buffers[bufferName]);
		});
	}
	setBuffer(locationOrName, bufferOrRange) {
		const location = this._getVaryingIndex(locationOrName);
		const { buffer, byteLength, byteOffset } = this._getBufferRange(bufferOrRange);
		if (location < 0) {
			this.unusedBuffers[locationOrName] = buffer;
			log.warn(`${this.id} unusedBuffers varying buffer ${locationOrName}`)();
			return;
		}
		this.buffers[location] = {
			buffer,
			byteLength,
			byteOffset
		};
		if (!this.bindOnUse) this._bindBuffer(location, buffer, byteOffset, byteLength);
	}
	getBuffer(locationOrName) {
		if (isIndex(locationOrName)) return this.buffers[locationOrName] || null;
		const location = this._getVaryingIndex(locationOrName);
		return location >= 0 ? this.buffers[location] : null;
	}
	bind(funcOrHandle = this.handle) {
		if (typeof funcOrHandle !== "function") {
			this.gl.bindTransformFeedback(36386, funcOrHandle);
			return this;
		}
		let value;
		if (!this._bound) {
			this.gl.bindTransformFeedback(36386, this.handle);
			this._bound = true;
			value = funcOrHandle();
			this._bound = false;
			this.gl.bindTransformFeedback(36386, null);
		} else value = funcOrHandle();
		return value;
	}
	unbind() {
		this.bind(null);
	}
	/** Extract offsets for bindBufferRange */
	_getBufferRange(bufferOrRange) {
		if (bufferOrRange instanceof WEBGLBuffer) return {
			buffer: bufferOrRange,
			byteOffset: 0,
			byteLength: bufferOrRange.byteLength
		};
		const { buffer, byteOffset = 0, byteLength = bufferOrRange.buffer.byteLength } = bufferOrRange;
		return {
			buffer,
			byteOffset,
			byteLength
		};
	}
	_getVaryingIndex(locationOrName) {
		if (isIndex(locationOrName)) return Number(locationOrName);
		for (const varying of this.layout.varyings || []) if (locationOrName === varying.name) return varying.location;
		return -1;
	}
	/**
	* Need to avoid chrome bug where buffer that is already bound to a different target
	* cannot be bound to 'TRANSFORM_FEEDBACK_BUFFER' target.
	*/
	_bindBuffers() {
		for (const bufferIndex in this.buffers) {
			const { buffer, byteLength, byteOffset } = this._getBufferRange(this.buffers[bufferIndex]);
			this._bindBuffer(Number(bufferIndex), buffer, byteOffset, byteLength);
		}
	}
	_unbindBuffers() {
		for (const bufferIndex in this.buffers) this.gl.bindBufferBase(35982, Number(bufferIndex), null);
	}
	_bindBuffer(index, buffer, byteOffset = 0, byteLength) {
		const handle = buffer && buffer.handle;
		if (!handle || byteLength === void 0) this.gl.bindBufferBase(35982, index, handle);
		else this.gl.bindBufferRange(35982, index, handle, byteOffset, byteLength);
	}
};
/**
* Returns true if the given value is an integer, or a string that
* trivially converts to an integer (only numeric characters).
*/
function isIndex(value) {
	if (typeof value === "number") return Number.isInteger(value);
	return /^\d+$/.test(value);
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/resources/webgl-query-set.js
/**
* Asynchronous queries for different kinds of information
*/
var WEBGLQuerySet = class extends QuerySet {
	device;
	handle;
	target = null;
	_queryPending = false;
	_pollingPromise = null;
	get [Symbol.toStringTag]() {
		return "Query";
	}
	constructor(device, props) {
		super(device, props);
		this.device = device;
		if (props.count > 1) throw new Error("WebGL QuerySet can only have one value");
		const handle = this.device.gl.createQuery();
		if (!handle) throw new Error("WebGL query not supported");
		this.handle = handle;
		Object.seal(this);
	}
	destroy() {
		this.device.gl.deleteQuery(this.handle);
	}
	/**
	* Shortcut for timer query (dependent on extension in both WebGL1 and 2)
	* Measures GPU time delta between this call and a matching `end` call in the
	* GPU instruction stream.
	*/
	beginTimestampQuery() {
		return this._begin(35007);
	}
	endTimestampQuery() {
		this._end();
	}
	beginOcclusionQuery(options) {
		return this._begin(options?.conservative ? 36202 : 35887);
	}
	endOcclusionQuery() {
		this._end();
	}
	beginTransformFeedbackQuery() {
		return this._begin(35976);
	}
	endTransformFeedbackQuery() {
		this._end();
	}
	async resolveQuery() {
		return [await this.pollQuery()];
	}
	/**
	* Due to OpenGL API limitations, after calling `begin()` on one Query
	* instance, `end()` must be called on that same instance before
	* calling `begin()` on another query. While there can be multiple
	* outstanding queries representing disjoint `begin()`/`end()` intervals.
	* It is not possible to interleave or overlap `begin` and `end` calls.
	*/
	_begin(target$1) {
		if (this._queryPending) return;
		this.target = target$1;
		this.device.gl.beginQuery(this.target, this.handle);
	}
	_end() {
		if (this._queryPending) return;
		if (this.target) {
			this.device.gl.endQuery(this.target);
			this.target = null;
			this._queryPending = true;
		}
	}
	isResultAvailable() {
		if (!this._queryPending) return false;
		const resultAvailable = this.device.gl.getQueryParameter(this.handle, 34919);
		if (resultAvailable) this._queryPending = false;
		return resultAvailable;
	}
	isTimerDisjoint() {
		return this.device.gl.getParameter(36795);
	}
	getResult() {
		return this.device.gl.getQueryParameter(this.handle, 34918);
	}
	getTimerMilliseconds() {
		return this.getResult() / 1e6;
	}
	pollQuery(limit = Number.POSITIVE_INFINITY) {
		if (this._pollingPromise) return this._pollingPromise;
		let counter = 0;
		this._pollingPromise = new Promise((resolve, reject) => {
			const poll = () => {
				if (this.isResultAvailable()) {
					resolve(this.getResult());
					this._pollingPromise = null;
				} else if (counter++ > limit) {
					reject("Timed out");
					this._pollingPromise = null;
				} else requestAnimationFrame(poll);
			};
			requestAnimationFrame(poll);
		});
		return this._pollingPromise;
	}
};

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/helpers/format-utils.js
function glFormatToComponents(format) {
	switch (format) {
		case 6406:
		case 33326:
		case 6403:
		case 36244: return 1;
		case 33339:
		case 33340:
		case 33328:
		case 33320:
		case 33319: return 2;
		case 6407:
		case 36248:
		case 34837: return 3;
		case 6408:
		case 36249:
		case 34836: return 4;
		default: return 0;
	}
}
function glTypeToBytes(type) {
	switch (type) {
		case 5121: return 1;
		case 33635:
		case 32819:
		case 32820: return 2;
		case 5126: return 4;
		default: return 0;
	}
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/converters/shader-formats.js
/** Get shadertypes data type from GL constants */
function convertGLDataTypeToDataType(type) {
	return GL_DATA_TYPE_MAP[type];
}
var GL_DATA_TYPE_MAP = {
	[5124]: "sint32",
	[5125]: "uint32",
	[5122]: "sint16",
	[5123]: "uint16",
	[5120]: "sint8",
	[5121]: "uint8",
	[5126]: "float32",
	[5131]: "float16",
	[33635]: "uint16",
	[32819]: "uint16",
	[32820]: "uint16",
	[33640]: "uint32",
	[35899]: "uint32",
	[35902]: "uint32",
	[34042]: "uint32",
	[36269]: "uint32"
};
/** Get shader data type from GL constants *
export function getPrimitiveTypeFromGL(type: GL): PrimitiveDataType {
switch (type) {
case GL.INT:
return 'i32';
case GL.UNSIGNED_INT:
return 'u32';
case GL.SHORT:
return 'i32';
case GL.UNSIGNED_SHORT:
return 'u32';
case GL.BYTE:
return 'i32';
case GL.UNSIGNED_BYTE:
return 'u32';
case GL.FLOAT:
return 'f32';
case GL.HALF_FLOAT:
return 'f16';
default:
throw new Error(String(type));
}
}

/** Get shader attribute type from GL constants *
export function getShaderAttributeTypeFromGL(
type: GL,
components: 1 | 2 | 3 | 4
): AttributeShaderType {
const dataType = getPrimitiveTypeFromGL(type);
switch (components) {
case 1:
return dataType;
case 2:
return `vec2<${dataType}>`;
case 3:
return `vec2<${dataType}>`;
case 4:
return `vec2<${dataType}>`;
default:
throw new Error(String(components));
}
}
*/
/** GetGL constant from shader data type
export function getGLFromShaderDataType(
type: PrimitiveDataType
): GL.INT | GL.UNSIGNED_INT | GL.FLOAT | GL.HALF_FLOAT {
switch (type) {
// TODO
case 'i32':
return GL.INT;
case 'u32':
return GL.UNSIGNED_INT;
case 'f32':
return GL.FLOAT;
case 'f16':
return GL.HALF_FLOAT;
default:
throw new Error(String(type));
}
}
*/

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/helpers/webgl-texture-utils.js
/**
* Copies data from a type  or a Texture object into ArrayBuffer object.
* App can provide targetPixelArray or have it auto allocated by this method
*  newly allocated by this method unless provided by app.
* @deprecated Use CommandEncoder.copyTextureToBuffer and Buffer.read
* @note Slow requires roundtrip to GPU
*
* @param source
* @param options
* @returns pixel array,
*/
function readPixelsToArray(source, options) {
	const { sourceX = 0, sourceY = 0, sourceAttachment = 0 } = options || {};
	let { target: target$1 = null, sourceWidth, sourceHeight, sourceDepth, sourceFormat, sourceType } = options || {};
	const { framebuffer, deleteFramebuffer } = getFramebuffer(source);
	const { gl, handle } = framebuffer;
	sourceWidth ||= framebuffer.width;
	sourceHeight ||= framebuffer.height;
	const texture = framebuffer.colorAttachments[sourceAttachment]?.texture;
	if (!texture) throw new Error(`Invalid framebuffer attachment ${sourceAttachment}`);
	sourceDepth = texture?.depth || 1;
	sourceFormat ||= texture?.glFormat || 6408;
	sourceType ||= texture?.glType || 5121;
	target$1 = getPixelArray(target$1, sourceType, sourceFormat, sourceWidth, sourceHeight, sourceDepth);
	const signedType = getDataType(target$1);
	sourceType = sourceType || convertDataTypeToGLDataType(signedType);
	const prevHandle = gl.bindFramebuffer(36160, handle);
	gl.readBuffer(36064 + sourceAttachment);
	gl.readPixels(sourceX, sourceY, sourceWidth, sourceHeight, sourceFormat, sourceType, target$1);
	gl.readBuffer(36064);
	gl.bindFramebuffer(36160, prevHandle || null);
	if (deleteFramebuffer) framebuffer.destroy();
	return target$1;
}
/**
* Copies data from a Framebuffer or a Texture object into a Buffer object.
* NOTE: doesn't wait for copy to be complete, it programs GPU to perform a DMA transffer.
* @deprecated Use CommandEncoder
* @param source
* @param options
*/
function readPixelsToBuffer(source, options) {
	const { target: target$1, sourceX = 0, sourceY = 0, sourceFormat = 6408, targetByteOffset = 0 } = options || {};
	let { sourceWidth, sourceHeight, sourceType } = options || {};
	const { framebuffer, deleteFramebuffer } = getFramebuffer(source);
	sourceWidth = sourceWidth || framebuffer.width;
	sourceHeight = sourceHeight || framebuffer.height;
	const webglFramebuffer = framebuffer;
	sourceType = sourceType || 5121;
	let webglBufferTarget = target$1;
	if (!webglBufferTarget) {
		const components = glFormatToComponents(sourceFormat);
		const byteCount = glTypeToBytes(sourceType);
		const byteLength = targetByteOffset + sourceWidth * sourceHeight * components * byteCount;
		webglBufferTarget = webglFramebuffer.device.createBuffer({ byteLength });
	}
	const commandEncoder = source.device.createCommandEncoder();
	commandEncoder.copyTextureToBuffer({
		sourceTexture: source,
		width: sourceWidth,
		height: sourceHeight,
		origin: [sourceX, sourceY],
		destinationBuffer: webglBufferTarget,
		byteOffset: targetByteOffset
	});
	commandEncoder.destroy();
	if (deleteFramebuffer) framebuffer.destroy();
	return webglBufferTarget;
}
function getFramebuffer(source) {
	if (!(source instanceof Framebuffer)) return {
		framebuffer: toFramebuffer(source),
		deleteFramebuffer: true
	};
	return {
		framebuffer: source,
		deleteFramebuffer: false
	};
}
/**
* Wraps a given texture into a framebuffer object, that can be further used
* to read data from the texture object.
*/
function toFramebuffer(texture, props) {
	const { device, width, height, id } = texture;
	return device.createFramebuffer({
		...props,
		id: `framebuffer-for-${id}`,
		width,
		height,
		colorAttachments: [texture]
	});
}
function getPixelArray(pixelArray, glType, glFormat, width, height, depth) {
	if (pixelArray) return pixelArray;
	glType ||= 5121;
	const ArrayType = getTypedArrayConstructor(convertGLDataTypeToDataType(glType));
	const components = glFormatToComponents(glFormat);
	return new ArrayType(width * height * components);
}

//#endregion
//#region node_modules/@luma.gl/webgl/dist/adapter/webgl-device.js
/** WebGPU style Device API for a WebGL context */
var WebGLDevice = class extends Device {
	/** type of this device */
	type = "webgl";
	/** The underlying WebGL context */
	handle;
	features;
	limits;
	info;
	canvasContext;
	preferredColorFormat = "rgba8unorm";
	preferredDepthFormat = "depth24plus";
	commandEncoder;
	lost;
	_resolveContextLost;
	/** WebGL2 context. */
	gl;
	/** Store constants */
	_constants;
	/** State used by luma.gl classes - TODO - not used? */
	_extensions = {};
	_polyfilled = false;
	/** Instance of Spector.js (if initialized) */
	spectorJS;
	get [Symbol.toStringTag]() {
		return "WebGLDevice";
	}
	toString() {
		return `${this[Symbol.toStringTag]}(${this.id})`;
	}
	isVertexFormatSupported(format) {
		switch (format) {
			case "unorm8x4-bgra": return false;
			default: return true;
		}
	}
	constructor(props) {
		super({
			...props,
			id: props.id || uid("webgl-device")
		});
		const canvasContextProps = Device._getCanvasContextProps(props);
		if (!canvasContextProps) throw new Error("WebGLDevice requires props.createCanvasContext to be set");
		let device = canvasContextProps.canvas?.gl?.device;
		if (device) throw new Error(`WebGL context already attached to device ${device.id}`);
		this.canvasContext = new WebGLCanvasContext(this, canvasContextProps);
		this.lost = new Promise((resolve) => {
			this._resolveContextLost = resolve;
		});
		const webglContextAttributes = { ...props.webgl };
		if (canvasContextProps.alphaMode === "premultiplied") webglContextAttributes.premultipliedAlpha = true;
		if (props.powerPreference !== void 0) webglContextAttributes.powerPreference = props.powerPreference;
		const gl = this.props._handle || createBrowserContext(this.canvasContext.canvas, {
			onContextLost: (event) => this._resolveContextLost?.({
				reason: "destroyed",
				message: "Entered sleep mode, or too many apps or browser tabs are using the GPU."
			}),
			onContextRestored: (event) => console.log("WebGL context restored")
		}, webglContextAttributes);
		if (!gl) throw new Error("WebGL context creation failed");
		device = gl.device;
		if (device) {
			if (props._reuseDevices) {
				log.log(1, `Not creating a new Device, instead returning a reference to Device ${device.id} already attached to WebGL context`, device)();
				device._reused = true;
				return device;
			}
			throw new Error(`WebGL context already attached to device ${device.id}`);
		}
		this.handle = gl;
		this.gl = gl;
		this.spectorJS = initializeSpectorJS({
			...this.props,
			gl: this.handle
		});
		this.gl.device = this;
		this.gl._version = 2;
		this.info = getDeviceInfo(this.gl, this._extensions);
		this.limits = new WebGLDeviceLimits(this.gl);
		this.features = new WebGLDeviceFeatures(this.gl, this._extensions, this.props._disabledFeatures);
		if (this.props._initializeFeatures) this.features.initializeFeatures();
		new WebGLStateTracker(this.gl, { log: (...args) => log.log(1, ...args)() }).trackState(this.gl, { copyState: false });
		const debugWebGL = props.debugWebGL || props.debug;
		const traceWebGL = props.debugWebGL;
		if (debugWebGL) {
			this.gl = makeDebugContext(this.gl, {
				debugWebGL,
				traceWebGL
			});
			log.warn("WebGL debug mode activated. Performance reduced.")();
			if (props.debugWebGL) log.level = Math.max(log.level, 1);
		}
		this.commandEncoder = new WEBGLCommandEncoder(this, { id: `${this}-command-encoder` });
	}
	/**
	* Destroys the device
	*
	* @note "Detaches" from the WebGL context unless _reuseDevices is true.
	*
	* @note The underlying WebGL context is not immediately destroyed,
	* but may be destroyed later through normal JavaScript garbage collection.
	* This is a fundamental limitation since WebGL does not offer any
	* browser API for destroying WebGL contexts.
	*/
	destroy() {
		if (!this.props._reuseDevices && !this._reused) delete this.gl.device;
	}
	get isLost() {
		return this.gl.isContextLost();
	}
	getTextureByteAlignment() {
		return 4;
	}
	createCanvasContext(props) {
		throw new Error("WebGL only supports a single canvas");
	}
	createBuffer(props) {
		const newProps = this._normalizeBufferProps(props);
		return new WEBGLBuffer(this, newProps);
	}
	createTexture(props) {
		return new WEBGLTexture(this, props);
	}
	createExternalTexture(props) {
		throw new Error("createExternalTexture() not implemented");
	}
	createSampler(props) {
		return new WEBGLSampler(this, props);
	}
	createShader(props) {
		return new WEBGLShader(this, props);
	}
	createFramebuffer(props) {
		return new WEBGLFramebuffer(this, props);
	}
	createVertexArray(props) {
		return new WEBGLVertexArray(this, props);
	}
	createTransformFeedback(props) {
		return new WEBGLTransformFeedback(this, props);
	}
	createQuerySet(props) {
		return new WEBGLQuerySet(this, props);
	}
	createRenderPipeline(props) {
		return new WEBGLRenderPipeline(this, props);
	}
	createComputePipeline(props) {
		throw new Error("ComputePipeline not supported in WebGL");
	}
	createCommandEncoder(props = {}) {
		return new WEBGLCommandEncoder(this, props);
	}
	/**
	* Offscreen Canvas Support: Commit the frame
	* https://developer.mozilla.org/en-US/docs/Web/API/WebGL2RenderingContext/commit
	* Chrome's offscreen canvas does not require gl.commit
	*/
	submit(commandBuffer) {
		if (!commandBuffer) {
			commandBuffer = this.commandEncoder.finish();
			this.commandEncoder.destroy();
			this.commandEncoder = this.createCommandEncoder({ id: `${this.id}-default-encoder` });
		}
		commandBuffer._executeCommands();
	}
	/** @deprecated - should use command encoder */
	readPixelsToArrayWebGL(source, options) {
		return readPixelsToArray(source, options);
	}
	/** @deprecated - should use command encoder */
	readPixelsToBufferWebGL(source, options) {
		return readPixelsToBuffer(source, options);
	}
	setParametersWebGL(parameters) {
		setGLParameters(this.gl, parameters);
	}
	getParametersWebGL(parameters) {
		return getGLParameters(this.gl, parameters);
	}
	withParametersWebGL(parameters, func) {
		return withGLParameters(this.gl, parameters, func);
	}
	resetWebGL() {
		log.warn("WebGLDevice.resetWebGL is deprecated, use only for debugging")();
		resetGLParameters(this.gl);
	}
	_getDeviceSpecificTextureFormatCapabilities(capabilities) {
		return getTextureFormatCapabilitiesWebGL(this.gl, capabilities, this._extensions);
	}
	/**
	* Triggers device (or WebGL context) loss.
	* @note primarily intended for testing how application reacts to device loss
	*/
	loseDevice() {
		let deviceLossTriggered = false;
		const ext = this.getExtension("WEBGL_lose_context").WEBGL_lose_context;
		if (ext) {
			deviceLossTriggered = true;
			ext.loseContext();
		}
		this._resolveContextLost?.({
			reason: "destroyed",
			message: "Application triggered context loss"
		});
		return deviceLossTriggered;
	}
	/** Save current WebGL context state onto an internal stack */
	pushState() {
		WebGLStateTracker.get(this.gl).push();
	}
	/** Restores previously saved context state */
	popState() {
		WebGLStateTracker.get(this.gl).pop();
	}
	/**
	* Returns the GL.<KEY> constant that corresponds to a numeric value of a GL constant
	* Be aware that there are some duplicates especially for constants that are 0,
	* so this isn't guaranteed to return the right key in all cases.
	*/
	getGLKey(value, options) {
		const number = Number(value);
		for (const key in this.gl) if (this.gl[key] === number) return `GL.${key}`;
		return options?.emptyIfUnknown ? "" : String(value);
	}
	/**
	* Returns a map with any GL.<KEY> constants mapped to strings, both for keys and values
	*/
	getGLKeys(glParameters) {
		const opts = { emptyIfUnknown: true };
		return Object.entries(glParameters).reduce((keys, [key, value]) => {
			keys[`${key}:${this.getGLKey(key, opts)}`] = `${value}:${this.getGLKey(value, opts)}`;
			return keys;
		}, {});
	}
	/**
	* Set a constant value for a location. Disabled attributes at that location will read from this value
	* @note WebGL constants are stored globally on the WebGL context, not the VertexArray
	* so they need to be updated before every render
	* @todo - remember/cache values to avoid setting them unnecessarily?
	*/
	setConstantAttributeWebGL(location, constant) {
		const maxVertexAttributes = this.limits.maxVertexAttributes;
		this._constants = this._constants || new Array(maxVertexAttributes).fill(null);
		const currentConstant = this._constants[location];
		if (currentConstant && compareConstantArrayValues(currentConstant, constant)) log.info(1, `setConstantAttributeWebGL(${location}) could have been skipped, value unchanged`)();
		this._constants[location] = constant;
		switch (constant.constructor) {
			case Float32Array:
				setConstantFloatArray(this, location, constant);
				break;
			case Int32Array:
				setConstantIntArray(this, location, constant);
				break;
			case Uint32Array:
				setConstantUintArray(this, location, constant);
				break;
			default: throw new Error("constant");
		}
	}
	/** Ensure extensions are only requested once */
	getExtension(name$1) {
		getWebGLExtension(this.gl, name$1, this._extensions);
		return this._extensions;
	}
	/**
	* Storing data on a special field on WebGLObjects makes that data visible in SPECTOR chrome debug extension
	* luma.gl ids and props can be inspected
	*/
	_setWebGLDebugMetadata(handle, resource, options) {
		handle.luma = resource;
		handle.__SPECTOR_Metadata = {
			props: options.spector,
			id: options.spector["id"]
		};
	}
};
/** Set constant float array attribute */
function setConstantFloatArray(device, location, array) {
	switch (array.length) {
		case 1:
			device.gl.vertexAttrib1fv(location, array);
			break;
		case 2:
			device.gl.vertexAttrib2fv(location, array);
			break;
		case 3:
			device.gl.vertexAttrib3fv(location, array);
			break;
		case 4:
			device.gl.vertexAttrib4fv(location, array);
			break;
		default:
	}
}
/** Set constant signed int array attribute */
function setConstantIntArray(device, location, array) {
	device.gl.vertexAttribI4iv(location, array);
}
/** Set constant unsigned int array attribute */
function setConstantUintArray(device, location, array) {
	device.gl.vertexAttribI4uiv(location, array);
}
/**
* Compares contents of two typed arrays
* @todo max length?
*/
function compareConstantArrayValues(v1, v2) {
	if (!v1 || !v2 || v1.length !== v2.length || v1.constructor !== v2.constructor) return false;
	for (let i = 0; i < v1.length; ++i) if (v1[i] !== v2[i]) return false;
	return true;
}

//#endregion
export { Log as C, Stats as S, getTypedArrayConstructor as _, getScratchArrayBuffer as a, log as b, RenderPipeline as c, Texture as d, Sampler as f, getDataType as g, alignTo as h, loadSpectorJS as i, Shader as l, getVertexFormatFromAttribute as m, loadWebGLDeveloperTools as n, getAttributeInfosFromLayouts as o, Device as p, DEFAULT_SPECTOR_PROPS as r, getVariableShaderTypeInfo as s, WebGLDevice as t, TextureView as u, Buffer as v, isBrowser as w, lumaStats as x, Resource as y };
//# sourceMappingURL=webgl-device-BEeceotL.js.map